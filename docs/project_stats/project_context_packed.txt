# Project Context Pack
# Generated for LLM Context Window Optimization
# Focus: Core Architecture (Backend + Core Logic)
# Root: split-novel-txt
----------------------------------------


==================== FILE: config.json ====================

{
  "input_file": "C:/Users/Neo/Downloads/528114_tw/故障烏託邦.txt",
  "encoding": "gbk",
  "output_dir": "output",
  "mode": "chapter",
  "chapter_range": "1-20",
  "batch_size": 10,
  "summarize": {
    "enabled": true,
    "provider": "openrouter",
    "model": "deepseek/deepseek-v3.2",
    "api_key": ""
  }
}

==================== FILE: debug_api.py ====================

import requests
import json
import urllib.parse

# 这里的 URL 需要根据实际情况调整，特别是端口
BASE_URL = "http://127.0.0.1:8000"

def test_api():
    novel_name = "故障烏託邦-first3"
    # 注意：在 URL 中使用中文可能需要编码，但在 requests 中通常会自动处理
    # 不过为了保险，我们可以手动检查一下
    
    # 1. List Novels
    print("Fetching novels...")
    res = requests.get(f"{BASE_URL}/api/novels")
    if res.status_code != 200:
        print(f"Error fetching novels: {res.text}")
        return
    novels = res.json()
    print(f"Novels: {json.dumps(novels, ensure_ascii=False)}")
    
    target_novel = None
    for n in novels:
        if n['name'] == novel_name:
            target_novel = n
            break
            
    if not target_novel:
        print(f"Novel {novel_name} not found")
        return

    file_hash = target_novel['hashes'][0]
    print(f"Using hash: {file_hash}")

    # 2. List Runs
    print(f"Fetching runs for {novel_name}/{file_hash}...")
    # URL encode path components if necessary, requests handles it usually but let's be safe
    # Actually requests handles unicode in path just fine.
    res = requests.get(f"{BASE_URL}/api/novels/{novel_name}/{file_hash}/runs")
    if res.status_code != 200:
        print(f"Error fetching runs: {res.text}")
        return
    runs = res.json()
    print(f"Runs found: {len(runs)}")
    if not runs:
        print("No runs found")
        return
        
    latest_run = runs[0]
    timestamp = latest_run['timestamp']
    print(f"Using run: {timestamp}")

    # 3. List Chapters
    print(f"Fetching chapters for {timestamp}...")
    res = requests.get(f"{BASE_URL}/api/novels/{novel_name}/{file_hash}/{timestamp}/chapters")
    if res.status_code != 200:
        print(f"Error fetching chapters: {res.text}")
        return
    chapters = res.json()
    print(f"Chapters found: {len(chapters)}")
    print(json.dumps(chapters, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    try:
        test_api()
    except Exception as e:
        print(f"Exception: {e}")


==================== FILE: main.py ====================

import sys
import os

# 将项目根目录添加到 sys.path，确保可以导入 app, core, data_protocol
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.main import main

if __name__ == '__main__':
    main()


==================== FILE: manage.py ====================

import argparse
import sys
import os
import shutil
import subprocess
from pathlib import Path
from core.config import settings
from core.db.engine import create_db_and_tables

def clean_cache():
    """清理缓存目录"""
    cache_dir = settings.OUTPUT_DIR / ".cache"
    if cache_dir.exists():
        print(f"Removing cache: {cache_dir}")
        shutil.rmtree(cache_dir)
        print("Done.")
    else:
        print("Cache directory does not exist.")

def clean_outputs():
    """清理所有输出文件"""
    output_dir = settings.OUTPUT_DIR
    if output_dir.exists():
        response = input(f"WARNING: This will delete ALL data in {output_dir}. Are you sure? (y/N): ")
        if response.lower() == 'y':
            for item in output_dir.iterdir():
                if item.name == ".gitkeep":
                    continue
                if item.is_dir():
                    shutil.rmtree(item)
                else:
                    item.unlink()
            print("Done.")
    else:
        print("Output directory does not exist.")

def reset_db():
    """重置数据库"""
    db_path = Path("storytrace.db") # TODO: parse from settings properly if needed
    if db_path.exists():
        print(f"Removing database: {db_path}")
        db_path.unlink()
    
    print("Creating new database...")
    create_db_and_tables()
    print("Done.")

def check_env():
    """环境自检"""
    print("=== Environment Check ===")
    print(f"Base Dir: {settings.BASE_DIR}")
    print(f"Output Dir: {settings.OUTPUT_DIR}")
    print(f"DB Path: {settings.database_path}")
    print(f"OpenRouter Key: {'Set' if settings.OPENROUTER_API_KEY else 'Not Set'}")
    
    # Check dependencies
    try:
        import fastapi
        print("FastAPI: Installed")
    except ImportError:
        print("FastAPI: Missing")
        
    try:
        import sqlmodel
        print("SQLModel: Installed")
    except ImportError:
        print("SQLModel: Missing")

    print("=== End Check ===")

def context_tools(tool_name: str):
    """运行 Context 工具"""
    script_map = {
        "watch": "scripts/context_tools/watch_stats.py",
        "pack": "scripts/context_tools/pack_context.py",
        "stats": "scripts/context_tools/generate_stats.py"
    }
    
    script_path = script_map.get(tool_name)
    if not script_path:
        print(f"Unknown context tool: {tool_name}")
        print(f"Available tools: {', '.join(script_map.keys())}")
        return

    print(f"Running {tool_name}...")
    subprocess.run([sys.executable, script_path])

def main():
    parser = argparse.ArgumentParser(description='StoryTrace Management Script')
    subparsers = parser.add_subparsers(dest='command', help='Commands')
    
    subparsers.add_parser('clean-cache', help='Clear the .cache directory')
    subparsers.add_parser('clean-all', help='Clear ALL outputs')
    subparsers.add_parser('reset-db', help='Delete and recreate SQLite database')
    subparsers.add_parser('check', help='Check environment configuration')
    
    context_parser = subparsers.add_parser('context', help='Manage project context for LLMs')
    context_parser.add_argument('tool', choices=['watch', 'pack', 'stats'], help='Tool to run (watch, pack, stats)')
    
    args = parser.parse_args()
    
    if args.command == 'clean-cache':
        clean_cache()
    elif args.command == 'clean-all':
        clean_outputs()
    elif args.command == 'reset-db':
        reset_db()
    elif args.command == 'check':
        check_env()
    elif args.command == 'context':
        context_tools(args.tool)
    else:
        parser.print_help()

if __name__ == '__main__':
    main()


==================== FILE: app\main.py ====================

import argparse
import sys
import os
from core.splitter.processor import Splitter
from core.splitter.saver import save_chapters
from core.summarizer.llm_client import ClientFactory
from core.summarizer.generator import SummaryGenerator
from core.utils import calculate_file_hash
from data_protocol.models import Chapter
import json
import time
from core.config import settings
from core.paths import PathManager

def parse_range(range_str: str, max_val: int) -> tuple:
    """
    解析用户输入的范围字符串
    支持格式: 
    - "10" -> (1, 10)
    - "5-15" -> (5, 15)
    - "all" -> (1, max_val)
    - "" (empty) -> (1, max_val)
    """
    s = range_str.strip().lower()
    if not s or s == 'all':
        return (1, max_val)
    
    if '-' in s:
        try:
            start, end = map(int, s.split('-'))
            return (max(1, start), min(max_val, end))
        except ValueError:
            return (1, max_val)
            
    try:
        val = int(s)
        return (1, min(max_val, val))
    except ValueError:
        return (1, max_val)

def get_user_input():
    """交互式获取用户输入"""
    print("\n=== 小说分割工具 ===")
    
    # 0. 尝试加载配置文件
    config_path = "config.json"
    if os.path.exists(config_path):
        print(f"\n检测到配置文件: {config_path}")
        if input("是否加载配置并直接运行? (Y/n): ").strip().lower() != 'n':
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                # 解析配置
                input_file = config.get('input_file', '')
                encoding = config.get('encoding', 'utf-8')
                output_dir = config.get('output_dir', 'output')
                mode_str = config.get('mode', 'chapter')
                range_str = config.get('chapter_range', '')
                batch_size = config.get('batch_size', 10)
                
                # 映射模式字符串到编号
                mode_map_rev = {'volume': '1', 'chapter': '2', 'batch': '3'}
                mode = mode_map_rev.get(mode_str, '2')
                
                # 解析范围
                # 需要先扫描章节数才能解析 "all" 或 "-10" 吗？
                # parse_range 需要 max_val。
                # 我们可以先扫描文件。
                
                print("\n--- 配置信息 ---")
                print(f"文件: {input_file}")
                print(f"编码: {encoding}")
                print(f"模式: {mode_str}")
                print(f"范围: {range_str if range_str else 'All'}")
                print(f"输出: {output_dir}")
                
                summ_conf = config.get('summarize', {})
                
                # 自动填充 API Key 逻辑 (Fix for .env loading)
                if summ_conf.get('enabled') and summ_conf.get('provider') == 'openrouter':
                    current_key = summ_conf.get('api_key')
                    if not current_key:  # If None or Empty String
                        # 优先从 settings (Pydantic加载的.env) 获取，其次才是 os.getenv
                        env_key = settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
                        if env_key:
                            summ_conf['api_key'] = env_key
                            print(f"  (已自动从 .env/环境变量 加载 OPENROUTER_API_KEY)")

                print(f"AI总结: {'开启' if summ_conf.get('enabled') else '关闭'}")
                if summ_conf.get('enabled'):
                    print(f"  Provider: {summ_conf.get('provider')}")
                    print(f"  Model: {summ_conf.get('model')}")
                
                if input("\n确认执行? (Y/n): ").strip().lower() != 'n':
                    # 执行预扫描以获取章节总数 (用于解析范围)
                    print("\n正在扫描文件结构...")
                    splitter = Splitter(encoding=encoding)
                    content = splitter.read_file(input_file)
                    # 更新为实际检测到的编码
                    encoding = splitter.encoding
                    total_chapters, _, _ = splitter.scan_chapters(content)
                    
                    chapter_range = parse_range(range_str, total_chapters)
                    
                    # 构造返回字典
                    extra_args = {}
                    if mode == '3':
                        extra_args['range'] = batch_size
                    if chapter_range:
                        extra_args['chapter_range'] = chapter_range
                        
                    return {
                        'input_file': input_file,
                        'mode': mode,
                        'output_dir': output_dir,
                        'encoding': encoding,
                        'extra_args': extra_args,
                        'summarize_config': summ_conf
                    }
            except Exception as e:
                print(f"配置文件加载失败: {e}")
                print("将转为手动输入模式...")

    # 1. 获取输入文件
    # 尝试使用 tkinter 弹出文件选择框
    input_file = ""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        # 隐藏主窗口
        root = tk.Tk()
        root.withdraw()
        
        # 尝试强制窗口置顶 (Windows特定)
        root.attributes('-topmost', True)
        
        print("正在打开文件选择窗口...")
        input_file = filedialog.askopenfilename(
            title="选择小说TXT文件",
            filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")]
        )
        root.destroy()
    except ImportError:
        # 如果没有 tkinter，静默失败，回退到输入框
        pass
    except Exception as e:
        print(f"无法打开文件选择框 ({e})，请手动输入。")
    
    # 如果用户取消选择或无法使用 tkinter，回退到手动输入
    while not input_file:
        input_file = input("请输入小说txt文件路径: ").strip()
        # 移除可能存在的引号
        input_file = input_file.strip('"').strip("'")
        if os.path.exists(input_file):
            break
        print(f"错误：文件 '{input_file}' 不存在，请重新输入。")
    
    print(f"已选择文件: {input_file}")

    # 2. 编码设置（提前到第二步，以便扫描文件）
    encoding = input("\n请输入文件编码 (默认为 'utf-8', 若乱码可尝试 'gbk'): ").strip()
    if not encoding:
        encoding = 'utf-8'

    # 3. 预扫描章节
    print("\n正在扫描文件结构...")
    try:
        splitter = Splitter(encoding=encoding)
        content = splitter.read_file(input_file)
        # 更新为实际检测到的编码
        encoding = splitter.encoding
        
        total_chapters, titles, is_continuous = splitter.scan_chapters(content)
        
        if total_chapters > 0:
            print(f"✅ 检测到共 {total_chapters} 章。")
            if not is_continuous:
                print("⚠️  警告: 章节编号似乎不连续，建议检查文件内容。")
            else:
                print("   章节编号连续。")
            
            print(f"   首章: {titles[0]}")
            print(f"   末章: {titles[-1]}")
        else:
            print("⚠️  未检测到明显的分章结构 (可能需要按卷或自定义正则)。")
            total_chapters = 999999 # Fallback
            
    except Exception as e:
        print(f"扫描失败: {e}")
        total_chapters = 0

    # 4. 选择处理范围
    chapter_range = None
    if total_chapters > 0:
        range_input = input(f"\n请输入处理范围 (默认处理全部，输入 '10' 代表前10章，'5-20' 代表区间): ").strip()
        chapter_range = parse_range(range_input, total_chapters)
        print(f"已选择范围: 第{chapter_range[0]}章 - 第{chapter_range[1]}章")

    # 5. 选择模式
    print("\n请选择分割模式：")
    print("1. 按卷分割（自动识别分卷，卷内再分章）")
    print("2. 仅按章节分割（整本小说切分为单章文件）")
    print("3. 按数量合并分割（每N章合并为一个文件）")
    
    while True:
        mode = input("请输入模式编号 (1/2/3): ").strip()
        if mode in ['1', '2', '3']:
            break
        print("输入无效，请输入 1, 2 或 3。")

    # 6. 获取输出目录
    output_dir = input(f"\n请输入输出目录 (默认为 '{settings.OUTPUT_DIR.name}'): ").strip()
    if not output_dir:
        output_dir = str(settings.OUTPUT_DIR)

    # 7. 获取特定模式的额外参数
    extra_args = {}
    if mode == '3':
        while True:
            try:
                range_val = input("请输入每个文件包含的章节数 (默认为10): ").strip()
                if not range_val:
                    extra_args['range'] = 10
                else:
                    extra_args['range'] = int(range_val)
                break
            except ValueError:
                print("请输入有效的数字。")
    
    # Pass the scan result range
    if chapter_range:
        extra_args['chapter_range'] = chapter_range

    # 8. AI 总结配置
    summarize_config = {'enabled': False}
    print("\n是否开启 AI 智能总结? (y/N)")
    if input().lower().strip() == 'y':
        summarize_config['enabled'] = True
        
        print("\n请选择 LLM 提供商:")
        print("1. OpenRouter (默认)")
        print("2. Local (Ollama/vLLM)")
        prov_input = input("请输入编号 (1/2): ").strip()
        
        if prov_input == '2':
            summarize_config['provider'] = 'local'
            # 尝试从环境变量获取默认值
            default_base = os.getenv("LOCAL_LLM_BASE_URL", "http://localhost:11434/v1")
            default_model = os.getenv("LOCAL_LLM_MODEL", "qwen2.5:14b")
            
            base_url = input(f"Base URL (默认 '{default_base}'): ").strip()
            summarize_config['base_url'] = base_url if base_url else default_base
            
            model = input(f"Model Name (默认 '{default_model}'): ").strip()
            summarize_config['model'] = model if model else default_model
        else:
            summarize_config['provider'] = 'openrouter'
            # OpenRouter Config
            default_model = os.getenv("OPENROUTER_MODEL", "google/gemini-2.0-flash-001")
            model = input(f"Model Name (默认 '{default_model}'): ").strip()
            summarize_config['model'] = model if model else default_model
            
            # API Key
            env_key = os.getenv("OPENROUTER_API_KEY")
            if env_key:
                print(f"检测到环境变量 OPENROUTER_API_KEY (已隐藏)")
                use_env = input("是否使用环境变量中的 Key? (Y/n): ").strip().lower()
                if use_env == 'n':
                    summarize_config['api_key'] = input("请输入 OpenRouter API Key: ").strip()
                else:
                    summarize_config['api_key'] = env_key
            else:
                summarize_config['api_key'] = input("请输入 OpenRouter API Key: ").strip()

    return {
        'input_file': input_file,
        'mode': mode,
        'output_dir': output_dir,
        'encoding': encoding,
        'extra_args': extra_args,
        'summarize_config': summarize_config
    }

from core.summarizer.prompts import Prompts
from core.cache_manager import CacheManager

def main():
    # 检查是否是启动 Web 服务命令
    if len(sys.argv) > 1 and sys.argv[1] == 'serve':
        try:
            import uvicorn
            from backend.server import app
            print("=== StoryTrace Visualization Server ===")
            print("正在启动 API 服务...")
            print(f"访问地址: http://{settings.API_HOST}:{settings.API_PORT}/docs")
            uvicorn.run(app, host=settings.API_HOST, port=settings.API_PORT)
        except ImportError:
            print("错误: 请先安装 web 依赖: pip install fastapi uvicorn")
        except Exception as e:
            print(f"启动失败: {e}")
        return

    parser = argparse.ArgumentParser(description='全能小说分割工具')
    parser.add_argument('-i', '--input', help='输入文件路径')
    parser.add_argument('-m', '--mode', choices=['volume', 'chapter', 'batch'], 
                        help='分割模式: volume(按卷), chapter(按章), batch(按数量)')
    parser.add_argument('-o', '--output', help='输出目录')
    parser.add_argument('-e', '--encoding', default='utf-8', help='文件编码')
    parser.add_argument('-r', '--range', type=int, default=10, help='批量分割时的章节数量 (仅batch模式有效)')
    parser.add_argument('--pattern', default=r'^[第卷\d一二三四五六七八九十百千万]+卷', help='分卷匹配模式 (仅volume模式有效)')
    
    # LLM 相关参数
    parser.add_argument('--summarize', action='store_true', help='开启智能总结 (实验性功能)')
    parser.add_argument('--provider', default='openrouter', choices=['local', 'openrouter'], help='LLM 提供商')
    parser.add_argument('--api-key', help='API Key (OpenRouter 需要)')
    parser.add_argument('--model', help='模型名称')
    parser.add_argument('--base-url', help='Local LLM Base URL')

    # 如果没有提供任何参数，且不是被导入调用，则进入交互模式
    if len(sys.argv) == 1:
        args_dict = get_user_input()
        print("\nDEBUG: 用户输入接收完成，正在初始化...", flush=True)
        input_file = args_dict['input_file']
        mode = args_dict['mode']
        output_dir = args_dict['output_dir']
        encoding = args_dict['encoding']
        
        # 映射模式编号到内部名称
        mode_map = {'1': 'volume', '2': 'chapter', '3': 'batch'}
        mode_name = mode_map[mode]
        
        extra_args = args_dict['extra_args']
        batch_size = extra_args.get('range', 10)
        chapter_range_filter = extra_args.get('chapter_range')
        
        pattern = r'^[第卷\d一二三四五六七八九十百千万]+卷' # 交互模式使用默认pattern
        
        # 读取交互模式下的 LLM 配置
        summarize_config = args_dict.get('summarize_config', {'enabled': False})
        summarize = summarize_config['enabled']
        provider = summarize_config.get('provider', 'openrouter')
        api_key = summarize_config.get('api_key')
        model = summarize_config.get('model')
        base_url = summarize_config.get('base_url')
        
        # 如果 Config 中没有提供 API Key，尝试从环境变量获取
        if not api_key and provider == 'openrouter':
            api_key = settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
            if api_key:
                print("DEBUG: 使用 .env/环境变量 中的 OPENROUTER_API_KEY")
    else:
        args = parser.parse_args()
        if not args.input:
            parser.error("非交互模式下必须指定输入文件 (-i/--input)")
        if not args.mode:
            parser.error("非交互模式下必须指定模式 (-m/--mode)")
            
        input_file = args.input
        mode_name = args.mode
        output_dir = args.output if args.output else str(settings.OUTPUT_DIR)
        encoding = args.encoding
        batch_size = args.range
        pattern = args.pattern
        chapter_range_filter = None # CLI模式暂不支持 range filter，后续可添加
        
        summarize = args.summarize
        provider = args.provider
        
        # 优先从命令行参数获取，如果没有，则尝试从环境变量获取
        api_key = args.api_key or settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
        model = args.model
        base_url = args.base_url

        # 如果是 OpenRouter 且没有指定 Model，尝试从环境变量获取默认 Model
        if provider == 'openrouter' and not model:
             model = settings.OPENROUTER_MODEL or os.getenv("OPENROUTER_MODEL")
             
        # 如果是 Local 且没有指定参数，尝试从环境变量获取
        if provider == 'local':
             if not base_url:
                 base_url = settings.LOCAL_LLM_BASE_URL or os.getenv("LOCAL_LLM_BASE_URL")
             if not model:
                 model = settings.LOCAL_LLM_MODEL or os.getenv("LOCAL_LLM_MODEL")

    # 构建最终输出目录结构
    # 1. 获取小说名（输入文件名，不含扩展名）
    novel_name = os.path.splitext(os.path.basename(input_file))[0]
    
    # --- 自动复制外部文件逻辑 ---
    # 获取项目根目录 (假设 main.py 在 app/ 目录下)
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    input_abs = os.path.abspath(input_file)
    
    # 检查文件是否在项目目录内
    if not input_abs.startswith(project_root):
        print(f"\n提示: 检测到输入文件位于项目目录外 ({input_abs})")
        inputs_dir = os.path.join(project_root, "inputs")
        os.makedirs(inputs_dir, exist_ok=True)
        
        new_path = os.path.join(inputs_dir, os.path.basename(input_file))
        
        # 自动复制
        try:
            import shutil
            if not os.path.exists(new_path):
                print(f"正在复制文件到项目目录: {new_path} ...")
                shutil.copy2(input_file, new_path)
            else:
                print(f"项目目录内已存在同名文件，将使用: {new_path}")
            
            # 更新 input_file 指向新路径
            input_file = new_path
        except Exception as e:
            print(f"警告: 文件复制失败 ({e})，将继续使用原路径。")

    print(f"DEBUG: 正在计算文件哈希... (文件: {input_file})", flush=True)
    # 2. 计算文件哈希（取前8位即可）
    file_hash = calculate_file_hash(input_file)
    if len(file_hash) > 8:
        file_hash = file_hash[:8]
    print(f"DEBUG: 文件哈希: {file_hash}", flush=True)
    
    # --- 缓存检查逻辑 (v3.0) ---
    print(f"DEBUG: Summarize={summarize}, Provider={provider}", flush=True)
    
    # 1. 计算当前运行的 Fingerprint
    # 注意：这里我们还没有加载 prompts，需要引入 Prompts 类来计算
    current_fingerprint = {
        "source_file_hash": file_hash,
        "prompt_hash": Prompts.get_prompt_hash() if summarize else None,
        "model_config": {
            "provider": provider,
            "model": model,
            # "temperature": ... (如果后续支持 temp 参数，这里也要加上)
        } if summarize else None,
        "splitter_config": {
            "mode": mode_name,
            "batch_size": batch_size if mode_name == 'batch' else None,
            "chapter_range_filter": chapter_range_filter, # 新增范围过滤指纹
            "pattern": pattern if mode_name == 'volume' else None
        }
    }
    print("DEBUG: 指纹计算完成，正在检查缓存...")
    
    # 2. 扫描历史记录
    novel_output_root = PathManager.get_novel_root(novel_name, file_hash)
    cache_hit_path = None
    cache_hit_timestamp = None
    
    if os.path.exists(novel_output_root) and summarize: # 只有开启总结时才值得缓存
        for ts in os.listdir(novel_output_root):
            ts_path = os.path.join(novel_output_root, ts)
            meta_path = os.path.join(ts_path, "run_metadata.json")
            if os.path.isdir(ts_path) and os.path.exists(meta_path):
                try:
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta = json.load(f)
                        # 比较指纹
                        # 注意：旧版本的 metadata 没有 fingerprint 字段，会自动忽略
                        if meta.get("fingerprint") == current_fingerprint:
                            cache_hit_path = ts_path
                            cache_hit_timestamp = ts
                            break
                except Exception:
                    continue
    
    # 3. 如果命中缓存
    if cache_hit_path:
        print(f"\n[Cache Hit] 发现完全相同的历史运行记录: {cache_hit_timestamp}")
        print(f"无需重复调用 LLM。")
        
        # 生成新的时间戳目录
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        final_output_dir = PathManager.get_run_dir(novel_name, file_hash, timestamp)
        os.makedirs(final_output_dir, exist_ok=True)
        
        # 创建 ref_link.json
        link_data = {
            "link_type": "cache_hit",
            "target_timestamp": cache_hit_timestamp,
            "reason": "Fingerprint match",
            "fingerprint": current_fingerprint
        }
        with open(os.path.join(final_output_dir, "ref_link.json"), 'w', encoding='utf-8') as f:
            json.dump(link_data, f, ensure_ascii=False, indent=2)
            
        print(f"已创建链接目录: {final_output_dir}")
        print(f"您可以在 Visualization Server 中查看此记录（将自动指向历史数据）。")
        return
    
    # --- 缓存检查结束 ---

    # 3. 获取当前时间戳
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # 最终路径：output_dir/novel_name/file_hash/timestamp
    final_output_dir = PathManager.get_run_dir(novel_name, file_hash, timestamp)
    abs_final_output_dir = os.path.abspath(final_output_dir)
    
    # 执行分割逻辑
    print(f"\n开始处理：{input_file}")
    print(f"模式：{mode_name}")
    print(f"输出目录 (绝对路径)：{abs_final_output_dir}")
    
    try:
        print(f"正在读取文件 (编码: {encoding})...")
        splitter = Splitter(encoding=encoding)
        content = splitter.read_file(input_file)
        
        print("正在分割章节...")
        if mode_name == 'volume':
            # 暂时不支持卷模式的范围过滤
            chapters = splitter.split_by_volume(content, volume_pattern=pattern)
        elif mode_name == 'chapter':
            chapters = splitter.split_by_chapter(content, chapter_range=chapter_range_filter)
        elif mode_name == 'batch':
            chapters = splitter.split_by_batch(content, batch_size=batch_size, chapter_range=chapter_range_filter)
        else:
            print(f"不支持的模式: {mode_name}")
            return
            
        if chapters:
            print(f"成功分割出 {len(chapters)} 章。正在保存...")
            # 使用新的 final_output_dir 保存章节
            # 强制使用 UTF-8 保存，确保 Web UI 能正确读取
            save_chapters(chapters, final_output_dir, encoding='utf-8')
            print("\n分割处理完成！")
            
            # 如果开启了总结功能
            if summarize:
                print("\n=== 开始智能总结 ===")
                try:
                    # 确保参数不为空
                    client_kwargs = {
                        "provider": provider,
                        "api_key": api_key,
                        "model": model,
                        "base_url": base_url
                    }
                    # 过滤掉 None 值和空字符串
                    client_kwargs = {k: v for k, v in client_kwargs.items() if v}
                    
                    llm_client = ClientFactory.create_client(**client_kwargs)
                    generator = SummaryGenerator(llm_client)
                    
                    # --- v4.0 Chapter-Level Caching ---
                    # Initialize CacheManager
                    cache_dir = PathManager.get_cache_dir()
                    cache_manager = CacheManager(str(cache_dir))
                    
                    prompt_hash = Prompts.get_prompt_hash()
                    model_config = {
                        "provider": provider,
                        "model": model,
                        "base_url": base_url
                    }
                    
                    import asyncio
                    
                    # Initialize total_chapters before defining async functions
                    total_chapters = len(chapters)

                    async def process_chapter_async(i, ch, cache_manager, generator, prompt_hash, model_config, semaphore, file_lock, jsonl_path):
                        async with semaphore:
                            print(f"[{i+1}/{total_chapters}] 处理章节: {ch.title} ... ", end="", flush=True)
                            
                            # 1. Try Cache
                            cached_summary = cache_manager.get_cached_summary(ch.content, prompt_hash, model_config)
                            
                            summary_data = None
                            
                            if cached_summary:
                                print("✅ 命中缓存")
                                cached_summary.chapter_id = ch.id 
                                summary_data = cached_summary.model_dump()
                            else:
                                # 2. Generate (Async) with Retry
                                max_retries = 3
                                retry_delay = 2
                                
                                for attempt in range(max_retries):
                                    try:
                                        summary = await generator.generate_summary_async(ch)
                                        
                                        # 3. Save to Cache
                                        try:
                                            cache_manager.save_summary(ch.content, prompt_hash, model_config, summary)
                                        except Exception as cache_err:
                                            print(f"(Cache Write Failed: {cache_err}) ", end="")
                                            
                                        summary_data = summary.model_dump()
                                        print("✨ 生成完成")
                                        break # Success
                                    except Exception as e:
                                        if attempt < max_retries - 1:
                                            print(f"⚠️ 失败(重试 {attempt+1}/{max_retries}): {e} ... ", end="", flush=True)
                                            await asyncio.sleep(retry_delay * (2 ** attempt)) # Exponential backoff
                                        else:
                                            print(f"❌ 最终失败: {e}")
                                            # Create Empty Placeholder to keep chapter in timeline
                                            from data_protocol.models import ChapterSummary
                                            empty_summary = ChapterSummary(
                                                chapter_id=ch.id,
                                                chapter_title=ch.title,
                                                headline="生成失败",
                                                summary_sentences=[],
                                                entities=[],
                                                relationships=[]
                                            )
                                            summary_data = empty_summary.model_dump()
                                
                            # Real-time save to summaries.jsonl (with lock)
                            if summary_data:
                                async with file_lock:
                                    with open(jsonl_path, 'a', encoding='utf-8') as f:
                                        json.dump(summary_data, f, ensure_ascii=False)
                                        f.write('\n')
                            
                            return (i, summary_data)

                    async def run_batch_processing():
                        # Adjust concurrency based on provider
                        limit = 1 if provider == 'local' else 5
                        semaphore = asyncio.Semaphore(limit)
                        file_lock = asyncio.Lock()
                        jsonl_path = os.path.join(final_output_dir, "summaries.jsonl")
                        
                        tasks = []
                        for i, ch in enumerate(chapters):
                            task = process_chapter_async(i, ch, cache_manager, generator, prompt_hash, model_config, semaphore, file_lock, jsonl_path)
                            tasks.append(task)
                        
                        results = await asyncio.gather(*tasks)
                        
                        # Sort results by index to ensure order
                        valid_results = [r for r in results if r is not None]
                        valid_results.sort(key=lambda x: x[0])
                        
                        return [r[1] for r in valid_results]

                    # Run Async Loop
                    summaries = asyncio.run(run_batch_processing())
                    
                    # 保存总结结果，直接保存在 final_output_dir 根目录
                    summary_path = os.path.join(final_output_dir, "summaries.json")
                    with open(summary_path, 'w', encoding='utf-8') as f:
                        json.dump(summaries, f, ensure_ascii=False, indent=2)
                    print(f"总结已保存至: {summary_path}")
                    
                    # 同时保存一份 metadata，记录这次运行的参数
                    metadata = {
                        "timestamp": timestamp,
                        "novel_name": novel_name,
                        "file_hash": file_hash,
                        "input_file": os.path.abspath(input_file),
                        "provider": provider,
                        "model": model,
                        "chapter_count": len(summaries),
                        "fingerprint": current_fingerprint # 记录指纹，供下次校验
                    }
                    with open(os.path.join(final_output_dir, "run_metadata.json"), 'w', encoding='utf-8') as f:
                        json.dump(metadata, f, ensure_ascii=False, indent=2)
                    
                    # --- 自动执行数据库迁移 (Auto Migration) ---
                    print("\n=== 正在自动更新图谱数据库 ===")
                    try:
                        from scripts.migrate_json_to_sqlite import migrate
                        print("正在同步数据到 storytrace.db ...")
                        migrate()
                        print("✅ 数据库同步完成！现在可以启动 Web 服务查看图谱了。")
                    except Exception as me:
                        print(f"⚠️ 自动迁移失败: {me}")
                        print("请稍后手动运行: python scripts/migrate_json_to_sqlite.py")

                except Exception as e:
                    print(f"智能总结失败: {e}")
                    import traceback
                    traceback.print_exc()
            
        else:
            print("\n未找到任何章节。")
        
    except Exception as e:
        print(f"\n发生错误: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()


==================== FILE: backend\__init__.py ====================



==================== FILE: backend\schemas.py ====================

from typing import List, Dict, Optional, Any
from pydantic import BaseModel

class NovelInfo(BaseModel):
    name: str
    hashes: List[str]

class RunInfo(BaseModel):
    timestamp: str
    metadata: Optional[Dict[str, Any]] = None

class ChapterPreview(BaseModel):
    id: str
    title: str
    headline: str
    has_summary: bool = True

class SourceSpan(BaseModel):
    start_index: int
    end_index: int
    text: str

class SummarySentence(BaseModel):
    summary_text: str
    source_spans: List[SourceSpan] = []

class EntityDetail(BaseModel):
    name: str
    type: str
    description: str
    confidence: float = 1.0

class ChapterDetail(BaseModel):
    id: str
    title: str
    headline: Optional[str] = None
    content: str
    summary_sentences: List[SummarySentence]
    entities: List[EntityDetail] = []

class TimelineEvent(BaseModel):
    chapter_id: str
    chapter_index: int
    chapter_title: str
    content: List[str]
    gap_before: int

class RelationshipInteraction(BaseModel):
    direction: str # forward or backward
    relation: str
    description: str
    confidence: float

class RelationshipTimelineEvent(BaseModel):
    chapter_id: str
    chapter_index: int  # Added for sorting
    chapter_title: str
    interactions: List[RelationshipInteraction]
    
    # Narrative State (Added in v4.2)
    narrative_state: Optional[Dict[str, Any]] = None # Serialized RelationshipState

class GraphNode(BaseModel):
    name: str
    type: str
    description: str
    count: int = 1
    chapter_ids: List[str] = []
    history: List[Dict[str, Any]] = [] # Detailed history per chapter

class EdgeEvent(BaseModel):
    chapter_id: str
    weight: int = 1
    relation: Optional[str] = None
    description: Optional[str] = None
    order: int = 0

class GraphEdge(BaseModel):
    source: str
    target: str
    weight: int
    timeline: List[EdgeEvent] = []

class GraphData(BaseModel):
    nodes: List[GraphNode]
    edges: List[GraphEdge]


==================== FILE: backend\server.py ====================

import os
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from backend.routers import novels, analysis, jobs

app = FastAPI(title="StoryTrace API")

# 允许跨域
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include Routers
app.include_router(novels.router)
app.include_router(analysis.router)
app.include_router(jobs.router)

@app.get("/")
async def index():
    return {"message": "StoryTrace API is running. Please access the frontend at http://localhost:5173"}

if __name__ == "__main__":
    import uvicorn
    from core.config import settings
    uvicorn.run(app, host=settings.API_HOST, port=settings.API_PORT)


==================== FILE: backend\utils.py ====================

from pathlib import Path
import json
from core.config import settings

def get_novel_path(novel_name: str, file_hash: str, timestamp: str) -> str:
    """Returns the absolute path to the run directory"""
    return str(settings.OUTPUT_DIR / novel_name / file_hash / timestamp)

def resolve_run_path(novel_name: str, file_hash: str, timestamp: str) -> str:
    """解析实际的运行路径（处理缓存链接）"""
    base_path = Path(get_novel_path(novel_name, file_hash, timestamp))
    ref_file = base_path / "ref_link.json"
    
    if ref_file.exists():
        try:
            with open(ref_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                target_ts = data.get("target_timestamp")
                if target_ts:
                    return get_novel_path(novel_name, file_hash, target_ts)
        except:
            pass
    return str(base_path)

def get_output_dir() -> str:
    return str(settings.OUTPUT_DIR)


==================== FILE: backend\narrative_engine\prompts.py ====================

from typing import List
import json

RELATIONSHIP_ANALYSIS_TEMPLATE = """
You are a literary analyst tracking the relationship between {source} and {target}.

### Previous State (Up to Ch {prev_chapter_index})
- Archetype: {dominant_archetype}
- Stage: {current_stage}
- Trust: {trust_level}/100 | Romance: {romance_level}/100 | Conflict: {conflict_level}/100
- Summary: {summary_so_far}
- Unresolved Threads: {unresolved_threads}

### New Events (Current Block)
{events_text}

### Task
Analyze how the relationship has EVOLVED based on the new events.
1. Update the metrics (Trust/Romance/Conflict).
2. **REWRITE** the `summary_so_far` to incorporate the new events.
   - The new summary should be a holistic description of the relationship status.
   - Keep it concise (under 300 words).
   - Retain important history while integrating new developments.

**IMPORTANT: Output MUST be in Chinese (Simplified).**
- `dominant_archetype` and `current_stage` should be concise Chinese terms (e.g., "盟友", "信任危机").
- `revised_summary` should be the updated narrative summary (replacing the old one).

### Output Format (JSON Only)
{{
    "trust_level": int,
    "romance_level": int,
    "conflict_level": int,
    "dominant_archetype": "string (Chinese)",
    "current_stage": "string (Chinese)",
    "revised_summary": "string (Chinese)",
    "new_unresolved_threads": ["string (Chinese)"]
}}
"""


==================== FILE: backend\narrative_engine\core\engine.py ====================

from typing import List, Dict, Type, Any, Union, Callable
from backend.narrative_engine.core.store import StateStore
from backend.narrative_engine.core.models import BaseNarrativeState, AnalysisEvent
from backend.narrative_engine.plugins.base import NarrativePlugin

class NarrativeEvolutionEngine:
    """
    Orchestrates the incremental analysis of narrative entities.
    """
    def __init__(self, store: StateStore):
        self.store = store
        self.plugins: Dict[str, NarrativePlugin] = {}

    def register_plugin(self, plugin: NarrativePlugin):
        """Register a plugin (e.g., 'relationship')"""
        self.plugins[plugin.plugin_type] = plugin

    def evolve_state(
        self,
        novel_hash: str,
        plugin_type: str,
        entity_id: str,
        target_chapter_index: int,
        new_events: List[AnalysisEvent],
        llm_client: Any = None,
        progress_callback: Callable[[int, str], None] = None
    ) -> BaseNarrativeState:
        """
        Main Loop:
        1. Load previous state (Snapshot N).
        2. Check if we need to run LLM (Adaptive Trigger).
        3. If yes, generate prompt -> call LLM -> parse -> save new state (Snapshot N+1).
        4. If no, clone previous state -> save new state (Snapshot N+1).
        """
        plugin = self.plugins.get(plugin_type)
        if not plugin:
            raise ValueError(f"Plugin '{plugin_type}' not registered.")

        # 1. Load Previous State
        # We look for the latest checkpoint BEFORE the target chapter
        prev_state = self.store.get_latest_state(
            novel_hash, 
            plugin_type, 
            entity_id, 
            before_chapter=target_chapter_index,
            model_class=plugin.state_model
        )

        # 1.5. Check if CURRENT State already exists (Cache Hit)
        # If we already have a state for target_chapter_index, we can skip analysis!
        # This is crucial for re-running the job on the same pair.
        current_state = self.store.get_state_at_chapter(
            novel_hash,
            plugin_type,
            entity_id,
            target_chapter_index,
            plugin.state_model
        )
        
        if current_state:
            # Cache Hit!
            if progress_callback:
                progress_callback(100, "Cache Hit (Skipping LLM)")
            return current_state

        # If no history, initialize blank state
        if not prev_state:
            if hasattr(plugin, 'get_initial_state'):
                prev_state = plugin.get_initial_state(entity_id)
            else:
                # Fallback or Error?
                # For now, let's assume all plugins MUST implement this or we fail gracefully
                print(f"[Engine] No previous state and no get_initial_state for {entity_id}")
                return None

        # 2. Check Trigger (Adaptive Logic)
        # Note: prev_state might be None if it's the very first chapter.
        should_trigger = False
        
        # If we have an LLM client, we check if we should trigger
        if llm_client:
            if progress_callback:
                progress_callback(10, "Checking interaction density...")
            should_trigger = plugin.check_trigger(prev_state, new_events)

        new_state = None

        if should_trigger and llm_client:
            # 3. LLM Path
            if progress_callback:
                progress_callback(30, "Generating LLM prompt...")
                
            prompt = plugin.generate_prompt(prev_state, new_events)
            
            try:
                if progress_callback:
                    progress_callback(50, "Waiting for LLM response...")
                    
                # Expecting llm_client to have a .generate(prompt) method
                response_str = llm_client.generate(prompt)
                
                if progress_callback:
                    progress_callback(80, "Parsing response...")
                
                # Parse response
                new_state = plugin.parse_response(response_str, prev_state)
                
            except Exception as e:
                print(f"[Engine] LLM Failed: {e}")
                should_trigger = False # Fallback to clone
                if progress_callback:
                    progress_callback(50, f"LLM Failed, falling back to clone. Error: {str(e)}")

        if not should_trigger or not new_state:
            # 4. Fast Path (Clone)
            # If no previous state, we can't clone. We must initialize.
            if prev_state:
                new_state = prev_state.model_copy()
                new_state.updated_at = "now"
            else:
                # First chapter, no trigger? Then no state.
                # Actually, if it's the first chapter and no interaction, we don't need a state.
                return None

        # 5. Save & Return
        if new_state:
            # Ensure correct index
            new_state.chapter_index = target_chapter_index
            self.store.save_state(novel_hash, plugin_type, entity_id, new_state)
            
            if progress_callback:
                progress_callback(100, "State saved.")
            
        return new_state


==================== FILE: backend\narrative_engine\core\job_manager.py ====================

import time
import uuid
import threading
from typing import Dict, Any, Optional, Callable
from pydantic import BaseModel

class JobStatus(BaseModel):
    job_id: str
    type: str           # "relationship_analysis"
    status: str         # "pending", "processing", "completed", "failed"
    progress: int       # 0-100
    message: str        # "Analyzing Chapter 45/120..."
    result: Optional[Any] = None
    error: Optional[str] = None
    created_at: float
    updated_at: float

class JobManager:
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(JobManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self.jobs: Dict[str, JobStatus] = {}
        self.active_job_id: Optional[str] = None
        self._job_lock = threading.Lock()
        self._initialized = True
        
    def submit_job(self, job_type: str, metadata: Dict[str, Any] = None) -> str:
        """
        Create a new job and return its ID.
        Note: The actual processing must be triggered by the caller (e.g., BackgroundTasks).
        """
        job_id = str(uuid.uuid4())
        now = time.time()
        
        with self._job_lock:
            # Simple queue logic: If there is an active job, new ones are pending.
            # But here we just create the record. The worker logic decides when to run.
            # Since we use FastAPI BackgroundTasks, they run sequentially if we await? 
            # actually BackgroundTasks run in a threadpool. 
            # We want to enforce strict sequential execution for LLM tasks.
            
            job = JobStatus(
                job_id=job_id,
                type=job_type,
                status="pending",
                progress=0,
                message="Job submitted",
                created_at=now,
                updated_at=now
            )
            self.jobs[job_id] = job
            
        return job_id

    def get_job(self, job_id: str) -> Optional[JobStatus]:
        return self.jobs.get(job_id)
        
    def list_jobs(self, active_only: bool = False):
        if active_only:
            return [j for j in self.jobs.values() if j.status in ["pending", "processing"]]
        return list(self.jobs.values())

    def update_progress(self, job_id: str, progress: int, message: str = None):
        if job_id not in self.jobs:
            return
            
        with self._job_lock:
            job = self.jobs[job_id]
            job.progress = progress
            if message:
                job.message = message
            job.updated_at = time.time()
            
            if progress >= 100:
                job.status = "completed"
            elif job.status == "pending":
                job.status = "processing"
                
    def fail_job(self, job_id: str, error_msg: str):
        if job_id not in self.jobs:
            return
            
        with self._job_lock:
            job = self.jobs[job_id]
            job.status = "failed"
            job.error = error_msg
            job.message = f"Failed: {error_msg}"
            job.updated_at = time.time()
            
    def complete_job(self, job_id: str, result: Any = None):
        if job_id not in self.jobs:
            return
            
        with self._job_lock:
            job = self.jobs[job_id]
            job.status = "completed"
            job.progress = 100
            job.message = "Analysis complete"
            job.result = result
            job.updated_at = time.time()

# Global Singleton
job_manager = JobManager()


==================== FILE: backend\narrative_engine\core\models.py ====================

from typing import List, Optional, Dict, Any, Union
from pydantic import BaseModel, Field
from datetime import datetime

class BaseNarrativeState(BaseModel):
    """
    Abstract base state for all narrative entities (Characters, Locations, Items, Factions).
    Represents the state of an entity at a specific point in the narrative timeline.
    """
    # Meta
    entity_id: str = Field(..., description="Unique identifier for the entity or pair (e.g., 'LiXiaoyao_LinYueru')")
    chapter_index: int = Field(..., description="The end chapter index of this state block")
    version: str = Field("1.0", description="Schema version")
    updated_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    
    # Narrative Content
    summary_so_far: str = Field(..., description="LLM-generated summary of the entity's history up to this point")
    key_tags: List[str] = Field(default_factory=list, description="High-level tags (e.g., 'Rival', 'Cursed', 'Lost')")
    
    # Context for Next Analysis
    unresolved_threads: List[str] = Field(default_factory=list, description="Issues/Questions carried over to next block")

    class Config:
        extra = "allow" # Allow plugins to add custom fields if needed dynamically

class RelationshipState(BaseNarrativeState):
    """
    Specific state for a relationship between two characters.
    """
    source: str = Field(..., description="Entity A Name")
    target: str = Field(..., description="Entity B Name")
    
    # Quantitative Metrics (0-100)
    trust_level: int = Field(50, ge=0, le=100, description="Trust level (0=Betrayal, 100=Blind Faith)")
    romance_level: int = Field(0, ge=0, le=100, description="Romance level (0=Platonic, 100=Soulmates)")
    conflict_level: int = Field(0, ge=0, le=100, description="Conflict level (0=Peace, 100=War)")
    
    # Qualitative Analysis
    dominant_archetype: str = Field("Stranger", description="Primary relationship archetype (e.g., 'Enemies to Lovers')")
    current_stage: str = Field("Initial", description="Current stage description (e.g., 'The Misunderstanding')")
    
    @property
    def pair_id(self) -> str:
        """Helper to generate consistent ID for undirected pairs (lexicographically sorted)"""
        return "_".join(sorted([self.source, self.target]))

class NarrativeBlock(BaseModel):
    """
    Represents a block of analysis result.
    It contains the state snapshot and the events that led to it.
    """
    range_start: int
    range_end: int
    state: Union[RelationshipState, BaseNarrativeState]
    events_digest: List[Dict[str, Any]] = Field(default_factory=list, description="Summary of key events in this block")

class AnalysisEvent(BaseModel):
    """
    Standardized event object passed from Job System to Narrative Engine/Plugins.
    Replaces the loose dictionary structure {"chapter_index": int, "content": [str]}.
    """
    chapter_index: int = Field(..., description="The chapter where this event occurred")
    content: List[str] = Field(..., description="List of relevant sentences or interaction descriptions")
    source: Optional[str] = Field(None, description="Source entity name if applicable")
    target: Optional[str] = Field(None, description="Target entity name if applicable")
    relation_type: Optional[str] = Field(None, description="Type of interaction (e.g., 'dialogue', 'action')")


==================== FILE: backend\narrative_engine\core\store.py ====================

import json
import os
from typing import Optional, List, Type
from pathlib import Path
from backend.narrative_engine.core.models import BaseNarrativeState, RelationshipState

class StateStore:
    """
    Persistence layer for Narrative States.
    Uses a file-based JSON storage for now (simplest for incremental updates).
    """
    def __init__(self, base_path: str = "cache/narrative"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

    def _get_entity_dir(self, novel_hash: str, plugin_type: str, entity_id: str) -> Path:
        """
        Constructs the storage path: cache/narrative/{hash}/{plugin}/{entity_id}/
        """
        # Sanitize entity_id for filesystem
        safe_id = "".join([c if c.isalnum() or c in ('_', '-') else '_' for c in entity_id])
        path = self.base_path / novel_hash / plugin_type / safe_id
        path.mkdir(parents=True, exist_ok=True)
        return path

    def save_state(self, novel_hash: str, plugin_type: str, entity_id: str, state: BaseNarrativeState):
        """
        Saves a state snapshot to a JSON file.
        Filename: checkpoint_{chapter_index}.json
        """
        entity_dir = self._get_entity_dir(novel_hash, plugin_type, entity_id)
        file_path = entity_dir / f"checkpoint_{state.chapter_index}.json"
        
        with open(file_path, "w", encoding="utf-8") as f:
            # Pydantic v2 compatible dump
            f.write(state.model_dump_json(indent=2))
            
    def get_latest_state(
        self, 
        novel_hash: str, 
        plugin_type: str, 
        entity_id: str, 
        before_chapter: int,
        model_class: Type[BaseNarrativeState]
    ) -> Optional[BaseNarrativeState]:
        """
        Retrieves the latest state snapshot BEFORE a given chapter index.
        Used to provide context for analyzing chapter N.
        """
        entity_dir = self._get_entity_dir(novel_hash, plugin_type, entity_id)
        if not entity_dir.exists():
            return None
            
        # Find all checkpoints
        checkpoints = []
        for file in entity_dir.glob("checkpoint_*.json"):
            try:
                # Parse index from filename "checkpoint_123.json"
                idx = int(file.stem.split("_")[1])
                if idx < before_chapter:
                    checkpoints.append((idx, file))
            except (ValueError, IndexError):
                continue
                
        if not checkpoints:
            return None
            
        # Sort by index descending (get the latest one)
        checkpoints.sort(key=lambda x: x[0], reverse=True)
        latest_file = checkpoints[0][1]
        
        try:
            with open(latest_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return model_class(**data)
        except Exception as e:
            print(f"[StateStore] Failed to load checkpoint {latest_file}: {e}")
            return None

    def get_state_at_chapter(
        self,
        novel_hash: str,
        plugin_type: str,
        entity_id: str,
        chapter_index: int,
        model_class: Type[BaseNarrativeState]
    ) -> Optional[BaseNarrativeState]:
        """
        Retrieves the state snapshot EXACTLY AT a given chapter index.
        Used for Cache Hit check.
        """
        entity_dir = self._get_entity_dir(novel_hash, plugin_type, entity_id)
        file_path = entity_dir / f"checkpoint_{chapter_index}.json"
        
        if not file_path.exists():
            return None
            
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                return model_class(**data)
        except Exception as e:
            print(f"[StateStore] Failed to load checkpoint {file_path}: {e}")
            return None

    def list_history(
        self, 
        novel_hash: str, 
        plugin_type: str, 
        entity_id: str,
        model_class: Type[BaseNarrativeState]
    ) -> List[BaseNarrativeState]:
        """
        Returns the full history of states for an entity, sorted by chapter.
        """
        entity_dir = self._get_entity_dir(novel_hash, plugin_type, entity_id)
        if not entity_dir.exists():
            return []
            
        states = []
        for file in sorted(entity_dir.glob("checkpoint_*.json"), key=lambda f: int(f.stem.split("_")[1])):
            try:
                with open(file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    states.append(model_class(**data))
            except Exception:
                continue
        return states

    def delete_history(self, novel_hash: str, plugin_type: str, entity_id: str) -> bool:
        """
        Deletes all history for a specific entity pair.
        Returns True if successful (or directory didn't exist), False on error.
        """
        entity_dir = self._get_entity_dir(novel_hash, plugin_type, entity_id)
        if not entity_dir.exists():
            return True
            
        try:
            # Delete all files in directory
            for file in entity_dir.iterdir():
                if file.is_file():
                    file.unlink()
            
            # Remove directory
            entity_dir.rmdir()
            return True
        except Exception as e:
            print(f"[StateStore] Failed to delete history for {entity_id}: {e}")
            return False


==================== FILE: backend\narrative_engine\plugins\base.py ====================

from abc import ABC, abstractmethod
from typing import Type, List, Optional
from backend.narrative_engine.core.models import BaseNarrativeState

class NarrativePlugin(ABC):
    """
    Abstract interface for all narrative plugins (Relationship, World, Item, Faction).
    Each plugin defines how to analyze its specific type of entity.
    """
    
    @property
    @abstractmethod
    def plugin_type(self) -> str:
        """e.g. 'relationship', 'world', 'item'"""
        pass
        
    @property
    @abstractmethod
    def state_model(self) -> Type[BaseNarrativeState]:
        """Pydantic model class for the state"""
        pass
        
    @abstractmethod
    def get_initial_state(self, entity_id: str, **kwargs) -> BaseNarrativeState:
        """Returns a blank/initial state for a new entity"""
        pass
        
    @abstractmethod
    def check_trigger(self, prev_state: BaseNarrativeState, new_events: List[dict]) -> bool:
        """
        Adaptive Triggering Logic.
        Returns True if LLM analysis is needed.
        Returns False if we can skip/clone the previous state.
        """
        pass
        
    @abstractmethod
    def generate_prompt(self, prev_state: BaseNarrativeState, new_events: List[dict]) -> str:
        """Constructs the prompt for the LLM"""
        pass
        
    @abstractmethod
    def parse_response(self, llm_response: str, base_state: BaseNarrativeState) -> BaseNarrativeState:
        """Parses LLM JSON response into a State object"""
        pass


==================== FILE: backend\narrative_engine\plugins\relationship.py ====================

import json
from typing import List, Type
from backend.narrative_engine.plugins.base import NarrativePlugin
from backend.narrative_engine.core.models import BaseNarrativeState, RelationshipState, AnalysisEvent
from backend.narrative_engine.prompts import RELATIONSHIP_ANALYSIS_TEMPLATE

class RelationshipPlugin(NarrativePlugin):
    """
    Pilot Plugin: Tracks character relationship dynamics.
    """
    
    @property
    def plugin_type(self) -> str:
        return "relationship"
        
    @property
    def state_model(self) -> Type[BaseNarrativeState]:
        return RelationshipState
        
    def get_initial_state(self, entity_id: str, **kwargs) -> RelationshipState:
        source, target = entity_id.split("_")
        return RelationshipState(
            entity_id=entity_id,
            chapter_index=0,
            summary_so_far="Initial state. No interactions yet.",
            source=source,
            target=target,
            trust_level=50, # Neutral
            romance_level=0,
            conflict_level=0,
            dominant_archetype="Stranger",
            current_stage="Introduction"
        )
        
    def check_trigger(self, prev_state: RelationshipState, new_events: List[AnalysisEvent]) -> bool:
        """
        Heuristic: Trigger if there are ANY interactions in the new block.
        Future Optimization: Check for 'strong verbs' or specific keywords.
        """
        # new_events is a list of AnalysisEvent objects
        if not new_events:
            return False
            
        # Basic density check: If interaction count > 0, trigger.
        return len(new_events) > 0

    def generate_prompt(self, prev_state: RelationshipState, new_events: List[AnalysisEvent]) -> str:
        """
        Constructs the incremental analysis prompt.
        """
        # 1. Format Events Digest
        events_text = ""
        for event in new_events:
            # Handle AnalysisEvent object
            idx = event.chapter_index
            content = event.content
            
            desc = "\n  ".join(content)
            events_text += f"- Ch {idx}:\n  {desc}\n"
            
        # 2. Build Prompt using Template
        prompt = RELATIONSHIP_ANALYSIS_TEMPLATE.format(
            source=prev_state.source,
            target=prev_state.target,
            prev_chapter_index=prev_state.chapter_index,
            dominant_archetype=prev_state.dominant_archetype,
            current_stage=prev_state.current_stage,
            trust_level=prev_state.trust_level,
            romance_level=prev_state.romance_level,
            conflict_level=prev_state.conflict_level,
            summary_so_far=prev_state.summary_so_far,
            unresolved_threads=json.dumps(prev_state.unresolved_threads, ensure_ascii=False),
            events_text=events_text
        )
        return prompt

    def parse_response(self, llm_response: str, base_state: RelationshipState) -> RelationshipState:
        try:
            # Simple JSON parsing (in prod, use a robust parser/repairer)
            data = json.loads(llm_response)
            
            # Revised summary replaces the old one
            # If revised_summary is missing (legacy LLM output), fallback to append logic
            revised_summary = data.get("revised_summary")
            if not revised_summary:
                 revised_summary = base_state.summary_so_far + "\n" + data.get("summary_update", "")
            
            return RelationshipState(
                entity_id=base_state.entity_id,
                chapter_index=base_state.chapter_index, # Will be updated by engine
                summary_so_far=revised_summary,
                source=base_state.source,
                target=base_state.target,
                trust_level=data.get("trust_level", base_state.trust_level),
                romance_level=data.get("romance_level", base_state.romance_level),
                conflict_level=data.get("conflict_level", base_state.conflict_level),
                dominant_archetype=data.get("dominant_archetype", base_state.dominant_archetype),
                current_stage=data.get("current_stage", base_state.current_stage),
                unresolved_threads=data.get("new_unresolved_threads", base_state.unresolved_threads)
            )
        except Exception as e:
            print(f"[RelationshipPlugin] Parse Error: {e}")
            # Fallback: Return previous state
            return base_state


==================== FILE: backend\routers\analysis.py ====================

from typing import List, Dict, Any
from fastapi import APIRouter, HTTPException, Depends
from sqlmodel import Session, select
from core.db.engine import engine
from core.db.models import Novel, NovelVersion, AnalysisRun, Chapter, Summary, Entity, StoryRelationship
from backend.schemas import (
    ChapterPreview, ChapterDetail, EntityDetail, SummarySentence, SourceSpan,
    GraphData, GraphNode, GraphEdge, EdgeEvent, TimelineEvent, RelationshipTimelineEvent, RelationshipInteraction
)
from data_protocol.models import (
    ChapterSummary, 
    SummarySentence as ProtoSummarySentence, 
    Entity as ProtoEntity, 
    Relationship as ProtoRelationship, 
    TextSpan as ProtoTextSpan
)
from core.world_builder.aggregator import EntityAggregator

router = APIRouter(prefix="/api/novels", tags=["analysis"])

def get_session():
    with Session(engine) as session:
        yield session

def db_chapter_to_summary(db_chapter: Chapter) -> ChapterSummary:
    # Convert summaries
    summaries = []
    for s in db_chapter.summaries:
        spans = []
        if s.span_start is not None and s.span_end is not None:
             spans.append(ProtoTextSpan(text="", start_index=s.span_start, end_index=s.span_end))
        
        summaries.append(ProtoSummarySentence(
            summary_text=s.text,
            source_spans=spans
        ))
    
    # Convert entities
    entities = []
    for e in db_chapter.entities:
        entities.append(ProtoEntity(
            name=e.name,
            type=e.type,
            description=e.description or "",
            confidence=1.0 
        ))

    # Convert relationships
    rels = []
    for r in db_chapter.relationships:
        rels.append(ProtoRelationship(
            source=r.source,
            target=r.target,
            relation=r.relation,
            description=r.description or "",
            confidence=1.0
        ))
    
    return ChapterSummary(
        chapter_id=str(db_chapter.id),
        chapter_title=db_chapter.title,
        headline=db_chapter.headline,
        summary_sentences=summaries,
        entities=entities,
        relationships=rels
    )

def get_merged_chapters(session: Session, novel_name: str, file_hash: str) -> List[Chapter]:
    """
    Best Effort Merge: Fetch all runs for this version and merge chapters.
    Later runs overwrite earlier ones for the same chapter index.
    """
    # 1. Find the version
    statement = select(NovelVersion).join(Novel).where(
        Novel.name == novel_name,
        NovelVersion.hash == file_hash
    )
    version = session.exec(statement).first()
    if not version:
        raise HTTPException(status_code=404, detail="Novel version not found")
    
    # 2. Get all runs sorted by timestamp (oldest first)
    # We want newer runs to overwrite older ones
    runs = sorted(version.runs, key=lambda r: r.timestamp)
    
    merged_map: Dict[int, Chapter] = {}
    
    for run in runs:
        for chapter in run.chapters:
            merged_map[chapter.chapter_index] = chapter
            
    # 3. Return sorted list
    return [merged_map[idx] for idx in sorted(merged_map.keys())]

@router.get("/{novel_name}/{file_hash}/{timestamp}/chapters", response_model=List[ChapterPreview])
def list_chapters(novel_name: str, file_hash: str, timestamp: str, session: Session = Depends(get_session)):
    # Note: We ignore the specific timestamp for listing chapters, 
    # instead returning the merged result of all runs for this hash.
    # This implements the "Best Effort Merge" logic.
    chapters = get_merged_chapters(session, novel_name, file_hash)
    
    return [
        ChapterPreview(
            id=str(c.id),
            title=c.title,
            headline=c.headline or "",
            has_summary=True
        )
        for c in chapters
    ]

@router.get("/{novel_name}/{file_hash}/{timestamp}/chapters/{chapter_id}", response_model=ChapterDetail)
def get_chapter_detail(novel_name: str, file_hash: str, timestamp: str, chapter_id: str, session: Session = Depends(get_session)):
    try:
        db_id = int(chapter_id)
        chapter = session.get(Chapter, db_id)
    except:
        raise HTTPException(status_code=404, detail="Invalid chapter ID")
        
    if not chapter:
         raise HTTPException(status_code=404, detail="Chapter not found")
         
    summary = db_chapter_to_summary(chapter)
    
    # Convert Proto models to Schema models
    summary_sentences = [
        SummarySentence(
            summary_text=s.summary_text,
            source_spans=[SourceSpan(**span.dict()) for span in s.source_spans]
        )
        for s in summary.summary_sentences
    ]
    
    entities = [
        EntityDetail(
            name=e.name,
            type=e.type,
            description=e.description,
            confidence=e.confidence or 1.0
        )
        for e in summary.entities
    ]
    
    return ChapterDetail(
        id=str(chapter.id),
        title=chapter.title,
        headline=chapter.headline,
        content=chapter.content or "",
        summary_sentences=summary_sentences,
        entities=entities
    )

@router.get("/{novel_name}/{file_hash}/{timestamp}/entities", response_model=List[GraphNode])
def list_entities(novel_name: str, file_hash: str, timestamp: str, session: Session = Depends(get_session)):
    # Use merged chapters for aggregation
    chapters = get_merged_chapters(session, novel_name, file_hash)
    
    # Aggregate
    summaries = [db_chapter_to_summary(c) for c in chapters]
    
    aggregator = EntityAggregator()
    aggregated_entities = aggregator.aggregate_entities(summaries)
    
    return [
        GraphNode(
            name=e.name,
            type=e.type,
            description=e.description,
            count=e.count,
            chapter_ids=e.chapter_ids,
            history=e.history
        )
        for e in aggregated_entities
    ]

@router.get("/{novel_name}/{file_hash}/{timestamp}/graph", response_model=GraphData)
def get_graph_data(novel_name: str, file_hash: str, timestamp: str, session: Session = Depends(get_session)):
    chapters = get_merged_chapters(session, novel_name, file_hash)
    summaries = [db_chapter_to_summary(c) for c in chapters]
    
    aggregator = EntityAggregator()
    entities = aggregator.aggregate_entities(summaries)
    relationships = aggregator.aggregate_relationships(summaries)
    
    # Pre-calculate chapter ID to index map for sorting
    # This ensures that 'chapter_ids' list in GraphNode is sorted by logical order, not just string order
    chap_id_to_index = {str(c.id).strip(): c.chapter_index for c in chapters}
    
    nodes = []
    for e in entities:
        # Sort chapter IDs by index
        # Ensure x is stripped string before lookup
        sorted_chapter_ids = sorted(e.chapter_ids, key=lambda x: chap_id_to_index.get(str(x).strip(), 999999))
        
        nodes.append(GraphNode(
            name=e.name,
            type=e.type,
            description=e.description,
            count=e.count,
            chapter_ids=sorted_chapter_ids,
            history=e.history
        ))
    
    edges = []
    for r in relationships:
        timeline_events = [
            EdgeEvent(
                chapter_id=str(item['chapter_id']).strip(),
                relation=item.get('relation'),
                description=item.get('description'),
                order=item.get('order', 0),
                weight=1 # Default weight per event
            )
            for item in r.timeline
        ]
        
        # Sort edge events by chapter index as well
        timeline_events.sort(key=lambda x: chap_id_to_index.get(x.chapter_id, 999999))
        
        edges.append(GraphEdge(
            source=r.source,
            target=r.target,
            weight=r.weight,
            timeline=timeline_events
        ))
    
    return GraphData(nodes=nodes, edges=edges)

@router.get("/{novel_name}/{file_hash}/{timestamp}/entity/{entity_name}/timeline", response_model=List[TimelineEvent])
def get_entity_timeline(novel_name: str, file_hash: str, timestamp: str, entity_name: str, session: Session = Depends(get_session)):
    """
    Get the chronological timeline of events for a specific entity.
    """
    chapters = get_merged_chapters(session, novel_name, file_hash)
    timeline_events = []
    
    aggregator = EntityAggregator()
    # Normalize input name for matching
    normalized_target_name = aggregator._normalize_text(entity_name)
    
    last_chapter_idx = -1
    
    for chapter in chapters:
        summary = db_chapter_to_summary(chapter)
        relevant_sentences = []
        entity_in_chapter = False
        
        # 1. Check explicit entities list (Strong Match)
        for e in summary.entities:
            if aggregator._normalize_text(e.name) == normalized_target_name:
                entity_in_chapter = True
                break
        
        # 2. Check sentences for mentions (Contextual Match)
        for sent in summary.summary_sentences:
            if normalized_target_name in sent.summary_text or entity_name in sent.summary_text:
                relevant_sentences.append(sent.summary_text)
                entity_in_chapter = True
        
        if entity_in_chapter:
            # Calculate gap (number of chapters skipped)
            gap = 0
            if last_chapter_idx != -1:
                gap = chapter.chapter_index - last_chapter_idx - 1
            
            # Use found sentences or fallback to entity description if available
            content = relevant_sentences
            if not content:
                # Try to find entity description
                for e in summary.entities:
                    if aggregator._normalize_text(e.name) == normalized_target_name and e.description:
                        content.append(e.description)
                        break
            
            timeline_events.append(TimelineEvent(
                chapter_id=str(chapter.id),
                chapter_index=chapter.chapter_index,
                chapter_title=chapter.title,
                content=content if content else ["本章提及该实体。"],
                gap_before=max(0, gap)
            ))
            
            last_chapter_idx = chapter.chapter_index
            
    return timeline_events

from backend.narrative_engine.core.store import StateStore
from backend.narrative_engine.core.engine import NarrativeEvolutionEngine
from backend.narrative_engine.plugins.relationship import RelationshipPlugin
from backend.narrative_engine.core.models import RelationshipState

# Initialize Narrative Engine (Lazy Singleton)
# In a real app, use dependency injection or app state
_state_store = StateStore()
_narrative_engine = NarrativeEvolutionEngine(_state_store)
_narrative_engine.register_plugin(RelationshipPlugin())

@router.delete("/{novel_name}/{file_hash}/relationship", status_code=204)
def delete_relationship_cache(
    novel_name: str, 
    file_hash: str, 
    source: str, 
    target: str, 
    session: Session = Depends(get_session)
):
    """
    Delete cached relationship analysis for a specific pair.
    """
    aggregator = EntityAggregator()
    norm_source = aggregator._normalize_text(source)
    norm_target = aggregator._normalize_text(target)
    
    if not norm_source or not norm_target:
        raise HTTPException(status_code=400, detail="Invalid source or target entities")
    
    pair_id = "_".join(sorted([norm_source, norm_target]))
    
    # Delegate to StateStore
    success = _state_store.delete_history(file_hash, "relationship", pair_id)
    
    if not success:
        # It's fine if it doesn't exist, but if deletion failed due to error, we might log it.
        # delete_history returns False if directory doesn't exist.
        pass
        
    return None

@router.get("/{novel_name}/{file_hash}/{timestamp}/relationship", response_model=List[RelationshipTimelineEvent])
def get_relationship_timeline( 
    timestamp: str, 
    source: str, 
    target: str, 
    session: Session = Depends(get_session)
):
    """
    Get the interaction timeline between two entities (bidirectional).
    Returns a list of interactions where Source->Target OR Target->Source.
    Also returns the Narrative State (Trust, Romance, etc.) if available.
    """
    chapters = get_merged_chapters(session, novel_name, file_hash)
    timeline_events = []
    
    aggregator = EntityAggregator()
    norm_source = aggregator._normalize_text(source)
    norm_target = aggregator._normalize_text(target)
    
    if not norm_source or not norm_target:
        return []
    
    # Sort pair ID for consistent state lookup
    pair_id = "_".join(sorted([norm_source, norm_target]))
    
    # Pre-fetch states for all chapters (Optimization: List history once)
    # But for now, we just want to attach the state to the event.
    # Actually, we should evolve the state chapter by chapter here if we wanted real-time analysis.
    # But as per plan, we lazy load or just check if state exists.
    
    # To keep response fast, we WON'T trigger LLM here. 
    # We only read what's in the cache.
    # If the user wants to trigger analysis, they should call a POST endpoint (future).
    # OR: We trigger it but with a timeout/background task? 
    # Let's stick to "Read Only" for GET request to avoid blocking.
    
    # Optimization: Load all history for this pair once
    history = _state_store.list_history(file_hash, "relationship", pair_id, RelationshipState)
    state_map = {s.chapter_index: s for s in history}
    
    current_state = None
    
    for chapter in chapters:
        summary = db_chapter_to_summary(chapter)
        
        interactions = []
        
        for rel in summary.relationships:
            r_source = aggregator._normalize_text(rel.source)
            r_target = aggregator._normalize_text(rel.target)
            
            # Direction 1: A -> B
            if r_source == norm_source and r_target == norm_target:
                interactions.append(RelationshipInteraction(
                    direction="forward", 
                    relation=rel.relation,
                    description=rel.description,
                    confidence=rel.confidence
                ))
            
            # Direction 2: B -> A
            elif r_source == norm_target and r_target == norm_source:
                interactions.append(RelationshipInteraction(
                    direction="backward",
                    relation=rel.relation,
                    description=rel.description,
                    confidence=rel.confidence
                ))
        
        # Check if we have a narrative state for this chapter (or carried over)
        # In a perfect world, we'd have a state for every chapter.
        # Here we look for exact match or closest previous?
        # Let's check exact match first.
        narrative_state_dict = None
        if chapter.chapter_index in state_map:
            current_state = state_map[chapter.chapter_index]
        
        # If we have interactions OR a state update, we add an event
        narrative_state_dict = None
        if current_state and current_state.chapter_index == chapter.chapter_index:
             # We dump the state to dict
             narrative_state_dict = current_state.model_dump()

        # Filter: Only show chapters with actual interactions or significant state changes.
        if interactions or narrative_state_dict:
            timeline_events.append(RelationshipTimelineEvent(
                chapter_id=str(chapter.id),
                chapter_index=chapter.chapter_index,
                chapter_title=chapter.title,
                interactions=interactions,
                narrative_state=narrative_state_dict
            ))
            
    return timeline_events


==================== FILE: backend\routers\jobs.py ====================

import asyncio
from typing import List, Optional, Dict
import os
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from pydantic import BaseModel

from backend.narrative_engine.core.job_manager import job_manager, JobStatus
from backend.routers.analysis import get_session, get_merged_chapters, db_chapter_to_summary, _narrative_engine
from backend.narrative_engine.core.models import AnalysisEvent
from core.world_builder.aggregator import EntityAggregator
from core.summarizer.llm_client import ClientFactory
from core.config import settings
from sqlmodel import Session

router = APIRouter(prefix="/api/jobs", tags=["jobs"])

class RelationshipJobRequest(BaseModel):
    novel_name: str
    file_hash: str
    source: str
    target: str
    force: bool = False

def run_relationship_analysis_task(job_id: str, request: RelationshipJobRequest):
    """
    Background task to run the relationship analysis.
    """
    try:
        # 1. Update status to processing
        job_manager.update_progress(job_id, 0, "Initializing analysis...")
        
        # 2. Setup Context (Need a new session for background task?)
        # Actually we need DB access. We can create a new session here.
        from core.db.engine import engine
        
        with Session(engine) as session:
            # 3. Load Chapters
            job_manager.update_progress(job_id, 5, "Loading chapters...")
            chapters = get_merged_chapters(session, request.novel_name, request.file_hash)
            
            if not chapters:
                job_manager.fail_job(job_id, "No chapters found")
                return

            # 4. Setup LLM Client
            # config = load_config()  <-- Deprecated
            
            # Prefer OpenRouter for analysis
            # We want to force OpenRouter if possible, or use config
            # User said: "All future calls default to OpenRouter"
            
            provider = "openrouter"
            # Try to get key from settings or env
            api_key = settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
            
            if not api_key:
                 job_manager.fail_job(job_id, "OpenRouter API Key not found. Please set OPENROUTER_API_KEY env var.")
                 return

            llm_client = ClientFactory.create_client(
                provider="openrouter",
                api_key=api_key,
                model=settings.OPENROUTER_MODEL or "google/gemini-2.0-flash-001" # Default model
            )
            
            # 5. Normalize Names
            # Explicitly load aliases from project root
            base_dir = os.getcwd()
            alias_path = os.path.join(base_dir, "config", "aliases.json")
            aggregator = EntityAggregator(alias_file=alias_path)
            
            norm_source = aggregator._normalize_text(request.source)
            norm_target = aggregator._normalize_text(request.target)
            pair_id = "_".join(sorted([norm_source, norm_target]))
            
            total_chapters = len(chapters)
            
            # 6. Iterate and Evolve
            for i, chapter in enumerate(chapters):
                progress_base = 10 + int((i / total_chapters) * 80)
                job_manager.update_progress(job_id, progress_base, f"Analyzing Chapter {chapter.chapter_index}...")
                
                # Prepare events
                summary = db_chapter_to_summary(chapter)
                
                # Filter relevant events
                relevant_sentences = []
                # Check explicit relationships
                for rel in summary.relationships:
                    r_s = aggregator._normalize_text(rel.source)
                    r_t = aggregator._normalize_text(rel.target)
                    if (r_s == norm_source and r_t == norm_target) or (r_s == norm_target and r_t == norm_source):
                        relevant_sentences.append(f"Interaction ({rel.relation}): {rel.description}")
                
                # Check text mentions
                for sent in summary.summary_sentences:
                    if (norm_source in sent.summary_text and norm_target in sent.summary_text):
                         relevant_sentences.append(sent.summary_text)

                # Check entity co-occurrence (Weak Interaction)
                source_in_chapter = False
                target_in_chapter = False
                for e in summary.entities:
                    norm_name = aggregator._normalize_text(e.name)
                    if norm_name == norm_source: source_in_chapter = True
                    if norm_name == norm_target: target_in_chapter = True
                
                if not relevant_sentences and source_in_chapter and target_in_chapter:
                    relevant_sentences.append("Both characters appear in this chapter, implying potential implicit interaction or co-presence.")

                if not relevant_sentences:
                    # Skip empty chapters to save time/cost, unless we want to decay relationship?
                    # For now, just skip.
                    continue
                    
                # Prepare event object
                new_events = [AnalysisEvent(
                    chapter_index=chapter.chapter_index,
                    content=relevant_sentences
                )]
                
                # Define callback for sub-steps (LLM generation)
                def step_callback(step_progress, msg):
                    # Map step_progress (0-100) to a small range within the chapter progress
                    # e.g., current chapter takes 5% of total progress
                    # We don't want to spam updates, so maybe just update message
                    # job_manager.update_progress(job_id, progress_base, f"Ch {chapter.chapter_index}: {msg}")
                    pass

                # Evolve State
                # Add try/except for evolution to not crash whole job
                try:
                    _narrative_engine.evolve_state(
                        novel_hash=request.file_hash,
                        plugin_type="relationship",
                        entity_id=pair_id,
                        target_chapter_index=chapter.chapter_index,
                        new_events=new_events,
                        llm_client=llm_client,
                        progress_callback=step_callback
                    )
                except Exception as evo_err:
                     print(f"Error evolving state for Ch {chapter.chapter_index}: {evo_err}")
                     # Continue to next chapter

            
            # 7. Finish
            job_manager.complete_job(job_id, {"pair_id": pair_id, "chapters_analyzed": total_chapters})
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        job_manager.fail_job(job_id, str(e))

@router.post("/relationship", response_model=Dict[str, str])
def submit_relationship_job(request: RelationshipJobRequest, background_tasks: BackgroundTasks):
    """
    Submit a background job to analyze relationship arc.
    """
    # Check for existing active jobs? 
    # For now, we allow multiple, but JobManager doesn't limit concurrency yet.
    # The design spec said "limit to 1 concurrent".
    # We can check JobManager here.
    active_jobs = job_manager.list_jobs(active_only=True)
    if len(active_jobs) > 0:
        # Optional: Reject or Queue.
        # For simple UX, let's reject with 429 or similar?
        # Or just let it run if user really wants.
        # Let's just warn in logs but allow it for v1.
        pass

    job_id = job_manager.submit_job("relationship_analysis")
    
    background_tasks.add_task(run_relationship_analysis_task, job_id, request)
    
    return {"job_id": job_id}

@router.get("/{job_id}", response_model=JobStatus)
def get_job_status(job_id: str):
    job = job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    return job

@router.get("/", response_model=List[JobStatus])
def list_jobs(active_only: bool = False):
    return job_manager.list_jobs(active_only)


==================== FILE: backend\routers\novels.py ====================

from typing import List, Optional
from fastapi import APIRouter, HTTPException, Depends
from sqlmodel import Session, select
from core.db.engine import engine
from core.db.models import Novel, NovelVersion, AnalysisRun
from backend.schemas import NovelInfo, RunInfo
import json

router = APIRouter(prefix="/api/novels", tags=["novels"])

def get_session():
    with Session(engine) as session:
        yield session

@router.get("", response_model=List[NovelInfo])
def list_novels(session: Session = Depends(get_session)):
    novels = session.exec(select(Novel)).all()
    results = []
    for n in novels:
        hashes = [v.hash for v in n.versions]
        results.append(NovelInfo(name=n.name, hashes=hashes))
    return results

@router.get("/{novel_name}/{file_hash}/runs", response_model=List[RunInfo])
def list_runs(novel_name: str, file_hash: str, session: Session = Depends(get_session)):
    # Find version
    statement = select(NovelVersion).join(Novel).where(Novel.name == novel_name).where(NovelVersion.hash == file_hash)
    version = session.exec(statement).first()
    
    if not version:
        raise HTTPException(status_code=404, detail="Novel version not found")
    
    runs = []
    for run in version.runs:
        metadata = {}
        if run.config_snapshot:
            try:
                metadata = json.loads(run.config_snapshot)
            except:
                pass
        runs.append(RunInfo(timestamp=run.timestamp, metadata=metadata))
    
    # Sort descending
    runs.sort(key=lambda x: x.timestamp, reverse=True)
    return runs


==================== FILE: config\aliases.json ====================

{
    "机器人": "塔派",
    "宋6": "宋6PUS"
}

==================== FILE: core\__init__.py ====================




==================== FILE: core\cache_manager.py ====================

import os
import json
import hashlib
from typing import Dict, Optional, List
from data_protocol.models import ChapterSummary

class CacheManager:
    """
    负责章节级别的缓存管理。
    缓存键 (Key) 由以下因素决定：
    1. 章节内容哈希 (Content Hash)
    2. Prompt 哈希 (Prompt Hash)
    3. 模型配置哈希 (Model Config Hash)
    """

    def __init__(self, cache_dir: str):
        self.cache_dir = cache_dir
        os.makedirs(self.cache_dir, exist_ok=True)

    def _calculate_key(self, content: str, prompt_hash: str, model_config: Dict) -> str:
        """计算缓存唯一键"""
        # 1. Content Hash
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()
        
        # 2. Model Config Hash (ensure consistent ordering)
        config_str = json.dumps(model_config, sort_keys=True)
        config_hash = hashlib.md5(config_str.encode('utf-8')).hexdigest()

        # Combine
        combined = f"{content_hash}_{prompt_hash}_{config_hash}"
        return hashlib.md5(combined.encode('utf-8')).hexdigest()

    def get_cached_summary(self, content: str, prompt_hash: str, model_config: Dict) -> Optional[ChapterSummary]:
        """尝试获取缓存的总结"""
        key = self._calculate_key(content, prompt_hash, model_config)
        cache_path = os.path.join(self.cache_dir, f"{key}.json")
        
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return ChapterSummary(**data)
            except Exception as e:
                print(f"[Cache] Error reading cache {key}: {e}")
                return None
        return None

    def save_summary(self, content: str, prompt_hash: str, model_config: Dict, summary: ChapterSummary):
        """保存总结到缓存"""
        key = self._calculate_key(content, prompt_hash, model_config)
        cache_path = os.path.join(self.cache_dir, f"{key}.json")
        
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                # model_dump is Pydantic v2, dict() is v1. Use model_dump if available.
                data = summary.model_dump() if hasattr(summary, 'model_dump') else summary.dict()
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[Cache] Error writing cache {key}: {e}")


==================== FILE: core\config.py ====================

import os
from pathlib import Path
from typing import Optional
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field

class Settings(BaseSettings):
    # Application Paths
    BASE_DIR: Path = Field(default_factory=lambda: Path(__file__).resolve().parent.parent)
    OUTPUT_DIR: Path = Field(default_factory=lambda: Path(__file__).resolve().parent.parent / "output")
    INPUTS_DIR: Path = Field(default_factory=lambda: Path(__file__).resolve().parent.parent / "inputs")
    
    # Database
    DATABASE_URL: str = "sqlite:///storytrace.db"
    
    # Server
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 8000
    
    # LLM - OpenRouter
    OPENROUTER_API_KEY: Optional[str] = None
    OPENROUTER_MODEL: str = "google/gemini-2.0-flash-001"
    
    # LLM - Local
    LOCAL_LLM_BASE_URL: str = "http://localhost:11434/v1"
    LOCAL_LLM_MODEL: str = "qwen2.5:14b"
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore" # Ignore extra env vars
    )

    @property
    def database_path(self) -> str:
        """Resolve database path relative to BASE_DIR if it's a relative sqlite path"""
        if self.DATABASE_URL.startswith("sqlite:///"):
            db_path = self.DATABASE_URL.replace("sqlite:///", "")
            if not os.path.isabs(db_path):
                return f"sqlite:///{self.BASE_DIR / db_path}"
        return self.DATABASE_URL

settings = Settings()


==================== FILE: core\identifiers.py ====================

import re
from typing import Optional

class IdentifierGenerator:
    """
    负责全项目统一的 ID 生成逻辑。
    确保 Splitter 生成的 ID 和数据库迁移时解析的 ID 一致。
    """

    @staticmethod
    def generate_chapter_id(index: int, prefix: str = "ch") -> str:
        """
        生成标准章节 ID。
        格式: {prefix}_{index}
        例如: ch_1, vol_1_ch_5
        
        Args:
            index: 1-based index
            prefix: 前缀，默认为 'ch'
        """
        return f"{prefix}_{index}"

    @staticmethod
    def parse_chapter_index(chapter_id: str) -> Optional[int]:
        """
        从 ID 中解析出数字索引。
        例如: "ch_42" -> 42, "vol_1_ch_5" -> 5
        """
        if not chapter_id:
            return None
            
        # 尝试匹配最后的数字部分
        # 匹配 _(\d+)$
        match = re.search(r'_(\d+)$', chapter_id)
        if match:
            return int(match.group(1))
            
        return None

    @staticmethod
    def generate_volume_id(index: int) -> str:
        """生成分卷 ID"""
        return f"vol_{index}"
    
    @staticmethod
    def generate_batch_id(start: int, end: int) -> str:
        """生成批次 ID"""
        return f"batch_{start}_{end}"


==================== FILE: core\paths.py ====================

import os
from pathlib import Path
from core.config import settings

class PathManager:
    """
    统一管理文件系统路径结构。
    """
    
    @staticmethod
    def get_output_root() -> Path:
        """获取输出根目录"""
        return settings.OUTPUT_DIR

    @staticmethod
    def get_novel_root(novel_name: str, file_hash: str) -> Path:
        """output/novel_name/hash/"""
        return PathManager.get_output_root() / novel_name / file_hash

    @staticmethod
    def get_run_dir(novel_name: str, file_hash: str, timestamp: str) -> Path:
        """output/novel_name/hash/timestamp/"""
        return PathManager.get_novel_root(novel_name, file_hash) / timestamp

    @staticmethod
    def get_cache_dir() -> Path:
        """output/.cache/"""
        return PathManager.get_output_root() / ".cache"
        
    @staticmethod
    def get_chapter_file_path(output_dir: Path, title: str, volume_title: str = None) -> Path:
        """
        根据章节信息生成文件路径。
        如果有 volume_title，则创建子目录。
        """
        # 清理非法字符
        clean_title = "".join([c for c in title if c not in r'\/:*?"<>|'])
        
        if volume_title:
            clean_vol = "".join([c for c in volume_title if c not in r'\/:*?"<>|'])
            return output_dir / clean_vol / f"{clean_title}.txt"
        else:
            return output_dir / f"{clean_title}.txt"


==================== FILE: core\utils.py ====================

import re
import hashlib
import cn2an

def calculate_file_hash(file_path: str, algorithm: str = 'md5') -> str:
    """
    计算文件的哈希值。
    
    :param file_path: 文件路径
    :param algorithm: 哈希算法 ('md5', 'sha1', 'sha256' 等)
    :return: 十六进制哈希字符串
    """
    hash_obj = hashlib.new(algorithm)
    # 分块读取文件以支持大文件
    try:
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_obj.update(chunk)
        return hash_obj.hexdigest()
    except FileNotFoundError:
        return "unknown_hash"

def extract_line_by_match(match, content, match_type):
    """
    根据正则匹配结果提取整行内容，并将中文数字转换为阿拉伯数字。
    
    :param match: re.Match 对象
    :param content: 完整文本内容
    :param match_type: 匹配类型，支持 "卷" 或 "章"
    :return: 处理后的标题行内容（包含阿拉伯数字）
    """
    # 获取匹配内容所在的行的起始和结束位置
    start_index = match.start()
    end_index = match.end()
    
    # 找到当前行的起始位置（上一个换行符之后）和结束位置（下一个换行符之前）
    line_start = content.rfind("\n", 0, start_index) + 1
    line_end = content.find("\n", end_index)
    
    # 如果找不到换行符，说明是在最后一行
    if line_end == -1:
        line_end = len(content)
    
    # 提取整行内容
    line_content = content[line_start:line_end].strip()
    
    # 提取数字部分并转化为阿拉伯数字
    num_match = None
    if match_type == "卷":
        num_match = re.search(r'第([零一二三四五六七八九十百千万\d]+)卷', line_content)
    elif match_type == "章":
        num_match = re.search(r'第([零一二三四五六七八九十百千万\d]+)章', line_content)
    
    if num_match:
        chinese_num = num_match.group(1)
        try:
            # 尝试转换中文数字为阿拉伯数字
            arabic_num = cn2an.cn2an(chinese_num)
            line_content = line_content.replace(chinese_num, str(arabic_num))
        except ValueError:
            # 如果转换失败（例如混合数字），则保留原样或进行部分处理
            pass

    return line_content


==================== FILE: core\db\__init__.py ====================



==================== FILE: core\db\engine.py ====================

from sqlmodel import create_engine, SQLModel
from core.config import settings

engine = create_engine(settings.database_path, echo=False)

def create_db_and_tables():
    SQLModel.metadata.create_all(engine)


==================== FILE: core\db\models.py ====================

from typing import List, Optional
from sqlmodel import Field, Relationship, SQLModel

class Novel(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    name: str = Field(index=True, unique=True)
    
    versions: List["NovelVersion"] = Relationship(back_populates="novel")

class NovelVersion(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    novel_id: int = Field(foreign_key="novel.id")
    hash: str = Field(index=True)
    
    novel: Novel = Relationship(back_populates="versions")
    runs: List["AnalysisRun"] = Relationship(back_populates="version")

class AnalysisRun(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    version_id: int = Field(foreign_key="novelversion.id")
    timestamp: str = Field(index=True)
    config_snapshot: Optional[str] = None
    
    version: NovelVersion = Relationship(back_populates="runs")
    chapters: List["Chapter"] = Relationship(back_populates="run")

class Chapter(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    run_id: int = Field(foreign_key="analysisrun.id")
    chapter_index: int
    title: str
    headline: Optional[str] = None
    content: Optional[str] = None
    
    run: AnalysisRun = Relationship(back_populates="chapters")
    summaries: List["Summary"] = Relationship(back_populates="chapter")
    entities: List["Entity"] = Relationship(back_populates="chapter")
    relationships: List["StoryRelationship"] = Relationship(back_populates="chapter")

class Summary(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    chapter_id: int = Field(foreign_key="chapter.id")
    text: str
    span_start: Optional[int] = None
    span_end: Optional[int] = None
    
    chapter: Chapter = Relationship(back_populates="summaries")

class Entity(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    chapter_id: int = Field(foreign_key="chapter.id")
    name: str
    type: str
    description: Optional[str] = None
    count: int = 1
    
    chapter: Chapter = Relationship(back_populates="entities")

class StoryRelationship(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    chapter_id: int = Field(foreign_key="chapter.id")
    source: str
    target: str
    relation: str
    description: Optional[str] = None
    weight: int = 1
    
    chapter: Chapter = Relationship(back_populates="relationships")


==================== FILE: core\splitter\__init__.py ====================




==================== FILE: core\splitter\processor.py ====================

import re
import os
from typing import List, Tuple, Optional
from data_protocol.models import Chapter, BookStructure
from core.utils import extract_line_by_match

from core.identifiers import IdentifierGenerator

class Splitter:
    """
    核心分割器类，负责将文本分割为章节对象。
    """
    def __init__(self, encoding: str = 'utf-8'):
        self.encoding = encoding

    def read_file(self, file_path: str) -> str:
        """读取文件内容，尝试多种编码"""
        encodings_to_try = [self.encoding]
        
        # 添加常见备选编码
        common_encodings = ['utf-8', 'utf-8-sig', 'gb18030', 'gbk', 'big5']
        for enc in common_encodings:
            if enc.lower() != self.encoding.lower():
                encodings_to_try.append(enc)
        
        # 去重
        seen = set()
        final_encodings = []
        for enc in encodings_to_try:
            if enc not in seen:
                final_encodings.append(enc)
                seen.add(enc)

        for enc in final_encodings:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    content = f.read()
                    print(f"成功使用编码读取文件: {enc}")
                    self.encoding = enc # 更新为实际有效的编码
                    return content
            except UnicodeDecodeError:
                continue
            except FileNotFoundError:
                raise FileNotFoundError(f"文件 {file_path} 不存在。")
            except Exception:
                continue
        
        # 如果所有尝试都失败
        raise ValueError(f"无法读取文件 {file_path}，已尝试编码: {', '.join(final_encodings)}。请检查文件是否损坏。")

    def scan_chapters(self, content: str) -> Tuple[int, List[str], bool]:
        """
        快速扫描章节结构
        Returns:
            total_count: 总章节数
            titles: 章节标题列表
            is_continuous: 是否检测到连续的数字编号 (1, 2, 3...)
        """
        # 支持繁体中文数字和异体字
        cn_nums = '零一二三四五六七八九十百千万壹贰叁肆伍陆柒捌玖拾佰仟萬億'
        # 匹配 "第xxx章" 或 "Chapter xxx"
        chapter_pattern = fr'(?:^第[{cn_nums}\d]+[章回節节])|(?:^Chapter\s+\d+)'
        
        matches = list(re.finditer(chapter_pattern, content, re.MULTILINE | re.IGNORECASE))
        
        titles = []
        for match in matches:
            line_start = match.start()
            line_end = content.find('\n', line_start)
            if line_end == -1: line_end = len(content)
            titles.append(content[line_start:line_end].strip())
            
        total = len(titles)
        if total == 0:
            return 0, [], False
            
        # Check continuity (heuristic)
        # Try to extract numbers from first few chapters
        is_continuous = True
        # (Simple check: if we found chapters, we assume structure exists. 
        #  Strict continuity check is hard due to "第十章" vs "第10章" mixing)
        
        return total, titles, is_continuous

    def split_by_chapter(self, content: str, chapter_range: Optional[Tuple[int, int]] = None) -> List[Chapter]:
        """
        按章节分割
        Args:
            content: 文本内容
            chapter_range: (start, end) 闭区间，从1开始计数。例如 (1, 10) 表示第1到第10章。
        """
        # 支持繁体中文数字和异体字
        cn_nums = '零一二三四五六七八九十百千万壹贰叁肆伍陆柒捌玖拾佰仟萬億'
        chapter_pattern = fr'(?:^第[{cn_nums}\d]+[章回節节])|(?:^Chapter\s+\d+)'
        
        print(f"DEBUG: 正在使用正则匹配章节: {chapter_pattern[:50]}...")
        matches = list(re.finditer(chapter_pattern, content, re.MULTILINE | re.IGNORECASE))
        print(f"DEBUG: 匹配到 {len(matches)} 个潜在章节标题。")
        
        if not matches:
            return []

        # Apply Range Filtering
        start_idx = 0
        end_idx = len(matches)
        
        if chapter_range:
            r_start, r_end = chapter_range
            print(f"DEBUG: 应用范围过滤: {r_start}-{r_end}")
            # Adjust 1-based index to 0-based
            start_idx = max(0, r_start - 1)
            end_idx = min(len(matches), r_end)
            
            print(f"DEBUG: 转换索引: [{start_idx}:{end_idx}]")
            
            if start_idx >= len(matches):
                print(f"DEBUG: 起始索引 {start_idx} 超出范围 (总数 {len(matches)})")
                return []
                
        # Filter matches
        target_matches = matches[start_idx : end_idx]
        if not target_matches:
            print("DEBUG: 过滤后章节列表为空。")
            return []
            
        print(f"DEBUG: 最终将处理 {len(target_matches)} 章。")

        chapters = []
        # We need to handle the content extraction carefully because we might be skipping chapters.
        # For the last selected chapter, its content goes until the NEXT chapter in the original list starts.
        
        for i, match in enumerate(target_matches):
            # Original index in 'matches' list
            original_idx = start_idx + i
            
            # Get Title
            line_start = match.start()
            line_end = content.find('\n', line_start)
            if line_end == -1: line_end = len(content)
            title_line = content[line_start:line_end].strip()
            
            # Get Content
            content_start = line_end
            
            # Find end of content: start of the NEXT chapter in the ORIGINAL list
            if original_idx < len(matches) - 1:
                content_end = matches[original_idx + 1].start()
            else:
                content_end = len(content)
                
            chapter_content = content[content_start:content_end].strip()
            
            chapters.append(Chapter(
                id=IdentifierGenerator.generate_chapter_id(original_idx + 1),
                title=title_line,
                content=chapter_content,
                word_count=len(chapter_content)
            ))
            
        return chapters

    def split_by_volume(self, content: str, volume_pattern: str = None) -> List[Chapter]:
        """按卷分割，卷内再分章"""
        # 如果未提供 pattern，使用默认增强版
        if not volume_pattern:
            cn_nums = '零一二三四五六七八九十百千万壹贰叁肆伍陆柒捌玖拾佰仟萬億'
            volume_pattern = fr'^[第卷{cn_nums}\d]+[卷巻]'
            
        matches = list(re.finditer(volume_pattern, content, re.MULTILINE))
        
        if not matches:
            # 如果没有分卷，尝试直接分章
            return self.split_by_chapter(content)

        all_chapters = []
        for i, match in enumerate(matches):
            # 获取卷标题行
            line_start = match.start()
            line_end = content.find('\n', line_start)
            if line_end == -1:
                line_end = len(content)
            
            volume_title_line = content[line_start:line_end].strip()

            cleaned_line = re.sub(r'[^\u4e00-\u9fa5]', '', volume_title_line)
            if cleaned_line.endswith(('终', '完', '終')):
                continue
            
            # 获取卷内容范围
            content_start = line_end
            if i < len(matches) - 1:
                content_end = matches[i+1].start()
            else:
                content_end = len(content)
            
            volume_content = content[content_start:content_end].strip()
            
            # 在卷内分章
            # 注意：split_by_chapter 会重新从 volume_content 中找章节
            volume_chapters = self.split_by_chapter(volume_content)
            
            # 如果卷内找不到章节（例如序卷），可能整卷就是一个内容
            if not volume_chapters and volume_content:
                 volume_chapters = [Chapter(
                     id=f"{IdentifierGenerator.generate_volume_id(i+1)}_content",
                     title=volume_title_line, # 使用卷名作为章名
                     content=volume_content,
                     word_count=len(volume_content)
                 )]

            for ch in volume_chapters:
                ch.volume_title = volume_title_line
                # 更新ID以包含卷信息，确保唯一性
                # ch.id 已经是 ch_1, ch_2...
                ch.id = f"{IdentifierGenerator.generate_volume_id(i+1)}_{ch.id}"
                all_chapters.append(ch)
                
        return all_chapters

    def split_by_batch(self, content: str, batch_size: int = 10, chapter_range: Optional[Tuple[int, int]] = None) -> List[Chapter]:
        """按数量合并分割"""
        # 首先按章节分割
        raw_chapters = self.split_by_chapter(content, chapter_range)
        if not raw_chapters:
            return []

        batched_chapters = []
        total = len(raw_chapters)
        
        for i in range(0, total, batch_size):
            batch = raw_chapters[i : i + batch_size]
            start_ch = i + 1
            end_ch = min(i + batch_size, total)
            
            combined_content = "\n\n".join([c.content for c in batch])
            title = f"第{start_ch}-{end_ch}章"
            
            batched_chapters.append(Chapter(
                id=IdentifierGenerator.generate_batch_id(start_ch, end_ch),
                title=title,
                content=combined_content,
                word_count=len(combined_content)
            ))
            
        return batched_chapters


==================== FILE: core\splitter\saver.py ====================

import os
from typing import List
from data_protocol.models import Chapter

def save_chapters(chapters: List[Chapter], output_dir: str, encoding: str = 'utf-8'):
    """
    保存章节列表到文件系统。
    根据是否有 volume_title 来决定是否创建子文件夹。
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for chapter in chapters:
        # 确定保存路径
        if chapter.volume_title:
            # 清理非法字符
            volume_clean = "".join([c for c in chapter.volume_title if c not in r'\/:*?"<>|'])
            volume_dir = os.path.join(output_dir, volume_clean)
            if not os.path.exists(volume_dir):
                os.makedirs(volume_dir)
            
            file_path = os.path.join(volume_dir, f"{chapter.title}.txt")
        else:
            file_path = os.path.join(output_dir, f"{chapter.title}.txt")

        try:
            with open(file_path, 'w', encoding=encoding) as f:
                f.write(chapter.content)
            print(f"已保存: {file_path}")
        except Exception as e:
            print(f"保存失败 {file_path}: {e}")


==================== FILE: core\summarizer\generator.py ====================

import json
import jieba
from collections import defaultdict
from typing import List, Tuple, Set
from core.summarizer.llm_client import LLMClient
from core.summarizer.prompts import Prompts
from data_protocol.models import Chapter, ChapterSummary, SummarySentence, TextSpan, Entity, Relationship

STOPWORDS = {
    "的", "了", "在", "是", "我", "有", "和", "就",
    "不", "人", "都", "一", "一个", "上", "也", "很",
    "到", "说", "要", "去", "你", "会", "着", "没有",
    "看", "好", "自己", "这", "那", "之", "与", "及"
}

class SummaryGenerator:
    """总结生成器，负责调用 LLM 并提取原文溯源"""
    
    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    async def generate_summary_async(self, chapter: Chapter) -> ChapterSummary:
        """异步为单个章节生成总结"""
        print(f"正在总结章节: {chapter.title} (字数: {chapter.word_count})")
        
        # 1. 调用 LLM 生成总结文本 (异步)
        prompt_messages = Prompts.get_summary_prompt(chapter.title, chapter.content[:4000])
        headline = None
        summary_texts = []
        entities_data = []
        relationships_data = [] # Add initialization
        
        try:
            # Check if client supports async
            if hasattr(self.llm, 'chat_completion_async'):
                raw_response = await self.llm.chat_completion_async(prompt_messages)
            else:
                # Fallback to sync if async not implemented (though it should be)
                import asyncio
                loop = asyncio.get_event_loop()
                raw_response = await loop.run_in_executor(None, self.llm.chat_completion, prompt_messages)

            parsed_data = self._parse_json_response(raw_response)
            
            if isinstance(parsed_data, dict):
                headline = parsed_data.get("headline")
                summary_texts = parsed_data.get("summary_sentences", [])
                entities_data = parsed_data.get("entities", [])
                relationships_data = parsed_data.get("relationships", [])
            elif isinstance(parsed_data, list):
                summary_texts = parsed_data
                if summary_texts:
                    headline = summary_texts[0]
            else:
                summary_texts = [str(parsed_data)]
                
        except Exception as e:
            print(f"LLM 响应解析失败: {e}")
            summary_texts = ["(总结生成失败)"]

        # 2. 溯源匹配 (CPU-bound, can keep sync or run in executor if slow)
        # For simplicity, we keep it sync as it's usually fast enough for now
        summary_objects = []
        if not isinstance(summary_texts, list):
            summary_texts = [str(summary_texts)]

        for text in summary_texts:
            spans = self._find_source_spans(text, chapter.content)
            summary_objects.append(SummarySentence(
                summary_text=text,
                source_spans=spans,
                confidence=1.0 if spans else 0.5
            ))

        # 3. 构建实体对象
        entity_objects = []
        for ent in entities_data:
            try:
                entity_objects.append(Entity(
                    name=ent.get("name", "Unknown"),
                    type=ent.get("type", "Other"),
                    description=ent.get("description", ""),
                    confidence=0.9
                ))
            except Exception as e:
                print(f"实体解析失败: {ent}, error: {e}")

        # 4. 构建关系对象
        relationship_objects = []
        for rel in relationships_data:
            try:
                source = rel.get("source", "").strip()
                target = rel.get("target", "").strip()
                relation = rel.get("relation", "").strip()
                description = rel.get("description", "").strip()
                
                if not source or not target or not relation:
                    continue
                    
                relationship_objects.append(Relationship(
                    source=source,
                    target=target,
                    relation=relation,
                    description=description,
                    confidence=0.9
                ))
            except Exception as e:
                print(f"关系解析失败: {rel}, error: {e}")

        return ChapterSummary(
            chapter_id=chapter.id,
            chapter_title=chapter.title,
            headline=headline,
            summary_sentences=summary_objects,
            entities=entity_objects,
            relationships=relationship_objects
        )

    def generate_summary(self, chapter: Chapter) -> ChapterSummary:
        """为单个章节生成总结"""
        print(f"正在总结章节: {chapter.title} (字数: {chapter.word_count})")
        
        # 1. 调用 LLM 生成总结文本
        prompt_messages = Prompts.get_summary_prompt(chapter.title, chapter.content[:4000]) # 限制长度以避免超 token
        headline = None
        summary_texts = []
        entities_data = []
        
        try:
            raw_response = self.llm.chat_completion(prompt_messages)
            parsed_data = self._parse_json_response(raw_response)
            
            if isinstance(parsed_data, dict):
                headline = parsed_data.get("headline")
                summary_texts = parsed_data.get("summary_sentences", [])
                entities_data = parsed_data.get("entities", [])
                relationships_data = parsed_data.get("relationships", [])
            elif isinstance(parsed_data, list):
                # 兼容旧格式（如果是 list，则视为 detailed summaries）
                summary_texts = parsed_data
                # 尝试用第一句作为 headline 的 fallback
                if summary_texts:
                    headline = summary_texts[0]
            else:
                summary_texts = [str(parsed_data)]
                
        except Exception as e:
            print(f"LLM 响应解析失败: {e}")
            summary_texts = ["(总结生成失败)"]

        # 2. 溯源匹配 (简单实现：基于关键词匹配)
        summary_objects = []
        
        # 确保 summary_texts 是列表
        if not isinstance(summary_texts, list):
            summary_texts = [str(summary_texts)]

        for text in summary_texts:
            spans = self._find_source_spans(text, chapter.content)
            summary_objects.append(SummarySentence(
                summary_text=text,
                source_spans=spans,
                confidence=1.0 if spans else 0.5
            ))

        # 3. 构建实体对象
        entity_objects = []
        for ent in entities_data:
            try:
                entity_objects.append(Entity(
                    name=ent.get("name", "Unknown"),
                    type=ent.get("type", "Other"),
                    description=ent.get("description", ""),
                    confidence=0.9 # 默认置信度
                ))
            except Exception as e:
                print(f"实体解析失败: {ent}, error: {e}")

        # 4. 构建关系对象
        relationship_objects = []
        for rel in relationships_data:
            try:
                # 显式检查必要字段，因为 .get() 会返回默认空字符串，可能绕过 Pydantic 校验
                # 但如果模型定义为 source: str = Field(...)，传入 "" 是合法的字符串。
                # 然而，空的 source/target/relation 是没有意义的。
                source = rel.get("source", "").strip()
                target = rel.get("target", "").strip()
                relation = rel.get("relation", "").strip()
                description = rel.get("description", "").strip()
                
                if not source or not target or not relation:
                    # 缺少关键信息，跳过
                    continue
                    
                relationship_objects.append(Relationship(
                    source=source,
                    target=target,
                    relation=relation,
                    description=description,
                    confidence=0.9
                ))
            except Exception as e:
                print(f"关系解析失败: {rel}, error: {e}")

        return ChapterSummary(
            chapter_id=chapter.id,
            chapter_title=chapter.title,
            headline=headline,
            summary_sentences=summary_objects,
            entities=entity_objects,
            relationships=relationship_objects
        )

    def _parse_json_response(self, response: str) -> object:
        """解析 LLM 返回的 JSON 字符串"""
        import re
        
        # 1. 移除思维链 <think>...</think>
        cleaned = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
        
        # 2. 尝试直接解析
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass
            
        # 3. 尝试提取 Markdown 代码块 ```json ... ```
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', cleaned, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
                
        # 4. 尝试提取最外层的大括号 {}
        # 寻找第一个 { 和最后一个 }
        start = cleaned.find('{')
        end = cleaned.rfind('}')
        
        if start != -1 and end != -1 and end > start:
            json_str = cleaned[start:end+1]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                print(f"无法解析提取的 JSON 片段: {json_str[:100]}...")
        
        print(f"无法解析 JSON: {cleaned[:200]}...")
        # 降级策略：如果无法解析 JSON，尝试按行分割，并假设每行是一条总结
        lines = [line.strip() for line in cleaned.split('\n') if line.strip()]
        return {
            "headline": lines[0] if lines else None,
            "summary_sentences": lines
        }

    def _find_source_spans(self, summary: str, content: str) -> List[TextSpan]:
        """
        在原文中寻找与总结句最相关的片段。
        采用基于关键词密度的滑动窗口算法。
        """
        # 1. 分词并过滤停用词
        keywords = [w for w in jieba.lcut(summary) if w not in STOPWORDS and len(w) > 1]
        
        if not keywords:
            # 降级：如果找不到关键词，尝试直接搜索前10个字符
            start = content.find(summary[:10])
            if start != -1:
                return [TextSpan(text=content[start:start+len(summary)], start_index=start, end_index=start+len(summary))]
            return []

        # 2. 找到所有关键词在原文中的位置
        # 格式: (index, word)
        keyword_positions = []
        for w in keywords:
            start = 0
            while True:
                idx = content.find(w, start)
                if idx == -1: break
                keyword_positions.append((idx, w))
                start = idx + 1
        
        if not keyword_positions:
            return []

        # 按位置排序
        keyword_positions.sort(key=lambda x: x[0])

        # 3. 滑动窗口寻找最佳匹配区域
        # 窗口大小设定为总结句长度的 2 倍 + 50 字符冗余，确保能覆盖概括性的描述
        window_size = len(summary) * 2 + 50
        
        best_score = 0
        best_span_indices = None # (start, end)
        
        left = 0
        current_keywords_count = defaultdict(int)
        
        for right in range(len(keyword_positions)):
            pos_r, word_r = keyword_positions[right]
            current_keywords_count[word_r] += 1
            
            # 收缩左边界，保证窗口大小不超过限制
            while pos_r - keyword_positions[left][0] > window_size:
                pos_l, word_l = keyword_positions[left]
                current_keywords_count[word_l] -= 1
                if current_keywords_count[word_l] <= 0:
                    del current_keywords_count[word_l]
                left += 1
            
            # 计算得分：唯一关键词的数量
            # (未来可以优化为 TF-IDF 加权)
            score = len(current_keywords_count)
            
            if score > best_score:
                best_score = score
                # 记录当前的跨度
                span_start = keyword_positions[left][0]
                span_end = pos_r + len(word_r)
                best_span_indices = (span_start, span_end)

        # 4. 返回结果
        if best_span_indices:
            start, end = best_span_indices
            # 稍微扩展一点上下文 (前后 5 个字符)，但不要越界
            start = max(0, start - 5)
            end = min(len(content), end + 5)
            
            return [TextSpan(
                text=content[start:end],
                start_index=start,
                end_index=end
            )]
            
        return []


==================== FILE: core\summarizer\llm_client.py ====================

from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any
from openai import OpenAI, AsyncOpenAI
import asyncio

class LLMClient(ABC):
    """LLM 客户端抽象基类"""
    @abstractmethod
    def chat_completion(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        pass

    @abstractmethod
    async def chat_completion_async(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """异步调用接口"""
        pass

class OpenAIClient(LLMClient):
    """基于 OpenAI SDK 的通用客户端 (支持 OpenRouter, Local, DeepSeek 等)"""
    def __init__(self, api_key: str, base_url: str, model: str):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.async_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model

    def chat_completion(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"LLM 同步调用失败: {e}")
            raise e

    def generate(self, prompt: str) -> str:
        """Alias for chat_completion with a single user message (for compatibility)"""
        return self.chat_completion([{"role": "user", "content": prompt}])

    async def chat_completion_async(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        try:
            response = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"LLM 异步调用失败: {e}")
            raise e

class ClientFactory:
    """工厂类，用于创建不同类型的 LLM 客户端"""
    @staticmethod
    def create_client(provider: str, **kwargs) -> LLMClient:
        if provider == "local":
            return OpenAIClient(
                api_key="lm-studio", # 本地通常不需要真实 Key
                base_url=kwargs.get("base_url", "http://localhost:1234/v1"),
                model=kwargs.get("model", "local-model")
            )
        elif provider == "openrouter":
            return OpenAIClient(
                api_key=kwargs.get("api_key"),
                base_url="https://openrouter.ai/api/v1",
                model=kwargs.get("model", "openai/gpt-3.5-turbo")
            )
        elif provider == "deepseek":
            return OpenAIClient(
                api_key=kwargs.get("api_key"),
                base_url="https://api.deepseek.com",
                model=kwargs.get("model", "deepseek-chat")
            )
        else:
            raise ValueError(f"不支持的 Provider: {provider}")


==================== FILE: core\summarizer\prompts.py ====================

from typing import List, Dict

import hashlib

class Prompts:
    """Prompt 模板管理"""
    
    SYSTEM_PROMPT = """你是一个专业的文学分析师。你的任务是对给定的小说章节进行总结，并提取其中的关键实体。
请遵循以下规则，涵盖小说的三要素（人物、情节、环境）：

### 1. 情节 (Story/Plot)
*   总结应概括本章的核心事件、人物互动和重要情节转折。
*   总结应该分为若干个独立的句子，每个句子描述一个具体的事件点。
*   **严禁在总结中重复章节标题**（如“本章标题是xxx”），直接开始总结情节。

### 2. 人物 (Characters)
*   提取本章出现的关键人物，标记为 'Person' 类型。
*   描述中应包含人物的身份、性格特征或本章中的重要行为。

### 3. 环境 (Environment/Setting)
*   提取本章出现的关键地点或环境描写，标记为 'Location' 类型。
*   提取社会环境（如组织、门派、国家），标记为 'Organization' 类型。
*   提取关键物品（道具、武器），标记为 'Item' 类型。
*   提取特殊概念（功法、境界、设定），标记为 'Concept' 类型。

### 4. 关系 (Relationships)
*   提取本章内发生的显式人物互动或实体关系。
*   关系三元组格式: (Source, Relation, Target)。
*   例如: ("张三", "攻击", "李四"), ("王五", "加入", "青云门")。
*   仅提取本章明确提及的重要关系。

### 通用规则
*   保持客观、准确，不要添加个人的主观评价。
*   输出格式必须是 JSON 对象，包含 'headline', 'summary_sentences', 'entities' 和 'relationships'。
*   如果章节内容为空或无实质情节，请返回空 JSON。
*   IMPORTANT: Output ONLY the JSON object. Do not include any explanations, thinking process (<think>...</think>), or markdown formatting outside the JSON.
"""

    USER_PROMPT_TEMPLATE = """请总结以下小说章节的内容，并基于“小说三要素”提取实体：

标题：{title}
内容：
{content}

请输出 JSON 格式，例如：
{{
    "headline": "张三离家出走并结识了李四。",
    "summary_sentences": ["张三离开了家乡。", "他在路上遇到了李四。", "两人决定结伴同行。"],
    "entities": [
        {{"name": "张三", "type": "Person", "description": "主角，性格坚毅，决定离开家乡闯荡"}},
        {{"name": "李四", "type": "Person", "description": "路遇的神秘剑客，外表冷漠"}},
        {{"name": "青云山", "type": "Location", "description": "故事开始的地方，终年云雾缭绕"}},
        {{"name": "青云门", "type": "Organization", "description": "当地的第一大修仙门派"}},
        {{"name": "青云剑", "type": "Item", "description": "李四随身携带的武器"}}
    ],
    "relationships": [
        {{"source": "张三", "relation": "遇见", "target": "李四", "description": "在山脚下偶遇"}},
        {{"source": "张三", "relation": "前往", "target": "青云山", "description": "为了拜师学艺"}},
        {{"source": "李四", "relation": "持有", "target": "青云剑", "description": "随身佩戴"}}
    ]
}}
"""

    @classmethod
    def get_prompt_hash(cls) -> str:
        """计算 Prompt 模板的哈希值，用于缓存校验"""
        content = cls.SYSTEM_PROMPT + cls.USER_PROMPT_TEMPLATE
        return hashlib.sha256(content.encode('utf-8')).hexdigest()

    @staticmethod
    def get_summary_prompt(title: str, content: str) -> List[Dict[str, str]]:

        """生成用于总结的 Prompt"""
        return [
            {"role": "system", "content": Prompts.SYSTEM_PROMPT},
            {"role": "user", "content": Prompts.USER_PROMPT_TEMPLATE.format(title=title, content=content)}
        ]


==================== FILE: core\world_builder\aggregator.py ====================

import json
import os
from typing import List, Dict, Tuple
from collections import defaultdict, Counter
import zhconv
from data_protocol.models import ChapterSummary, Entity, AggregatedEntity, AggregatedRelationship

class EntityAggregator:
    """
    实体与关系聚合器 (World Builder)
    负责将分散在各个章节中的实体和关系信息汇总成全局档案。
    """

    def __init__(self, alias_file=None):
        self.aliases = self._load_aliases(alias_file)

    def _load_aliases(self, alias_file):
        """加载别名配置文件"""
        if not alias_file:
            # 默认路径
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            alias_file = os.path.join(base_dir, "config", "aliases.json")
        
        if os.path.exists(alias_file):
            try:
                with open(alias_file, 'r', encoding='utf-8') as f:
                    print(f"DEBUG: Loaded aliases from {alias_file}")
                    return json.load(f)
            except Exception as e:
                print(f"WARNING: Failed to load aliases from {alias_file}: {e}")
                return {}
        return {}

    def _normalize_text(self, text: str) -> str:
        """
        标准化文本：去除首尾空格，应用别名映射，并转为简体中文。
        解决繁简混杂及别名导致同一实体被识别为两个节点的问题。
        """
        if not text:
            return ""
        
        text = text.strip()
        
        # 1. 应用别名映射 (在转简体之前还是之后？建议之前，如果别名表里的key也是原文形式)
        # 但为了稳健，先转简体再查别名？或者查两次？
        # 假设 aliases.json 中的 key 已经尽可能涵盖了常见形式。
        # 策略：先查一次 -> 转简体 -> 再查一次 (防止 alias key 是简体的)
        
        if text in self.aliases:
            text = self.aliases[text]
            
        text = zhconv.convert(text, 'zh-cn')
        
        if text in self.aliases:
            text = self.aliases[text]
            
        return text

    def aggregate_entities(self, summaries: List[ChapterSummary]) -> List[AggregatedEntity]:
        """
        聚合所有章节的实体。
        
        Args:
            summaries: 章节总结列表

        Returns:
            List[AggregatedEntity]: 聚合后的全局实体列表，按出现频率降序排列。
        """
        # Key: name (normalized), Value: dict to accumulate data
        # Fix: Group by name only, not (name, type), to prevent duplicate nodes with same ID but different types
        entity_map: Dict[str, Dict] = defaultdict(lambda: {
            "name": "",
            "types": Counter(), # Track frequency of each type
            "descriptions": [],
            "history": [],
            "chapter_ids": set(),
            "count": 0
        })

        for summary in summaries:
            if not summary.entities:
                continue
                
            for entity in summary.entities:
                # 标准化处理：去除首尾空格，转简体，应用别名
                name = self._normalize_text(entity.name)
                type_ = entity.type.strip()
                
                if not name:
                    continue

                # Key is now just the name
                key = name
                entry = entity_map[key]
                
                if not entry["name"]:
                    entry["name"] = name
                
                # Accumulate type
                if type_:
                    entry["types"][type_] += 1
                
                if entity.description:
                    entry["descriptions"].append(entity.description)
                    entry["history"].append({
                        "chapter_id": str(summary.chapter_id).strip(),
                        "content": entity.description
                    })
                
                entry["chapter_ids"].add(str(summary.chapter_id).strip())
                entry["count"] += 1

        results = []
        for key, data in entity_map.items():
            # 描述合并策略：
            # 1. 优先选择最长的描述（通常包含更多细节）
            # 2. 如果没有描述，使用空字符串
            descriptions = data["descriptions"]
            final_desc = max(descriptions, key=len) if descriptions else "暂无描述"
            
            # 类型决策策略：选择出现频率最高的类型
            # 如果没有记录到类型，默认为 'Unknown'
            # data["types"] is a Counter
            most_common_type = data["types"].most_common(1)
            final_type = most_common_type[0][0] if most_common_type else "Unknown"

            # 章节列表排序
            sorted_chapters = sorted(list(data["chapter_ids"]))

            agg_entity = AggregatedEntity(
                name=data["name"],
                type=final_type,
                description=final_desc,
                history=data["history"],
                chapter_ids=sorted_chapters,
                count=data["count"]
            )
            results.append(agg_entity)

        # 按出现频率降序排列
        return sorted(results, key=lambda x: x.count, reverse=True)

    def aggregate_relationships(self, summaries: List[ChapterSummary]) -> List[AggregatedRelationship]:
        """
        聚合所有章节的关系。
        将多个章节中出现的 (A, B) 互动合并为一条带有时间线的全局关系。
        """
        print(f"DEBUG: Aggregating relationships for {len(summaries)} summaries")
        # Key: (source, target), Value: dict
        # 注意：需要规范化 source/target 的顺序吗？
        # 目前不需要，因为 A->B (攻击) 和 B->A (被攻击) 是不同的方向。
        # 暂时保持有向图。
        rel_map: Dict[Tuple[str, str], Dict] = defaultdict(lambda: {
            "source": "",
            "target": "",
            "timeline": [],
            "weight": 0
        })

        total_rels = 0
        
        for summary in summaries:
            if not summary.relationships:
                continue
                
            total_rels += len(summary.relationships)
            valid_rel_count = 0
            for rel in summary.relationships:
                # 标准化处理：转简体，应用别名
                s = self._normalize_text(rel.source)
                t = self._normalize_text(rel.target)
                
                # 简单的数据清洗：跳过无效数据
                if not s or not t:
                    print(f"DEBUG: Skipped invalid rel: '{rel.source}'->'{rel.target}' => '{s}'->'{t}'")
                    continue
                    
                key = (s, t)
                entry = rel_map[key]
                
                if not entry["source"]:
                    entry["source"] = s
                    entry["target"] = t
                
                valid_rel_count += 1
                
                # 添加到时间线
                entry["timeline"].append({
                    "chapter_id": str(summary.chapter_id).strip(),
                    "relation": rel.relation,
                    "description": rel.description,
                    "order": valid_rel_count  # 记录本章内的有效顺序 (1-based, 连续)
                })
                
                entry["weight"] += 1

        results = []
        for key, data in rel_map.items():
            # 按章节顺序排序时间线? 假设 summaries 已经是按顺序传入的
            # 如果不确定，可以在这里 sort timeline by chapter_id (如果 id 可排序)
            
            agg_rel = AggregatedRelationship(
                source=data["source"],
                target=data["target"],
                timeline=data["timeline"],
                weight=data["weight"]
            )
            results.append(agg_rel)

        print(f"DEBUG: Total raw rels: {total_rels}, Final unique edges: {len(results)}")
        # 按权重降序排列
        return sorted(results, key=lambda x: x.weight, reverse=True)


==================== FILE: core\world_builder\merger.py ====================

import os
import json
import re
from typing import List, Dict, Optional
from data_protocol.models import ChapterSummary

class ResultMerger:
    """
    负责将不同时间戳运行的结果进行合并 (Best-Effort Merging)。
    """
    
    @staticmethod
    def _extract_chapter_number(chapter_id: str) -> float:
        """从 chapter_id 提取数字用于排序 (例如 'ch_10' -> 10.0)"""
        if not chapter_id:
            return 0.0
        
        # 尝试提取数字
        match = re.search(r'(\d+(\.\d+)?)', chapter_id)
        if match:
            return float(match.group(1))
        return 0.0

    def merge_summaries(self, run_path: str) -> List[ChapterSummary]:
        """
        加载指定 run_path 的 summary，并尝试从同级目录的其他 run 中补全缺失章节。
        
        Args:
            run_path: 当前选中的运行结果目录 (例如 .../20240220_120000)
            
        Returns:
            合并后的 ChapterSummary 列表，按章节号排序。
        """
        base_summaries = []
        
        # 1. 加载 Base Run (当前选中的)
        base_file = os.path.join(run_path, "summaries.json")
        if os.path.exists(base_file):
            try:
                with open(base_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for item in data:
                        try:
                            # 兼容旧数据: 确保必要字段存在
                            if "entities" not in item: item["entities"] = []
                            if "relationships" not in item: item["relationships"] = []
                            base_summaries.append(ChapterSummary(**item))
                        except Exception as e:
                            print(f"Skipping malformed summary in base run: {e}")
            except Exception as e:
                print(f"Error loading base run: {e}")
        
        # 建立 map: chapter_id -> summary
        # 优先信赖当前选中的 run
        merged_map: Dict[str, ChapterSummary] = {}
        for s in base_summaries:
            merged_map[s.chapter_id] = s
            
        print(f"DEBUG: Base run has {len(merged_map)} chapters.")

        # 2. 扫描同级目录 (Sibling Runs)
        parent_dir = os.path.dirname(run_path) # .../file_hash/
        if not os.path.exists(parent_dir):
            return base_summaries
            
        # 获取所有 timestamp 目录
        all_runs = []
        for d in os.listdir(parent_dir):
            full_path = os.path.join(parent_dir, d)
            if os.path.isdir(full_path) and full_path != run_path: # 排除自己
                # 检查是否包含 summaries.json
                if os.path.exists(os.path.join(full_path, "summaries.json")):
                    all_runs.append(full_path)
        
        # 按时间倒序排序 (优先使用最新的其他 run)
        all_runs.sort(key=lambda x: os.path.basename(x), reverse=True)
        
        # 3. 补全缺失章节
        for other_run in all_runs:
            try:
                summary_file = os.path.join(other_run, "summaries.json")
                with open(summary_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                added_count = 0
                for item in data:
                    chap_id = item.get("chapter_id")
                    if chap_id and chap_id not in merged_map:
                        try:
                            # 兼容性检查
                            if "entities" not in item: item["entities"] = []
                            if "relationships" not in item: item["relationships"] = []
                            
                            summary = ChapterSummary(**item)
                            merged_map[chap_id] = summary
                            added_count += 1
                        except Exception:
                            continue
                
                if added_count > 0:
                    print(f"DEBUG: Merged {added_count} chapters from {os.path.basename(other_run)}")
                    
            except Exception as e:
                print(f"Error reading sibling run {os.path.basename(other_run)}: {e}")
                continue

        # 4. 排序并返回
        result_list = list(merged_map.values())
        
        # 按章节号排序
        result_list.sort(key=lambda x: self._extract_chapter_number(x.chapter_id))
        
        print(f"DEBUG: Final merged result has {len(result_list)} chapters.")
        return result_list


==================== FILE: data_protocol\__init__.py ====================




==================== FILE: data_protocol\models.py ====================

from typing import List, Optional, Dict
from pydantic import BaseModel, Field

class TextSpan(BaseModel):
    """表示文本中的一个片段及其位置"""
    text: str = Field(..., description="片段内容")
    start_index: int = Field(..., description="在原文中的起始字符偏移量")
    end_index: int = Field(..., description="在原文中的结束字符偏移量")

class Chapter(BaseModel):
    """章节数据模型"""
    id: str = Field(..., description="唯一标识符 (如 'vol1_ch1')")
    title: str = Field(..., description="章节标题 (如 '第一章 序幕')")
    volume_title: Optional[str] = Field(None, description="所属分卷标题 (可选)")
    content: str = Field(..., description="章节完整文本")
    word_count: int = Field(..., description="字数")

class BookStructure(BaseModel):
    """整书结构模型"""
    book_name: str = Field(..., description="书名")
    chapters: List[Chapter] = Field(default_factory=list, description="章节列表")
    metadata: Dict = Field(default_factory=dict, description="额外元数据")

class SummarySentence(BaseModel):
    """单句总结及其溯源"""
    summary_text: str = Field(..., description="总结的句子 (LLM 生成)")
    source_spans: List[TextSpan] = Field(default_factory=list, description="对应的原文片段 (用于点击跳转)")
    confidence: Optional[float] = Field(None, description="置信度 (可选)")

class Entity(BaseModel):
    """实体模型 (世界观构建)"""
    name: str = Field(..., description="实体名称 (如 '孙杰克', '玄天宗')")
    type: str = Field(..., description="实体类型: Person(人物), Location(地点/自然环境), Organization(组织/社会环境), Item(物品), Concept(概念)")
    description: str = Field(..., description="本章中的相关描述或状态更新")
    confidence: Optional[float] = Field(None, description="置信度")

class Relationship(BaseModel):
    """实体关系模型 (v6.0)"""
    source: str = Field(..., description="主体 (Subject)，如 '孙杰克'")
    target: str = Field(..., description="客体 (Object)，如 '塔派'")
    relation: str = Field(..., description="关系类型/谓语，如 '朋友', '敌人', '攻击', '遇见'")
    description: str = Field(..., description="关系描述，如 '在垃圾场捡到的机器人'")
    confidence: float = Field(default=1.0)

class ChapterSummary(BaseModel):
    """单章总结"""
    chapter_id: str = Field(..., description="关联的章节 ID")
    chapter_title: Optional[str] = Field(None, description="章节标题")
    headline: Optional[str] = Field(None, description="一句话核心总结 (Overview Mode)")
    summary_sentences: List[SummarySentence] = Field(default_factory=list, description="总结句子列表")
    entities: List[Entity] = Field(default_factory=list, description="本章出现的关键实体及其描述")
    relationships: List[Relationship] = Field(default_factory=list, description="本章内发生的实体互动关系")
    # key_entities: List[str]  # Deprecated in v5, replaced by entities list

class AggregatedEntity(BaseModel):
    """聚合后的全局实体"""
    name: str = Field(..., description="实体名称")
    type: str = Field(..., description="实体类型")
    description: str = Field(..., description="合并后的描述 (通常取首次出现或最详细的描述)")
    history: List[Dict] = Field(default_factory=list, description="实体描述历史: [{'chapter_id': 'ch1', 'content': '...'}, ...]")
    chapter_ids: List[str] = Field(default_factory=list, description="出现的章节ID列表")
    count: int = Field(0, description="出现次数")

class AggregatedRelationship(BaseModel):
    """聚合后的全局关系 (v6.0)"""
    source: str = Field(..., description="主体")
    target: str = Field(..., description="客体")
    # 关系是动态的，所以不应该只有一个静态的 relation 字段
    # 而是存储一个时间线列表
    timeline: List[Dict] = Field(
        default_factory=list, 
        description="关系演变历史: [{'chapter_id': 'ch1', 'relation': 'stranger', 'description': '...'}, ...]"
    )
    weight: int = Field(0, description="互动次数权重")


==================== FILE: frontend\package.json ====================

{
  "name": "storytrace-ui",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vue-tsc -b && vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "axios": "^1.7.9",
    "pinia": "^2.3.1",
    "vis-network": "^9.1.9",
    "vue": "^3.5.13",
    "vue-router": "^4.5.0"
  },
  "devDependencies": {
    "@tailwindcss/typography": "^0.5.16",
    "@types/node": "^22.13.4",
    "@vitejs/plugin-vue": "^5.2.1",
    "@vue/tsconfig": "^0.7.0",
    "autoprefixer": "^10.4.20",
    "postcss": "^8.5.2",
    "tailwindcss": "^3.4.17",
    "typescript": "~5.7.2",
    "vite": "^6.1.0",
    "vue-tsc": "^2.2.0"
  }
}


==================== FILE: frontend\postcss.config.js ====================

export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}


==================== FILE: frontend\tailwind.config.js ====================

/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{vue,js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [
    require('@tailwindcss/typography'),
  ],
}


==================== FILE: frontend\tsconfig.app.json ====================

{
  "extends": "@vue/tsconfig/tsconfig.dom.json",
  "include": ["src/**/*", "src/**/*.vue"],
  "exclude": ["src/**/__tests__/*"],
  "compilerOptions": {
    "composite": true,
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  }
}


==================== FILE: frontend\vite.config.ts ====================

import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'
import path from 'path'

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [vue()],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
  server: {
    proxy: {
      '/api': {
        target: 'http://localhost:8000',
        changeOrigin: true,
        // rewrite: (path) => path.replace(/^\/api/, ''), // Backend API routes are like /api/novels, so no rewrite needed
      },
    },
  },
})


==================== FILE: frontend\src\App.vue ====================

<script setup lang="ts">
import { RouterView } from 'vue-router'
import JobStatusWidget from '@/components/JobStatusWidget.vue'
import { useJobStore } from '@/stores/jobStore'

const jobStore = useJobStore()

function handleViewResult(result: any) {
    // Ideally we should emit this event to the current view or use a global event bus
    // But since GraphView is deeply nested, we might need a better way.
    // For v1, if we are on GraphView, we can refresh?
    // Actually, JobStatusWidget is global.
    // Let's use a global state in jobStore to signal "Show Result for Pair X"
    // Or just let the user click the button and we close the widget?
    // The "View Result" button in the widget should probably just trigger the drawer.
    // But the drawer is inside GraphView.
    // We can use a global event bus or store flag.
    
    // For now, let's just close the widget and let the user manually check.
    // Wait, that's bad UX.
    // Let's add a `resultTrigger` to jobStore.
    jobStore.clearActiveJob()
    
    // We need to tell GraphView to open the drawer.
    // Since we don't have a global event bus handy, let's just log it for now.
    // Or we can dispatch a custom window event.
    window.dispatchEvent(new CustomEvent('open-relationship-result', { detail: result }));
}
</script>

<template>
  <RouterView />
  <JobStatusWidget @view-result="handleViewResult" />
</template>


==================== FILE: frontend\src\main.ts ====================

import { createApp } from 'vue'
import { createPinia } from 'pinia'
import './style.css'
import 'vis-network/styles/vis-network.css'
import App from './App.vue'
import router from './router'

const app = createApp(App)

app.use(createPinia())
app.use(router)

app.mount('#app')


==================== FILE: frontend\src\api\client.ts ====================

import axios from 'axios';
import type { Novel, Run, Chapter, Entity, GraphData, TimelineEvent, RelationshipTimelineEvent } from '@/types';

const apiClient = axios.create({
  baseURL: '/api',
  headers: {
    'Content-Type': 'application/json',
  },
});

export const API = {
  async fetchNovels(): Promise<Novel[]> {
    const response = await apiClient.get<Novel[]>('/novels');
    return response.data;
  },

  async fetchRuns(novelName: string, hash: string): Promise<Run[]> {
    const response = await apiClient.get<Run[]>(`/novels/${novelName}/${hash}/runs`);
    return response.data;
  },

  async fetchChapters(novelName: string, hash: string, timestamp: string): Promise<Chapter[]> {
    const response = await apiClient.get<Chapter[]>(`/novels/${novelName}/${hash}/${timestamp}/chapters`);
    return response.data;
  },

  async fetchChapterDetail(novelName: string, hash: string, timestamp: string, chapterId: string): Promise<Chapter> {
    const response = await apiClient.get<Chapter>(`/novels/${novelName}/${hash}/${timestamp}/chapters/${chapterId}`);
    return response.data;
  },

  async fetchGlobalEntities(novelName: string, hash: string, timestamp: string): Promise<Entity[]> {
    const response = await apiClient.get<Entity[]>(`/novels/${novelName}/${hash}/${timestamp}/entities`);
    return response.data;
  },

  async fetchGraphData(novelName: string, hash: string, timestamp: string): Promise<GraphData> {
    const response = await apiClient.get<GraphData>(`/novels/${novelName}/${hash}/${timestamp}/graph`);
    return response.data;
  },

  async fetchEntityTimeline(novelName: string, hash: string, timestamp: string, entityName: string): Promise<TimelineEvent[]> {
    const response = await apiClient.get<TimelineEvent[]>(`/novels/${novelName}/${hash}/${timestamp}/entity/${encodeURIComponent(entityName)}/timeline`);
    return response.data;
  },

  async fetchRelationshipTimeline(novelName: string, hash: string, timestamp: string, source: string, target: string): Promise<RelationshipTimelineEvent[]> {
    const response = await apiClient.get<RelationshipTimelineEvent[]>(`/novels/${novelName}/${hash}/${timestamp}/relationship`, {
      params: { source, target, _t: Date.now() }
    });
    return response.data;
  },

  async deleteRelationshipAnalysis(novelName: string, hash: string, source: string, target: string): Promise<void> {
    await apiClient.delete(`/novels/${novelName}/${hash}/relationship`, {
      params: { source, target }
    });
  }
};


==================== FILE: frontend\src\components\AppNavbar.vue ====================

<script setup lang="ts">
import { useNovelStore } from '@/stores/novel';
import { computed } from 'vue';

const store = useNovelStore();

const novels = computed(() => store.novels);
const runs = computed(() => store.runs);

// Actions
const selectNovel = (event: Event) => {
  const target = event.target as HTMLSelectElement;
  const novel = novels.value.find(n => n.name === target.value);
  if (novel) {
    store.selectNovel(novel);
  }
};

const selectRun = (event: Event) => {
  const target = event.target as HTMLSelectElement;
  const run = runs.value.find(r => r.timestamp === target.value);
  if (run) {
    store.selectRun(run);
  }
};

// Formatting
const formatTime = (ts: string) => {
  if (ts.length === 15) {
    return `${ts.slice(0,4)}-${ts.slice(4,6)}-${ts.slice(6,8)} ${ts.slice(9,11)}:${ts.slice(11,13)}`;
  }
  return ts;
};
</script>

<template>
  <header class="bg-white shadow-sm px-6 py-4 flex items-center justify-between z-10 sticky top-0">
    <h1 class="text-xl font-bold text-indigo-600 flex items-center gap-2">
      <span>📚</span> StoryTrace V2
    </h1>
    
    <div class="flex gap-4 items-center">
      <!-- Novel Selector -->
      <select 
        :value="store.currentNovel?.name || ''" 
        @change="selectNovel" 
        class="border rounded px-2 py-1 text-sm bg-white hover:border-indigo-400 transition-colors"
      >
        <option value="" disabled>选择小说</option>
        <option v-for="n in novels" :key="n.name" :value="n.name">{{ n.name }}</option>
      </select>
      
      <!-- Run Selector -->
      <select 
        :value="store.currentRun?.timestamp || ''" 
        @change="selectRun" 
        class="border rounded px-2 py-1 text-sm bg-white hover:border-indigo-400 transition-colors"
        :disabled="!store.currentNovel"
      >
        <option value="" disabled>选择版本</option>
        <option v-for="r in runs" :key="r.timestamp" :value="r.timestamp">{{ formatTime(r.timestamp) }}</option>
      </select>

      <!-- Chapter Selector -->
      <select 
        v-if="store.currentRun"
        :value="store.selectedChapterId || ''" 
        @change="(e) => store.selectedChapterId = (e.target as HTMLSelectElement).value" 
        class="border rounded px-2 py-1 text-sm bg-white hover:border-indigo-400 transition-colors max-w-[200px]"
      >
        <option value="" disabled>跳转章节</option>
        <option v-for="c in store.chapters" :key="c.id" :value="c.id">{{ c.title }}</option>
      </select>

      <!-- View Toggles -->
      <div class="flex bg-gray-100 rounded-lg p-1" v-if="store.currentRun">
        <button 
          @click="store.viewMode = 'overview'" 
          class="px-3 py-1 text-sm rounded-md transition-all font-medium"
          :class="store.viewMode === 'overview' ? 'bg-white text-indigo-600 shadow-sm' : 'text-gray-500 hover:text-gray-700'"
        >
          📚 概览
        </button>
        <button 
          @click="store.viewMode = 'graph'" 
          class="px-3 py-1 text-sm rounded-md transition-all font-medium"
          :class="store.viewMode === 'graph' ? 'bg-white text-indigo-600 shadow-sm' : 'text-gray-500 hover:text-gray-700'"
        >
          🕸️ 图谱
        </button>
      </div>
    </div>
  </header>
</template>


==================== FILE: frontend\src\components\EntityChronicleDrawer.vue ====================

<script setup lang="ts">
import { computed } from 'vue';
import type { TimelineEvent } from '@/types';

const props = defineProps<{
  isOpen: boolean;
  entityName: string;
  events: TimelineEvent[];
  isLoading: boolean;
}>();

const emit = defineEmits<{
  (e: 'close'): void;
  (e: 'jump-to-chapter', chapterId: string): void;
}>();

const timeline = computed(() => props.events);
</script>

<template>
  <!-- Drawer Container -->
  <div 
    class="fixed inset-y-0 right-0 w-96 bg-white shadow-xl transform transition-transform duration-300 ease-in-out z-50 flex flex-col border-l border-gray-200"
    :class="isOpen ? 'translate-x-0' : 'translate-x-full'"
  >
    <!-- Header -->
    <div class="p-6 border-b border-gray-100 flex justify-between items-center bg-white z-10">
        <div>
            <h2 class="text-lg font-bold text-gray-900 truncate max-w-[200px]" :title="entityName">{{ entityName }}</h2>
            <p class="text-xs text-gray-500 uppercase tracking-wider font-semibold mt-1">Entity Chronicle</p>
        </div>
        <button 
          @click="emit('close')"
          class="p-2 rounded-full hover:bg-gray-100 text-gray-400 hover:text-gray-600 transition-colors"
        >
          <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
    </div>

    <!-- Timeline Body -->
    <div class="flex-1 overflow-y-auto custom-scrollbar bg-gray-50 p-6 relative">
         <!-- Loading State -->
        <div v-if="isLoading" class="absolute inset-0 flex items-center justify-center bg-white/50 z-10">
            <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-indigo-600"></div>
        </div>

        <div v-if="timeline.length > 0" class="space-y-8 relative">
            <!-- Timeline Line -->
            <div class="absolute left-3 top-2 bottom-2 w-0.5 bg-gray-200"></div>

            <div v-for="event in timeline" :key="event.chapter_id" class="relative pl-8">
                 <!-- Dot -->
                 <div class="absolute left-[5px] top-1.5 w-2.5 h-2.5 rounded-full bg-white border-2 border-indigo-500 z-10"></div>
                 
                 <!-- Gap Indicator -->
                 <div v-if="event.gap_before > 0" class="mb-4 text-xs text-gray-400 font-mono pl-1 border-l-2 border-dashed border-gray-300 ml-[-20px] py-2 bg-gray-50/80">
                    ... Skip {{ event.gap_before }} chapters ...
                 </div>

                 <!-- Content -->
                 <div class="group">
                     <div class="flex items-baseline justify-between mb-1">
                        <button 
                            @click="emit('jump-to-chapter', event.chapter_id)"
                            class="text-xs font-bold text-indigo-600 hover:text-indigo-800 hover:underline transition-colors ml-auto bg-indigo-50 px-2 py-0.5 rounded-full flex items-center gap-1"
                        >
                            <span>Jump</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 5l7 7m0 0l-7 7m7-7H3" />
                            </svg>
                        </button>
                     </div>
                     <h3 class="text-sm font-semibold text-gray-800 mb-2 leading-tight">{{ event.chapter_title }}</h3>
                     
                     <ul class="space-y-2">
                        <li 
                            v-for="(sent, idx) in event.content" 
                            :key="idx"
                            class="text-xs text-gray-600 leading-relaxed bg-white p-3 rounded shadow-sm border border-gray-100"
                        >
                            {{ sent }}
                        </li>
                     </ul>
                 </div>
            </div>
            
            <div class="text-center pt-8 pb-4">
                <span class="text-xs text-gray-400 font-medium bg-gray-100 px-3 py-1 rounded-full">End of Records</span>
            </div>
        </div>
        
        <div v-else-if="!isLoading" class="flex flex-col items-center justify-center h-64 text-gray-400">
             <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12 mb-4 text-gray-300" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z" />
             </svg>
             <p>No timeline data found.</p>
        </div>
    </div>
  </div>

  <!-- Overlay -->
  <div 
    v-if="isOpen"
    class="fixed inset-0 bg-black/20 backdrop-blur-sm z-40 transition-opacity"
    @click="emit('close')"
  ></div>
</template>

<style scoped>
.custom-scrollbar::-webkit-scrollbar {
  width: 5px;
}
.custom-scrollbar::-webkit-scrollbar-track {
  background: transparent;
}
.custom-scrollbar::-webkit-scrollbar-thumb {
  background: #cbd5e1;
  border-radius: 2px;
}
</style>


==================== FILE: frontend\src\components\GraphView.vue ====================

<script setup lang="ts">
import { onMounted, ref, watch, onUnmounted, computed, shallowRef } from 'vue';
import { Network, DataSet } from "vis-network/standalone";
import type { Entity, TimelineEvent, RelationshipTimelineEvent } from '@/types';
import { API } from '@/api/client';
import EntityChronicleDrawer from './EntityChronicleDrawer.vue';
import RelationshipArcDrawer from './RelationshipArcDrawer.vue';
import { useNovelStore } from '@/stores/novel';
import { useJobStore } from '@/stores/jobStore';

const store = useNovelStore();
const jobStore = useJobStore();

const container = ref<HTMLElement | null>(null);
const network = shallowRef<Network | null>(null);

// State for filtering
const minWeight = ref(1);
const selectedTypes = ref<string[]>(['Person', 'Location', 'Organization', 'Event', 'Object', 'Concept']);
const availableTypes = ['Person', 'Location', 'Organization', 'Event', 'Object', 'Concept'];

// State for Timeline
const timelineIndex = ref(0);
const maxTimelineIndex = computed(() => (store.chapters.length > 0 ? store.chapters.length - 1 : 0));
const graphMode = ref<'cumulative' | 'focus'>('cumulative');

// Chronicle State
const isChronicleOpen = ref(false);
const chronicleEvents = ref<TimelineEvent[]>([]);
const isChronicleLoading = ref(false);
const selectedEntity = ref<Entity | null>(null);

// Relationship Arc State
const selectedNodes = ref<Entity[]>([]);
const isRelationshipDrawerOpen = ref(false);
const relationshipEvents = ref<RelationshipTimelineEvent[]>([]);
const isRelationshipLoading = ref(false);

// Stats
const stats = computed(() => {
    if (!store.graphData) return { nodes: 0, edges: 0 };
    return {
        nodes: nodesDataSet.length,
        edges: edgesDataSet.length
    };
});

// Vis.js DataSets
const nodesDataSet = new DataSet<any>();
const edgesDataSet = new DataSet<any>();

const debugMapSize = ref(0);
const lastError = ref<string>("");

const typeColors: Record<string, string> = {
  'Person': '#fbbf24', // amber-400
  'Location': '#60a5fa', // blue-400
  'Organization': '#a78bfa', // purple-400
  'Event': '#f87171', // red-400
  'Object': '#34d399', // emerald-400
  'Concept': '#f472b6', // pink-400
  'Other': '#9ca3af'   // gray-400
};

const typeShapes: Record<string, string> = {
  'Person': 'dot',
  'Location': 'triangle',
  'Organization': 'square',
  'Event': 'star',
  'Object': 'diamond',
  'Concept': 'hexagon',
  'Other': 'dot'
};

const typeLabels: Record<string, string> = {
  'Person': '人物',
  'Location': '地点',
  'Organization': '组织',
  'Event': '事件',
  'Object': '物品',
  'Concept': '概念',
  'Other': '其他'
};

// --- Async Analysis Logic ---

const handleAnalyzeRelationship = async () => {
    if (selectedNodes.value.length !== 2 || !store.currentNovel || !store.currentRun) return;
    
    // 1. Check Threshold (Warning)
    // We need to check if they have enough interactions.
    // We can use the graph data for this.
    // Find the edge between them
    const n1 = selectedNodes.value[0].name;
    const n2 = selectedNodes.value[1].name;
    
    // This logic is a bit naive because we don't have the edge object readily available in `selectedNodes`
    // But we can find it in store.graphData.edges
    // Or we can just let the backend handle it?
    // The design spec said "Frontend checks edge.weight".
    // Let's find the edge.
    const edge = store.graphData?.edges.find(e => 
        (e.source === n1 && e.target === n2) || (e.source === n2 && e.target === n1)
    );
    
    const weight = edge ? edge.weight : 0;
    const coOccurrence = edge?.timeline?.length || 0; // Approximate co-occurrence by timeline events
    
    if (weight < 3 && coOccurrence < 3) {
        if (!confirm(`这两位角色的互动较少 (权重 ${weight}, 事件 ${coOccurrence})。\n深度分析可能产生幻觉或内容稀疏。\n是否继续？`)) {
            return;
        }
    }
    
    // 2. Submit Job
    try {
        const hash = store.currentNovel.hashes[0];
        // If force is true, we might want to delete cache first?
        // Actually, the backend job runner doesn't auto-delete unless we tell it to, or we handle it here.
        // But for "Analyze", we usually mean "Compute if missing".
        // If the user wants to RE-analyze, they should probably clear cache.
        
        await jobStore.submitRelationshipJob({
            novel_name: store.currentNovel.name,
            file_hash: hash,
            source: n1,
            target: n2,
            force: true
        });
        
        // Deselect or just notify?
        // The JobStatusWidget will appear.
    } catch (e) {
        alert("Failed to start analysis: " + e);
    }
};

const handleClearCache = async () => {
    if (selectedNodes.value.length !== 2 || !store.currentNovel) return;
    
    const n1 = selectedNodes.value[0].name;
    const n2 = selectedNodes.value[1].name;
    
    if (!confirm(`确定要清除 "${n1} & ${n2}" 的分析缓存吗？\n清除后需要重新运行 AI 分析。`)) return;
    
    try {
        const hash = store.currentNovel.hashes[0];
        await API.deleteRelationshipAnalysis(
            store.currentNovel.name, 
            hash, 
            n1, 
            n2
        );
        alert("缓存已清除，请重新点击 Analyze 进行分析。");
        // Close drawer if open
        isRelationshipDrawerOpen.value = false;
        relationshipEvents.value = [];
    } catch (e) {
        alert("清除缓存失败: " + e);
    }
};

const openRelationshipDrawer = async () => {
    if (selectedNodes.value.length !== 2 || !store.currentNovel || !store.currentRun) return;
    
    isRelationshipDrawerOpen.value = true;
    isRelationshipLoading.value = true;
    
    try {
        const hash = store.currentNovel.hashes[0];
        relationshipEvents.value = await API.fetchRelationshipTimeline(
            store.currentNovel.name,
            hash,
            store.currentRun.timestamp,
            selectedNodes.value[0].name,
            selectedNodes.value[1].name
        );
    } catch (e) {
        console.error("Failed to fetch relationship timeline:", e);
    } finally {
        isRelationshipLoading.value = false;
    }
};

// Listen for global event to open drawer after analysis
onMounted(() => {
    window.addEventListener('open-relationship-result', handleAnalysisResult as EventListener);
});

onUnmounted(() => {
    window.removeEventListener('open-relationship-result', handleAnalysisResult as EventListener);
});

const handleAnalysisResult = (e: CustomEvent) => {
    const result = e.detail;
    // result contains { pair_id: "A_B", ... }
    // We need to parse pair_id to find source/target names?
    // Or simpler: Just check if the currently selected nodes match the result?
    // If user changed selection, we might not want to open drawer blindly.
    // But for better UX, we should probably parse the pair_id and set selectedNodes.
    
    // For now, let's just trigger the drawer refresh if the selected nodes match.
    // Or if the user clicks "View Result", we assume they want to see THAT result.
    // So we should ideally open the drawer for the entities involved in the job.
    // The job result has `pair_id`.
    
    // Let's assume we just open the drawer for the current selection for now
    // as that's the most common flow (User waits).
    if (selectedNodes.value.length === 2) {
         openRelationshipDrawer();
    }
};

const openChronicle = async () => {
    if (!selectedEntity.value || !store.currentNovel || !store.currentRun) return;
    
    isChronicleOpen.value = true;
    isChronicleLoading.value = true;
    
    try {
        const hash = store.currentNovel.hashes[0];
        chronicleEvents.value = await API.fetchEntityTimeline(
            store.currentNovel.name,
            hash,
            store.currentRun.timestamp,
            selectedEntity.value.name
        );
    } catch (e) {
        console.error("Failed to fetch chronicle:", e);
    } finally {
        isChronicleLoading.value = false;
    }
};

const handleChronicleJump = async (chapterId: string) => {
    store.selectedChapterId = chapterId;
    await store.loadChapterDetail(chapterId);
    store.viewMode = 'reader'; // Switch to reader mode directly
    isChronicleOpen.value = false;
    isRelationshipDrawerOpen.value = false;
};

// --- Graph Logic ---

const initGraph = () => {
  if (!container.value) return;

  const data = {
    nodes: nodesDataSet,
    edges: edgesDataSet
  };

  const options = {
    nodes: {
      shape: 'dot',
      font: {
        size: 14,
        color: '#374151' // gray-700
      },
      borderWidth: 2,
      shadow: true
    },
    edges: {
      width: 1,
      color: { color: '#d1d5db', highlight: '#6366f1' }, // gray-300, indigo-500
      smooth: {
        type: 'continuous'
      },
      arrows: {
          to: { enabled: false } // undirected by default
      }
    },
    physics: {
      stabilization: {
          enabled: true,
          iterations: 100
      },
      barnesHut: {
        gravitationalConstant: -30000,
        springLength: 200,
        springConstant: 0.04,
        damping: 0.09
      }
    },
    interaction: {
      hover: true,
      tooltipDelay: 200,
      hideEdgesOnDrag: true,
      multiselect: true
    }
  };

  network.value = new Network(container.value, data, options);

  // Event listeners
  network.value.on("click", (params) => {
    const selectedIds = params.nodes;
    
    if (selectedIds.length === 1) {
      const nodeId = selectedIds[0];
      const entity = store.graphData?.nodes.find(n => n.name === nodeId);
      if (entity) {
        selectedEntity.value = entity;
      }
      selectedNodes.value = [];
    } else if (selectedIds.length === 2) {
      selectedEntity.value = null;
      const n1 = store.graphData?.nodes.find(n => n.name === selectedIds[0]);
      const n2 = store.graphData?.nodes.find(n => n.name === selectedIds[1]);
      if (n1 && n2) {
          selectedNodes.value = [n1, n2];
      }
    } else {
        selectedEntity.value = null;
        selectedNodes.value = [];
    }
  });

  // Initial update if data is already available
  if (store.graphData) {
      updateGraphData();
  }
};

const updateGraphData = () => {
    if (!store.graphData) return;

    // 1. Filter Nodes
    const activeNodes = store.graphData.nodes.filter(node => {
        // Type filter
        if (!selectedTypes.value.includes(node.type)) return false;
        
        // Timeline filter: Node must appear in chapters <= timelineIndex
        if (store.chapters.length === 0) return true;

        // Use strict ID matching
        const hasAppeared = node.chapter_ids?.some(id => {
            const chIdStr = String(id);
            const chIndex = store.chapters.findIndex(c => String(c.id) === chIdStr);
            return chIndex !== -1 && chIndex <= timelineIndex.value;
        });

        return hasAppeared ?? false;
    });

    // 2. Filter Edges
    const currentChapter = store.chapters[timelineIndex.value];
    if (!currentChapter) return;
    
    // Ensure strict string comparison
    const currentChapterId = String(currentChapter.id); 
    
    const activeEdges: any[] = [];
    const nodeWeights: Record<string, number> = {};

    try {
        // Optimization: Create map for O(1) chapter index lookup
        const chapterIndexMap = new Map<string, number>();
        store.chapters.forEach((c, idx) => {
            chapterIndexMap.set(String(c.id), idx);
        });
        debugMapSize.value = chapterIndexMap.size;
        
        store.graphData.edges.forEach((edge) => {
            if (!edge.timeline) return;

            let weight = 0;
            let label = '';
            let isVisible = false;

            if (graphMode.value === 'cumulative') {
                // Sum weights of all events where chapter_index <= timelineIndex
                for (const event of edge.timeline) {
                    const evtChId = String(event.chapter_id);
                    const chIndex = chapterIndexMap.get(evtChId);
                    
                    if (chIndex !== undefined && chIndex <= timelineIndex.value) {
                        weight += (event.weight || 1);
                    }
                }
                isVisible = weight >= minWeight.value;

            } else { // Focus Mode
                // Only events matching current chapter ID
                for (const event of edge.timeline) {
                    const evtChId = String(event.chapter_id);
                    if (evtChId === currentChapterId) {
                        weight += (event.weight || 1);
                        label = event.relation || '';
                    }
                }
                isVisible = weight >= 1; 
            }

            if (isVisible) {
                activeEdges.push({
                    from: edge.source,
                    to: edge.target,
                    value: weight,
                    label: graphMode.value === 'focus' ? label : undefined,
                    font: { align: 'middle', size: 10, strokeWidth: 2, strokeColor: '#ffffff' }
                });
                
                // Accumulate node weights
                nodeWeights[edge.source] = (nodeWeights[edge.source] || 0) + weight;
                nodeWeights[edge.target] = (nodeWeights[edge.target] || 0) + weight;
            }
        });
        
    } catch (err: any) {
        console.error("Error processing graph edges:", err);
        lastError.value = err.toString();
    }

    // 3. Filter Nodes based on Edges (Hide isolated nodes if configured, or just update sizing)
    // Filter out nodes with 0 degree if strict filtering is needed
    // For now, let's keep all type-filtered nodes but update their size
    const processedNodeIds = new Set<string>();
    
    const visNodes = activeNodes.map(node => {
        // Defensive check: Skip if ID already processed
        if (processedNodeIds.has(node.name)) {
            console.warn(`[GraphView] Duplicate node ID skipped: ${node.name}`);
            return null;
        }
        
        const degree = nodeWeights[node.name] || 0;
        
        // In Focus mode, hide nodes with no interaction in this chapter
        if (graphMode.value === 'focus' && degree === 0) return null;
        
        // In Cumulative mode, always hide isolated nodes to prevent layout explosion
        if (graphMode.value === 'cumulative' && degree === 0) return null;

        processedNodeIds.add(node.name);

        return {
            id: node.name,
            label: node.name,
            value: Math.log(degree + 1) * 10 + 5, // Log scale size
            color: typeColors[node.type] || typeColors['Other'],
            shape: typeShapes[node.type] || typeShapes['Other'],
            title: node.description // Tooltip
        };
    }).filter(n => n !== null);

    // Update DataSets
    nodesDataSet.clear();
    nodesDataSet.add(visNodes);
    
    edgesDataSet.clear();
    edgesDataSet.add(activeEdges);

    // Update Physics based on Mode
    if (network.value) {
        if (graphMode.value === 'focus') {
             network.value.setOptions({
                physics: {
                    barnesHut: {
                        gravitationalConstant: -20000, // Stronger repulsion
                        springLength: 200 // Longer springs
                    }
                }
            });
        } else {
             network.value.setOptions({
                physics: {
                    barnesHut: {
                        gravitationalConstant: -10000,
                        springLength: 120
                    }
                }
            });
        }
    }
};

// --- Interactions ---

const toggleType = (type: string) => {
    if (selectedTypes.value.includes(type)) {
        selectedTypes.value = selectedTypes.value.filter(t => t !== type);
    } else {
        selectedTypes.value = [...selectedTypes.value, type]; // Immutable update
    }
};

const prevChapter = () => {
    if (timelineIndex.value > 0) timelineIndex.value--;
};

const nextChapter = () => {
    if (timelineIndex.value < maxTimelineIndex.value) timelineIndex.value++;
};

// Watchers
watch([() => store.graphData, selectedTypes, minWeight, timelineIndex, graphMode], () => {
    updateGraphData();
}, { deep: true });

// Lifecycle
onMounted(async () => {
    await store.loadGraphData();
    initGraph();
    
    // Keyboard shortcuts
    window.addEventListener('keydown', handleKeydown);
});

onUnmounted(() => {
    window.removeEventListener('keydown', handleKeydown);
});

const handleKeydown = (e: KeyboardEvent) => {
    if (store.viewMode !== 'graph') return;
    
    if (e.key === 'ArrowLeft') prevChapter();
    if (e.key === 'ArrowRight') nextChapter();
};

// Computed Display Description
const displayDescription = computed(() => {
    if (!selectedEntity.value) return '';
    
    // Find history entry for current chapter or latest before it
    if (!selectedEntity.value.history) return selectedEntity.value.description;

    const currentChapterId = store.chapters[timelineIndex.value]?.id;
    if (!currentChapterId) return selectedEntity.value.description;

    if (graphMode.value === 'focus') {
        // Exact match
        const entry = selectedEntity.value.history.find(h => h.chapter_id === currentChapterId);
        return entry ? entry.content : "未在本章出现";
    } else {
        // Latest up to current
        // Assuming history is sorted? Or we need to sort.
        // Let's assume history is chronological.
        // We find the last entry where chapter index <= timelineIndex
        // This requires chapter index mapping.
        // Simplified: Just show the main description which is usually the aggregated one.
        return selectedEntity.value.description;
    }
});

</script>

<template>
  <div class="h-full flex relative overflow-hidden">
    <!-- Main Canvas -->
    <div ref="container" class="flex-1 bg-gray-50 outline-none"></div>

    <!-- Controls Overlay -->
    <div class="absolute top-4 left-4 bg-white/90 backdrop-blur p-4 rounded-xl shadow-lg border border-gray-200 w-64 z-10 flex flex-col gap-4">
        <!-- Mode Switch -->
        <div class="flex bg-gray-100 p-1 rounded-lg">
            <button 
                @click="graphMode = 'cumulative'"
                class="flex-1 py-1 text-xs font-bold rounded-md transition-all"
                :class="graphMode === 'cumulative' ? 'bg-white shadow text-indigo-600' : 'text-gray-500'"
            >
                全局累积
            </button>
            <button 
                @click="graphMode = 'focus'"
                class="flex-1 py-1 text-xs font-bold rounded-md transition-all"
                :class="graphMode === 'focus' ? 'bg-white shadow text-indigo-600' : 'text-gray-500'"
            >
                单章专注
            </button>
        </div>

        <!-- Timeline Control -->
        <div class="space-y-2">
            <div class="flex justify-between text-xs font-bold text-gray-500 uppercase">
                <span>Timeline</span>
                <!-- Hide ID, just show chapter index/progress -->
                <span>{{ timelineIndex + 1 }} / {{ maxTimelineIndex + 1 }}</span>
            </div>
            
            <!-- Slider -->

            <input 
                type="range" 
                min="0" 
                :max="maxTimelineIndex" 
                v-model.number="timelineIndex"
                class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-indigo-600"
            >

            <!-- Navigation Buttons -->
            <div class="flex gap-2">
                <button @click="prevChapter" :disabled="timelineIndex <= 0" class="flex-1 bg-gray-100 hover:bg-gray-200 text-gray-600 rounded px-2 py-1 text-xs disabled:opacity-50">
                    &larr; Prev
                </button>
                <button @click="nextChapter" :disabled="timelineIndex >= maxTimelineIndex" class="flex-1 bg-gray-100 hover:bg-gray-200 text-gray-600 rounded px-2 py-1 text-xs disabled:opacity-50">
                    Next &rarr;
                </button>
            </div>
            
            <!-- Chapter Jump -->
            <select v-model.number="timelineIndex" class="w-full text-xs border-gray-200 rounded bg-gray-50">
                <option v-for="(chap, idx) in store.chapters" :key="chap.id" :value="idx">
                    {{ idx + 1 }}: {{ chap.title }}
                </option>
            </select>
        </div>

        <hr class="border-gray-100">

        <!-- Type Filters -->
        <div class="space-y-2">
            <span class="text-xs font-bold text-gray-500 uppercase">Filters & Legend</span>
            <div class="flex flex-col gap-1.5">
                <button 
                    v-for="type in availableTypes" 
                    :key="type"
                    @click="toggleType(type)"
                    class="px-2 py-1.5 rounded-lg text-xs font-medium transition-all border flex items-center justify-between group"
                    :class="selectedTypes.includes(type) 
                        ? 'bg-white border-gray-200 shadow-sm hover:border-indigo-300' 
                        : 'bg-gray-50 text-gray-400 border-transparent hover:bg-gray-100'"
                >
                    <div class="flex items-center gap-2">
                         <!-- Legend Icon -->
                        <div 
                            class="w-3 h-3 flex items-center justify-center"
                            :style="{ color: typeColors[type] }"
                        >
                            <!-- Dot -->
                            <div v-if="typeShapes[type] === 'dot'" class="w-2.5 h-2.5 rounded-full bg-current"></div>
                            <!-- Square -->
                            <div v-else-if="typeShapes[type] === 'square'" class="w-2.5 h-2.5 bg-current rounded-[1px]"></div>
                            <!-- Triangle (CSS) -->
                            <div v-else-if="typeShapes[type] === 'triangle'" class="w-0 h-0 border-l-[5px] border-r-[5px] border-b-[9px] border-l-transparent border-r-transparent border-b-current mb-0.5"></div>
                             <!-- Diamond (CSS) -->
                            <div v-else-if="typeShapes[type] === 'diamond'" class="w-2 h-2 bg-current rotate-45"></div>
                            <!-- Star (SVG) -->
                            <svg v-else-if="typeShapes[type] === 'star'" viewBox="0 0 24 24" fill="currentColor" class="w-3 h-3">
                                <path d="M12 2l3.09 6.26L22 9.27l-5 4.87 1.18 6.88L12 17.77l-6.18 3.25L7 14.14 2 9.27l6.91-1.01L12 2z"/>
                            </svg>
                             <!-- Hexagon (SVG) -->
                            <svg v-else-if="typeShapes[type] === 'hexagon'" viewBox="0 0 24 24" fill="currentColor" class="w-3 h-3">
                                <path d="M12 2l8.66 5v10L12 22l-8.66-5V7L12 2z"/>
                            </svg>
                        </div>
                        <span :class="selectedTypes.includes(type) ? 'text-gray-700' : 'text-gray-400'">
                            {{ typeLabels[type] || type }}
                        </span>
                    </div>
                    
                    <!-- Checkmark -->
                    <div class="w-4 h-4 rounded-full border flex items-center justify-center transition-colors"
                        :class="selectedTypes.includes(type) ? 'border-indigo-500 bg-indigo-500 text-white' : 'border-gray-300'"
                    >
                        <svg v-if="selectedTypes.includes(type)" xmlns="http://www.w3.org/2000/svg" class="h-2.5 w-2.5" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd" />
                        </svg>
                    </div>
                </button>
            </div>
        </div>

        <!-- Weight Slider -->
        <div class="space-y-1" v-if="graphMode === 'cumulative'">
            <div class="flex justify-between text-xs text-gray-400">
                <span>Min Interactions</span>
                <span>{{ minWeight }}</span>
            </div>
            <input 
                type="range" 
                min="1" 
                max="10" 
                v-model.number="minWeight"
                class="w-full h-1 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-indigo-400"
            >
        </div>
        
        <!-- Stats -->
        <div class="text-[10px] text-gray-400 font-mono text-center pt-2">
            {{ stats.nodes }} Nodes · {{ stats.edges }} Edges
        </div>

        <!-- Debug Info (Temporary) -->
        <div class="text-[10px] text-red-500 font-mono bg-red-50 p-2 rounded border border-red-200 opacity-70 hover:opacity-100">
            <div>Idx: {{ timelineIndex }} / {{ maxTimelineIndex }}</div>
            <div>ChID: {{ store.chapters[timelineIndex]?.id }}</div>
            <div>Mode: {{ graphMode }}</div>
            <div>MapSize: {{ debugMapSize }}</div>
            <div v-if="timelineIndex >= 11">Debug: Ch 12+ Active</div>
        </div>
    </div>

    <!-- Entity Details Panel -->
    <div v-if="selectedEntity" class="absolute top-4 right-4 w-80 bg-white/95 backdrop-blur shadow-xl rounded-xl border border-gray-100 p-6 z-20 transition-all animate-in slide-in-from-right-4">
        <div class="flex items-start justify-between mb-4">
             <div 
                class="w-12 h-12 rounded-lg flex items-center justify-center text-xl font-bold shadow-sm"
                :style="{ backgroundColor: typeColors[selectedEntity.type] + '20', color: typeColors[selectedEntity.type] }"
            >
                {{ selectedEntity.name[0] }}
            </div>
            <button @click="selectedEntity = null" class="text-gray-400 hover:text-gray-600">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                    <path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd" />
                </svg>
            </button>
        </div>
        
        <h2 class="text-xl font-bold text-gray-900 mb-1">{{ selectedEntity.name }}</h2>
        <span class="inline-block px-2 py-0.5 rounded text-xs font-bold uppercase tracking-wider mb-4" :style="{ backgroundColor: typeColors[selectedEntity.type] + '20', color: typeColors[selectedEntity.type] }">
            {{ selectedEntity.type }}
        </span>

        <p class="text-sm text-gray-600 leading-relaxed mb-6 max-h-60 overflow-y-auto custom-scrollbar">
            {{ displayDescription }}
        </p>
        
        <div class="space-y-2">
             <button 
                @click="openChronicle"
                class="w-full py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-lg text-sm font-bold shadow-sm transition-colors flex items-center justify-center gap-2"
            >
                <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z" />
                </svg>
                查看编年史
            </button>
        </div>
    </div>

    <!-- Relationship Selection Panel -->
    <div v-if="selectedNodes.length === 2" class="absolute bottom-8 left-1/2 transform -translate-x-1/2 bg-white/95 backdrop-blur shadow-xl rounded-xl p-4 border border-gray-200 z-30 flex items-center gap-4 transition-all animate-in fade-in slide-in-from-bottom-4">
        <div class="flex items-center gap-2">
            <div class="flex -space-x-2">
                <div class="w-8 h-8 rounded-full bg-indigo-100 border-2 border-white flex items-center justify-center text-xs font-bold text-indigo-800">
                    {{ selectedNodes[0].name[0] }}
                </div>
                <div class="w-8 h-8 rounded-full bg-pink-100 border-2 border-white flex items-center justify-center text-xs font-bold text-pink-800">
                    {{ selectedNodes[1].name[0] }}
                </div>
            </div>
            <div class="flex flex-col">
                <span class="text-xs font-medium text-gray-500">Compare</span>
                <span class="text-sm font-bold text-gray-900 leading-none">
                    {{ selectedNodes[0].name }} & {{ selectedNodes[1].name }}
                </span>
            </div>
        </div>
        
        <div class="h-8 w-px bg-gray-200 mx-2"></div>
        
        <button 
            @click="openRelationshipDrawer"
            class="py-2 px-4 bg-indigo-600 hover:bg-indigo-700 text-white text-sm font-medium rounded-lg shadow-sm transition-colors flex items-center gap-2"
        >
            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 7h8m0 0v8m0-8l-8 8-4-4-6 6" />
            </svg>
            View Arc
        </button>
        
        <button 
            @click="handleAnalyzeRelationship"
            class="py-2 px-4 bg-white hover:bg-gray-50 text-indigo-600 border border-indigo-200 hover:border-indigo-300 text-sm font-medium rounded-lg shadow-sm transition-colors flex items-center gap-2"
            title="AI Analyze"
        >
            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19.428 15.428a2 2 0 00-1.022-.547l-2.384-.477a6 6 0 00-3.86.517l-.318.158a6 6 0 01-3.86.517L6.05 15.21a2 2 0 00-1.806.547M8 4h8l-1 1v5.172a2 2 0 00.586 1.414l5 5c1.26 1.26.367 3.414-1.415 3.414H4.828c-1.782 0-2.674-2.154-1.414-3.414l5-5A2 2 0 009 10.172V5L8 4z" />
            </svg>
            Analyze
        </button>

        <!-- Clear Cache Button -->
        <button 
            @click="handleClearCache"
            class="p-2 text-red-400 hover:text-red-600 hover:bg-red-50 rounded-lg transition-colors border border-transparent hover:border-red-200"
            title="Clear Analysis Cache"
        >
            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16" />
            </svg>
        </button>
        
        <button 
            @click="selectedNodes = []; network?.unselectAll()"
            class="p-2 text-gray-400 hover:text-gray-600 hover:bg-gray-100 rounded-lg transition-colors"
        >
            <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
            </svg>
        </button>
    </div>

    <!-- Relationship Drawer -->
    <RelationshipArcDrawer 
        v-if="selectedNodes.length === 2"
        :is-open="isRelationshipDrawerOpen"
        :source-entity="selectedNodes[0]"
        :target-entity="selectedNodes[1]"
        :events="relationshipEvents"
        :is-loading="isRelationshipLoading"
        @close="isRelationshipDrawerOpen = false"
        @jump-to-chapter="handleChronicleJump"
    />

    <!-- Chronicle Drawer -->
    <EntityChronicleDrawer 
        :is-open="isChronicleOpen"
        :entity-name="selectedEntity?.name || ''"
        :events="chronicleEvents"
        :is-loading="isChronicleLoading"
        @close="isChronicleOpen = false"
        @jump-to-chapter="handleChronicleJump"
    />
  </div>
</template>

<style scoped>
.custom-scrollbar::-webkit-scrollbar {
  width: 4px;
}
.custom-scrollbar::-webkit-scrollbar-track {
  background: transparent;
}
.custom-scrollbar::-webkit-scrollbar-thumb {
  background: #cbd5e1;
  border-radius: 2px;
}
</style>


==================== FILE: frontend\src\components\JobStatusWidget.vue ====================

<script setup lang="ts">
import { computed } from 'vue';
import { useJobStore } from '@/stores/jobStore';

const jobStore = useJobStore();
const job = computed(() => jobStore.activeJob);

// Don't show if no job
const isVisible = computed(() => !!job.value);

const statusColor = computed(() => {
    if (!job.value) return 'bg-gray-500';
    switch (job.value.status) {
        case 'pending': return 'bg-yellow-400';
        case 'processing': return 'bg-indigo-500';
        case 'completed': return 'bg-emerald-500';
        case 'failed': return 'bg-rose-500';
        default: return 'bg-gray-500';
    }
});

const progressWidth = computed(() => {
    return `${job.value?.progress || 0}%`;
});

function closeWidget() {
    jobStore.clearActiveJob();
}
</script>

<template>
    <div 
        v-if="isVisible"
        class="fixed bottom-6 right-6 z-50 flex flex-col items-end gap-2"
    >
        <!-- The Bubble Card -->
        <div class="bg-white rounded-2xl shadow-xl border border-gray-100 overflow-hidden w-80 transition-all duration-300 transform hover:scale-[1.02]">
            
            <!-- Header -->
            <div class="px-4 py-3 bg-gray-50/50 flex items-center justify-between border-b border-gray-100">
                <div class="flex items-center gap-2">
                    <span class="relative flex h-3 w-3">
                        <span 
                            v-if="job?.status === 'processing'"
                            class="animate-ping absolute inline-flex h-full w-full rounded-full opacity-75"
                            :class="statusColor"
                        ></span>
                        <span class="relative inline-flex rounded-full h-3 w-3" :class="statusColor"></span>
                    </span>
                    <span class="text-xs font-bold text-gray-700 uppercase tracking-wider">
                        {{ job?.status === 'processing' ? '正在分析 (ANALYZING)' : 
                           job?.status === 'completed' ? '分析完成 (READY)' :
                           job?.status === 'failed' ? '分析失败 (FAILED)' : '排队中 (PENDING)' }}
                    </span>
                </div>
                
                <button @click="closeWidget" class="text-gray-400 hover:text-gray-600">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>
            
            <!-- Body -->
            <div class="p-4">
                <p class="text-sm text-gray-600 font-medium mb-1 truncate">{{ job?.message }}</p>
                
                <!-- Progress Bar -->
                <div class="h-2 w-full bg-gray-100 rounded-full overflow-hidden">
                    <div 
                        class="h-full transition-all duration-500 ease-out"
                        :class="statusColor"
                        :style="{ width: progressWidth }"
                    ></div>
                </div>
                
                <div class="flex justify-between mt-2 text-[10px] text-gray-400 font-mono">
                    <span>{{ job?.progress }}%</span>
                    <span>{{ job?.type }}</span>
                </div>

                <!-- Result Action -->
                <div v-if="job?.status === 'completed'" class="mt-4">
                    <button 
                        class="w-full py-2 bg-emerald-50 text-emerald-600 hover:bg-emerald-100 rounded-lg text-xs font-bold transition-colors border border-emerald-100 flex items-center justify-center gap-2"
                        @click="$emit('view-result', job.result)"
                    >
                        <span>查看结果 (VIEW RESULT)</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z" />
                        </svg>
                    </button>
                </div>

                <!-- Error Action -->
                <div v-if="job?.status === 'failed'" class="mt-4">
                     <p class="text-xs text-rose-500 bg-rose-50 p-2 rounded mb-2">{{ job.error }}</p>
                     <button 
                        class="w-full py-2 bg-gray-50 text-gray-600 hover:bg-gray-100 rounded-lg text-xs font-bold transition-colors border border-gray-200"
                        @click="closeWidget"
                    >
                        关闭 (CLOSE)
                    </button>
                </div>
            </div>
        </div>
    </div>
</template>


==================== FILE: frontend\src\components\OverviewGrid.vue ====================

<script setup lang="ts">
import { useNovelStore } from '@/stores/novel';
import { computed, watch, nextTick } from 'vue';

const store = useNovelStore();

const chapters = computed(() => store.chapters);

// Auto-Scroll Logic
watch(() => store.selectedChapterId, (newId) => {
  if (!newId || store.viewMode !== 'overview') return;

  nextTick(() => {
    const el = document.getElementById(`card-${newId}`);
    if (el) {
      el.scrollIntoView({ behavior: 'smooth', block: 'center' });
      // Highlight effect
      el.classList.add('ring-4', 'ring-indigo-300');
      setTimeout(() => el.classList.remove('ring-4', 'ring-indigo-300'), 1500);
    } else {
        console.warn('Card not found', newId);
    }
  });
});

const enterIntensiveReading = async (chapterId: string) => {
  store.selectedChapterId = chapterId;
  await store.loadChapterDetail(chapterId);
  store.viewMode = 'focus';
};
</script>

<template>
  <div class="p-6 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-6 pb-24">
    <div 
      v-for="chap in chapters" 
      :key="chap.id"
      :id="`card-${chap.id}`"
      @click="enterIntensiveReading(chap.id)"
      class="bg-white p-5 rounded-xl shadow-sm border border-gray-100 hover:border-indigo-400 hover:shadow-lg cursor-pointer transition-all duration-300 group flex flex-col h-full"
      :class="{'ring-2 ring-indigo-500 bg-indigo-50/30': store.selectedChapterId === chap.id}"
    >
      <div class="flex justify-between items-start mb-3">
        <h3 class="font-bold text-gray-800 text-lg group-hover:text-indigo-600 transition-colors line-clamp-1" :title="chap.title">
          {{ chap.title }}
        </h3>
        <!-- ID display hidden for cleaner UI -->
        <!-- <span class="text-xs font-mono text-gray-400 bg-gray-50 px-2 py-1 rounded-full whitespace-nowrap">
          {{ chap.id }}
        </span> -->
      </div>
      
      <div class="flex-1 mb-4">
        <p class="text-sm text-gray-600 leading-relaxed line-clamp-4" v-if="chap.headline">
          {{ chap.headline }}
        </p>
        <p class="text-sm text-gray-400 italic" v-else>
          (暂无核心总结)
        </p>
      </div>

      <div class="mt-auto pt-4 border-t border-gray-50 flex justify-end">
        <button 
          @click.stop="enterIntensiveReading(chap.id)"
          class="text-xs bg-indigo-50 hover:bg-indigo-100 text-indigo-600 hover:text-indigo-800 px-4 py-2 rounded-full transition-colors font-semibold flex items-center gap-1 opacity-0 group-hover:opacity-100 translate-y-2 group-hover:translate-y-0 duration-300"
        >
          开始精读 &rarr;
        </button>
      </div>
    </div>
  </div>
</template>


==================== FILE: frontend\src\components\ReaderView.vue ====================

<script setup lang="ts">
import { useNovelStore } from '@/stores/novel';
import { computed, ref, nextTick, watch } from 'vue';

const store = useNovelStore();
const chapter = computed(() => store.currentChapter);
const activeSentenceIndex = ref<number | null>(null);
const contentContainer = ref<HTMLElement | null>(null);

const backToOverview = () => {
  store.viewMode = 'overview';
};

// Compute text segments for highlighting
const textSegments = computed(() => {
    if (!chapter.value?.content) return [];
    
    const content = chapter.value.content;
    const segments: { text: string; isHighlight: boolean; id?: string }[] = [];
    
    // If no active sentence or no spans, return full content as one segment
    if (activeSentenceIndex.value === null) {
        return [{ text: content, isHighlight: false }];
    }

    const sentence = chapter.value.summary_sentences[activeSentenceIndex.value];
    if (!sentence || !sentence.source_spans || sentence.source_spans.length === 0) {
        return [{ text: content, isHighlight: false }];
    }

    // Sort spans by start_index
    const spans = [...sentence.source_spans].sort((a, b) => a.start_index - b.start_index);
    
    let lastIndex = 0;
    
    spans.forEach((span, idx) => {
        // Add text before highlight
        if (span.start_index > lastIndex) {
            segments.push({
                text: content.slice(lastIndex, span.start_index),
                isHighlight: false
            });
        }
        
        // Add highlighted text
        // Ensure we don't go out of bounds
        const end = Math.min(span.end_index, content.length);
        if (end > span.start_index) {
            segments.push({
                text: content.slice(span.start_index, end),
                isHighlight: true,
                id: idx === 0 ? 'highlight-target' : undefined // Mark first highlight for scrolling
            });
        }
        
        lastIndex = end;
    });
    
    // Add remaining text
    if (lastIndex < content.length) {
        segments.push({
            text: content.slice(lastIndex),
            isHighlight: false
        });
    }
    
    return segments;
});

const handleSelect = (idx: number) => {
    // Toggle if clicking same item
    if (activeSentenceIndex.value === idx) {
        activeSentenceIndex.value = null;
    } else {
        activeSentenceIndex.value = idx;
    }
};

// Auto-scroll when active sentence changes
watch(activeSentenceIndex, async (newVal) => {
    if (newVal !== null) {
        await nextTick();
        const target = contentContainer.value?.querySelector('#highlight-target');
        if (target) {
            target.scrollIntoView({ behavior: 'smooth', block: 'center' });
        }
    }
});
</script>

<template>
  <div class="h-full w-full flex flex-col bg-white overflow-hidden" v-if="chapter">
    <!-- Header -->
    <div class="flex-none border-b border-gray-200 px-6 py-4 flex justify-between items-center bg-white z-10">
        <div class="flex items-center gap-4">
            <button 
              @click="backToOverview"
              class="text-sm text-gray-500 hover:text-indigo-600 flex items-center gap-1 transition-colors"
            >
              <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18" />
              </svg>
              返回概览
            </button>
            <h1 class="text-xl font-bold text-gray-900 truncate max-w-md" :title="chapter.title">{{ chapter.title }}</h1>
        </div>
        <!-- <div class="text-xs font-mono text-gray-400">ID: {{ chapter.id }}</div> -->
    </div>


    <!-- Split View -->
    <div class="flex-1 flex overflow-hidden">
        <!-- Left: Summary List -->
        <div class="w-1/3 min-w-[320px] max-w-md border-r border-gray-200 bg-gray-50 overflow-y-auto custom-scrollbar">
            <div class="p-6 space-y-4">
                <h2 class="text-sm font-bold text-gray-500 uppercase tracking-wider mb-4 px-2">智能总结</h2>
                
                <div 
                  v-for="(sent, idx) in chapter.summary_sentences" 
                  :key="idx"
                  @click="handleSelect(idx)"
                  class="p-4 rounded-xl cursor-pointer transition-all duration-200 border border-transparent"
                  :class="activeSentenceIndex === idx 
                    ? 'bg-white border-indigo-200 shadow-md ring-1 ring-indigo-500/20' 
                    : 'bg-white/50 hover:bg-white hover:border-gray-200 hover:shadow-sm'"
                >
                  <div class="flex gap-3">
                      <span 
                        class="flex-none w-6 h-6 rounded-full flex items-center justify-center text-xs font-bold transition-colors"
                        :class="activeSentenceIndex === idx ? 'bg-indigo-100 text-indigo-700' : 'bg-gray-200 text-gray-500'"
                      >
                        {{ idx + 1 }}
                      </span>
                      <p class="text-sm text-gray-700 leading-relaxed">{{ sent.summary_text }}</p>
                  </div>
                </div>
            </div>
        </div>

        <!-- Right: Content -->
        <div ref="contentContainer" class="flex-1 overflow-y-auto bg-white p-8 md:p-12 custom-scrollbar scroll-smooth">
            <div class="max-w-3xl mx-auto prose prose-lg text-gray-800 leading-loose">
                <!-- Use span segments for rendering to support highlighting -->
                <template v-for="(seg, i) in textSegments" :key="i">
                    <span 
                        v-if="seg.isHighlight"
                        :id="seg.id"
                        class="bg-yellow-200 text-gray-900 px-0.5 rounded transition-colors duration-500"
                    >{{ seg.text }}</span>
                    <span v-else class="whitespace-pre-wrap">{{ seg.text }}</span>
                </template>
                
                <div v-if="!chapter.content" class="text-gray-400 italic text-center py-20">
                    (原文内容未加载)
                </div>
            </div>
        </div>
    </div>
  </div>
</template>

<style scoped>
.custom-scrollbar::-webkit-scrollbar {
  width: 6px;
}
.custom-scrollbar::-webkit-scrollbar-track {
  background: transparent;
}
.custom-scrollbar::-webkit-scrollbar-thumb {
  background: #cbd5e1;
  border-radius: 3px;
}
.custom-scrollbar::-webkit-scrollbar-thumb:hover {
  background: #94a3b8;
}
</style>


==================== FILE: frontend\src\components\RelationshipArcDrawer.vue ====================

<script setup lang="ts">
import { computed } from 'vue';
import type { RelationshipTimelineEvent, Entity, NarrativeState } from '@/types';

const props = defineProps<{
  isOpen: boolean;
  sourceEntity: Entity | null;
  targetEntity: Entity | null;
  events: RelationshipTimelineEvent[];
  isLoading: boolean;
}>();

const emit = defineEmits<{
  (e: 'close'): void;
  (e: 'jump-to-chapter', chapterId: string): void;
}>();

// --- 1. State Processing & Localization ---

const sortedEvents = computed(() => {
    // Filter out events with no interactions unless they have narrative state
    // Sort by chapter index
    return [...props.events]
        .filter(e => (e.interactions && e.interactions.length > 0) || e.narrative_state)
        .sort((a, b) => a.chapter_index - b.chapter_index);
});

const currentState = computed<NarrativeState | undefined>(() => {
    // Find the latest narrative state from sorted events
    const events = sortedEvents.value;
    for (let i = events.length - 1; i >= 0; i--) {
        if (events[i].narrative_state) {
            return events[i].narrative_state;
        }
    }
    return undefined;
});

// --- 2. Timeline Compression Logic ---

interface TimelineBlock {
    type: 'event' | 'gap';
    data?: RelationshipTimelineEvent;
    gapStart?: number;
    gapEnd?: number;
}

const compressedTimeline = computed<TimelineBlock[]>(() => {
    if (!sortedEvents.value.length) return [];
    
    const blocks: TimelineBlock[] = [];
    let lastChapterIdx = -1;
    
    for (const event of sortedEvents.value) {
        const currentIdx = event.chapter_index;
        
        // Check for gap
        if (lastChapterIdx !== -1 && currentIdx > lastChapterIdx + 1) {
            blocks.push({
                type: 'gap',
                gapStart: lastChapterIdx + 1,
                gapEnd: currentIdx - 1
            });
        }
        
        blocks.push({
            type: 'event',
            data: event
        });
        
        lastChapterIdx = currentIdx;
    }
    
    return blocks;
});

// --- 3. UI Helpers ---

const typeStyles: Record<string, { bg: string, text: string, border: string }> = {
  'Person': { bg: 'bg-amber-50', text: 'text-amber-800', border: 'border-amber-200' },
  'Location': { bg: 'bg-blue-50', text: 'text-blue-800', border: 'border-blue-200' },
  'Organization': { bg: 'bg-purple-50', text: 'text-purple-800', border: 'border-purple-200' },
  'Event': { bg: 'bg-red-50', text: 'text-red-800', border: 'border-red-200' },
  'Object': { bg: 'bg-emerald-50', text: 'text-emerald-800', border: 'border-emerald-200' },
  'Concept': { bg: 'bg-pink-50', text: 'text-pink-800', border: 'border-pink-200' },
  'Other': { bg: 'bg-gray-50', text: 'text-gray-800', border: 'border-gray-200' }
};

const getStyle = (type: string) => typeStyles[type] || typeStyles['Other'];

</script>

<template>
  <!-- Drawer Container -->
  <div 
    class="fixed inset-y-0 right-0 w-[640px] bg-white shadow-2xl transform transition-transform duration-300 ease-in-out z-50 flex flex-col border-l border-gray-200"
    :class="isOpen ? 'translate-x-0' : 'translate-x-full'"
  >
    <!-- Header with 2 Entities -->
    <div class="p-6 border-b border-gray-100 flex-none bg-white/80 backdrop-blur z-10 relative">
        <!-- Close Button -->
        <button 
          @click="emit('close')"
          class="absolute top-4 right-4 p-2 rounded-full hover:bg-gray-100 text-gray-400 hover:text-gray-600 transition-colors z-20"
        >
          <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>

        <div class="text-xs font-mono text-gray-400 mb-6 uppercase tracking-wider">关系演化 (RELATIONSHIP ARC)</div>

        <div class="flex items-center justify-between gap-4">
            <!-- Source Entity (Left) -->
            <div v-if="sourceEntity" class="flex flex-col items-center flex-1 group cursor-default">
                 <div 
                    class="w-14 h-14 rounded-2xl flex items-center justify-center text-2xl font-bold shadow-sm mb-3 transition-transform group-hover:scale-105"
                    :class="getStyle(sourceEntity.type).bg + ' ' + getStyle(sourceEntity.type).text"
                >
                    {{ sourceEntity.name[0] }}
                </div>
                <span class="font-bold text-base text-center leading-tight text-gray-900">{{ sourceEntity.name }}</span>
                <span class="text-[10px] text-gray-400 mt-1 uppercase">{{ sourceEntity.type }}</span>
            </div>

            <!-- VS / Connection Icon -->
            <div class="flex flex-col items-center justify-center w-12 text-gray-300">
                <div class="w-full h-px bg-gray-200 mb-1"></div>
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 text-indigo-300" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7h12m0 0l-4-4m4 4l-4 4m0 6H4m0 0l4 4m-4-4l4-4" />
                </svg>
                <div class="w-full h-px bg-gray-200 mt-1"></div>
            </div>

            <!-- Target Entity (Right) -->
            <div v-if="targetEntity" class="flex flex-col items-center flex-1 group cursor-default">
                 <div 
                    class="w-14 h-14 rounded-2xl flex items-center justify-center text-2xl font-bold shadow-sm mb-3 transition-transform group-hover:scale-105"
                    :class="getStyle(targetEntity.type).bg + ' ' + getStyle(targetEntity.type).text"
                >
                    {{ targetEntity.name[0] }}
                </div>
                <span class="font-bold text-base text-center leading-tight text-gray-900">{{ targetEntity.name }}</span>
                <span class="text-[10px] text-gray-400 mt-1 uppercase">{{ targetEntity.type }}</span>
            </div>
        </div>
        
        <!-- Narrative State Insights (New) -->
        <div v-if="currentState" class="mt-6 pt-4 border-t border-gray-100">
             <div class="flex items-center justify-between mb-3">
                <span class="text-xs font-bold text-gray-400 uppercase tracking-wider">最新关系状态 (LATEST STATE)</span>
                <span class="px-2 py-0.5 rounded-full text-[10px] font-medium bg-indigo-50 text-indigo-600 border border-indigo-100">
                    {{ currentState.dominant_archetype }}
                </span>
             </div>
             
             <!-- Metrics -->
             <div class="grid grid-cols-3 gap-2 mb-3">
                <div class="bg-gray-50 rounded-lg p-2 text-center">
                    <div class="text-[10px] text-gray-400 uppercase">信任 (Trust)</div>
                    <div class="text-sm font-bold text-gray-700">{{ currentState.trust_level }}%</div>
                </div>
                <div class="bg-gray-50 rounded-lg p-2 text-center">
                    <div class="text-[10px] text-gray-400 uppercase">浪漫 (Romance)</div>
                    <div class="text-sm font-bold text-gray-700">{{ currentState.romance_level }}%</div>
                </div>
                <div class="bg-gray-50 rounded-lg p-2 text-center">
                    <div class="text-[10px] text-gray-400 uppercase">冲突 (Conflict)</div>
                    <div class="text-sm font-bold text-gray-700">{{ currentState.conflict_level }}%</div>
                </div>
             </div>
             
             <p class="text-xs text-gray-500 italic leading-relaxed bg-gray-50 p-3 rounded-lg border border-gray-100">
                "{{ currentState.summary_so_far }}"
             </p>
        </div>
    </div>

    <!-- Timeline Body -->
    <div class="flex-1 overflow-y-auto custom-scrollbar bg-gray-50/50 p-6 relative">
         <!-- Loading State -->
        <div v-if="isLoading" class="absolute inset-0 flex items-center justify-center bg-white/50 z-10">
            <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-indigo-600"></div>
        </div>

        <div v-if="events.length > 0" class="space-y-0">
            <template v-for="(block, index) in compressedTimeline" :key="index">
                
                <!-- GAP BLOCK -->
                <div v-if="block.type === 'gap'" class="flex justify-center py-6 relative">
                     <!-- Dotted Line -->
                     <div class="absolute left-1/2 top-0 bottom-0 w-px border-l-2 border-dotted border-gray-300 -ml-px"></div>
                     
                     <div class="relative z-10 bg-gray-100 text-gray-400 text-[10px] font-medium px-3 py-1 rounded-full border border-gray-200 shadow-sm">
                        第 {{ block.gapStart }} 章 - 第 {{ block.gapEnd }} 章 无互动
                     </div>
                </div>

                <!-- EVENT BLOCK -->
                <div v-else-if="block.type === 'event' && block.data" class="relative mb-8 pt-4">
                     <!-- Chapter Header (Sticky) -->
                     <div class="sticky top-0 z-20 flex justify-center mb-6">
                        <div 
                            class="bg-gray-50/95 backdrop-blur px-4 py-1.5 rounded-full border border-gray-200 shadow-sm flex items-center gap-2 cursor-pointer hover:bg-white hover:border-indigo-300 hover:shadow-md transition-all group"
                            @click="emit('jump-to-chapter', block.data.chapter_id)"
                        >
                            <span class="w-2 h-2 rounded-full bg-indigo-500 group-hover:scale-110 transition-transform"></span>
                            <span class="text-xs font-bold text-gray-600 group-hover:text-indigo-600">{{ block.data.chapter_title }}</span>
                        </div>
                     </div>

                     <!-- Timeline Grid -->
                     <div class="grid grid-cols-[1fr_2rem_1fr] gap-x-0 relative">
                        <!-- Central Line -->
                        <div class="absolute left-1/2 top-0 bottom-0 w-px bg-gray-200 -ml-px"></div>

                        <template v-for="(interaction, idx) in block.data.interactions" :key="idx">
                            <!-- Left Side (Forward: A -> B) -->
                            <div class="py-2 pr-4 flex justify-end">
                                <div v-if="interaction.direction === 'forward'" class="relative group max-w-[90%] w-full flex justify-end">
                                    <!-- Card Content -->
                                    <div class="bg-white p-3 rounded-xl border border-indigo-100 shadow-sm hover:shadow-md transition-all text-right relative w-full">
                                        <!-- Connector Dot -->
                                        <div class="absolute top-1/2 -right-[1.35rem] w-2.5 h-2.5 rounded-full bg-indigo-500 border-2 border-white z-10 shadow-sm"></div>
                                        <!-- Connector Line -->
                                        <div class="absolute top-1/2 -right-4 w-4 h-px bg-indigo-200"></div>

                                        <div class="flex items-center justify-end gap-2 mb-1">
                                             <div class="text-[10px] font-medium text-indigo-400 bg-indigo-50 px-1.5 py-0.5 rounded truncate max-w-[120px]">
                                                {{ sourceEntity?.name }} → {{ targetEntity?.name }}
                                            </div>
                                            <div class="text-xs font-bold text-indigo-600 uppercase tracking-wider whitespace-nowrap">{{ interaction.relation }}</div>
                                        </div>
                                        <p class="text-xs text-gray-700 leading-relaxed text-justify" style="text-align-last: right;">{{ interaction.description }}</p>
                                    </div>
                                </div>
                            </div>

                            <!-- Center Axis (Empty for spacing) -->
                            <div></div>

                            <!-- Right Side (Backward: B -> A) -->
                            <div class="py-2 pl-4 flex justify-start">
                                <div v-if="interaction.direction === 'backward'" class="relative group max-w-[90%] w-full flex justify-start">
                                    <!-- Card Content -->
                                    <div class="bg-white p-3 rounded-xl border border-rose-100 shadow-sm hover:shadow-md transition-all text-left relative w-full">
                                         <!-- Connector Dot -->
                                        <div class="absolute top-1/2 -left-[1.35rem] w-2.5 h-2.5 rounded-full bg-rose-500 border-2 border-white z-10 shadow-sm"></div>
                                        <!-- Connector Line -->
                                        <div class="absolute top-1/2 -left-4 w-4 h-px bg-rose-200"></div>

                                        <div class="flex items-center justify-start gap-2 mb-1">
                                            <div class="text-xs font-bold text-rose-600 uppercase tracking-wider whitespace-nowrap">{{ interaction.relation }}</div>
                                            <div class="text-[10px] font-medium text-rose-400 bg-rose-50 px-1.5 py-0.5 rounded truncate max-w-[120px]">
                                                {{ targetEntity?.name }} → {{ sourceEntity?.name }}
                                            </div>
                                        </div>
                                        <p class="text-xs text-gray-700 leading-relaxed text-justify">{{ interaction.description }}</p>
                                    </div>
                                </div>
                            </div>
                        </template>
                     </div>
                </div>

            </template>
            
            <div class="text-center pt-8 pb-4">
                <span class="text-xs text-gray-400 font-medium bg-gray-100 px-3 py-1 rounded-full">时间轴结束 (End of Timeline)</span>
            </div>
        </div>
        
        <div v-else-if="!isLoading" class="flex flex-col items-center justify-center h-64 text-gray-400">
             <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12 mb-4 text-gray-300" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M13 10V3L4 14h7v7l9-11h-7z" />
             </svg>
             <p>未发现互动记录 (No interactions found)</p>
        </div>
    </div>
  </div>

  <!-- Overlay -->
  <div 
    v-if="isOpen"
    class="fixed inset-0 bg-black/20 backdrop-blur-sm z-40 transition-opacity"
    @click="emit('close')"
  ></div>
</template>

<style scoped>
.custom-scrollbar::-webkit-scrollbar {
  width: 5px;
}
.custom-scrollbar::-webkit-scrollbar-track {
  background: transparent;
}
.custom-scrollbar::-webkit-scrollbar-thumb {
  background: #cbd5e1;
  border-radius: 2px;
}
</style>


==================== FILE: frontend\src\router\index.ts ====================

import { createRouter, createWebHistory } from 'vue-router'
import Dashboard from '@/views/Dashboard.vue'

const router = createRouter({
  history: createWebHistory(),
  routes: [
    {
      path: '/',
      name: 'home',
      component: Dashboard
    },
  ]
})

export default router


==================== FILE: frontend\src\stores\jobStore.ts ====================

import { defineStore } from 'pinia';
import { ref, computed } from 'vue';
import axios from 'axios';

// --- Interfaces ---
export interface JobStatus {
  job_id: string;
  type: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress: number;
  message: string;
  result?: any;
  error?: string;
  created_at: number;
  updated_at: number;
}

export interface RelationshipJobRequest {
  novel_name: string;
  file_hash: string;
  source: string;
  target: string;
  force?: boolean;
}

export const useJobStore = defineStore('jobs', () => {
  // State
  const activeJobId = ref<string | null>(null);
  const jobs = ref<Record<string, JobStatus>>({});
  const isPolling = ref(false);
  const pollingInterval = ref<number | null>(null);

  // Getters
  const activeJob = computed(() => activeJobId.value ? jobs.value[activeJobId.value] : null);
  const allJobs = computed(() => Object.values(jobs.value).sort((a, b) => b.created_at - a.created_at));

  // Actions
  async function submitRelationshipJob(request: RelationshipJobRequest) {
    if (activeJobId.value && jobs.value[activeJobId.value].status === 'processing') {
      console.warn("Already running a job.");
      // Optionally allow queueing, but for now just warn
    }

    try {
      const response = await axios.post('http://localhost:8000/api/jobs/relationship', request);
      const jobId = response.data.job_id;
      
      // Initialize job placeholder
      jobs.value[jobId] = {
        job_id: jobId,
        type: 'relationship_analysis',
        status: 'pending',
        progress: 0,
        message: 'Job submitted',
        created_at: Date.now() / 1000,
        updated_at: Date.now() / 1000
      };
      
      activeJobId.value = jobId;
      startPolling();
      return jobId;
    } catch (error) {
      console.error("Failed to submit job:", error);
      throw error;
    }
  }

  async function fetchJobStatus(jobId: string) {
    try {
      const response = await axios.get<JobStatus>(`http://localhost:8000/api/jobs/${jobId}`);
      const job = response.data;
      jobs.value[jobId] = job;
      
      // Update active job status logic
      if (job.status === 'completed' || job.status === 'failed') {
          // Keep it active so user can see result, but stop polling if no other jobs?
          // Actually we only poll the active one for now.
          stopPolling();
      }
      return job;
    } catch (error) {
      console.error(`Failed to fetch job ${jobId}:`, error);
    }
  }

  function startPolling() {
    // If already polling, don't start another interval
    if (pollingInterval.value !== null) return;
    
    isPolling.value = true;
    pollingInterval.value = window.setInterval(async () => {
      if (activeJobId.value) {
        // Only fetch if status is not final
        const job = jobs.value[activeJobId.value];
        if (job && (job.status === 'completed' || job.status === 'failed')) {
            stopPolling();
            return;
        }
        await fetchJobStatus(activeJobId.value);
      } else {
        stopPolling();
      }
    }, 2000); // Poll every 2 seconds
  }

  function stopPolling() {
    if (pollingInterval.value) {
      clearInterval(pollingInterval.value);
      pollingInterval.value = null;
    }
    isPolling.value = false;
  }
  
  function clearActiveJob() {
      activeJobId.value = null;
      stopPolling();
  }

  return {
    activeJobId,
    jobs,
    activeJob,
    allJobs,
    submitRelationshipJob,
    fetchJobStatus,
    clearActiveJob
  };
});


==================== FILE: frontend\src\stores\novel.ts ====================

import { defineStore } from 'pinia';
import { API } from '@/api/client';
import type { Novel, Run, Chapter, Entity, GraphData } from '@/types';

export const useNovelStore = defineStore('novel', {
  state: () => ({
    novels: [] as Novel[],
    runs: [] as Run[],
    chapters: [] as Chapter[],
    currentNovel: null as Novel | null,
    currentRun: null as Run | null,
    currentChapter: null as Chapter | null,
    selectedChapterId: null as string | null,
    
    // Graph Data
    graphData: null as GraphData | null,
    globalEntities: [] as Entity[],

    // UI State
    loading: false,
    viewMode: 'overview' as 'overview' | 'focus' | 'encyclopedia' | 'graph',
    error: null as string | null,
  }),

  actions: {
    async loadNovels() {
      this.loading = true;
      try {
        this.novels = await API.fetchNovels();
      } catch (e: any) {
        this.error = e.message;
      } finally {
        this.loading = false;
      }
    },

    async selectNovel(novel: Novel) {
      this.currentNovel = novel;
      this.currentRun = null;
      this.chapters = [];
      this.graphData = null;
      
      // Load runs
      if (novel.hashes.length > 0) {
        const hash = novel.hashes[0];
        if (!hash) return;
        
        const runs = await API.fetchRuns(novel.name, hash);
        this.runs = runs;
        const latestRun = runs[0];
        if (latestRun) {
          await this.selectRun(latestRun);
        }
      }
    },

    async selectRun(run: Run) {
      if (!this.currentNovel) return;
      const hash = this.currentNovel.hashes[0];
      if (!hash) return;

      this.currentRun = run;
      this.loading = true;
      try {
        this.chapters = await API.fetchChapters(this.currentNovel.name, hash, run.timestamp);
        // Reset view to overview on new run
        this.viewMode = 'overview';
      } catch (e: any) {
        this.error = e.message;
      } finally {
        this.loading = false;
      }
    },

    async loadChapterDetail(chapterId: string) {
      if (!this.currentNovel || !this.currentRun) return;
      const hash = this.currentNovel.hashes[0];
      if (!hash) return;

      this.loading = true;
      try {
        const chapter = await API.fetchChapterDetail(this.currentNovel.name, hash, this.currentRun.timestamp, chapterId);
        this.currentChapter = chapter;
      } catch (e: any) {
        this.error = e.message;
      } finally {
        this.loading = false;
      }
    },

    async loadGraphData() {
        if (!this.currentNovel || !this.currentRun) return;
        const hash = this.currentNovel.hashes[0];
        if (!hash) return;

        // If already loaded, skip
        if (this.graphData) return;

        this.loading = true;
        try {
            this.graphData = await API.fetchGraphData(this.currentNovel.name, hash, this.currentRun.timestamp);
        } catch (e: any) {
            this.error = e.message;
        } finally {
            this.loading = false;
        }
    }
  },
});


==================== FILE: frontend\src\types\index.ts ====================

export interface Novel {
  name: string;
  hashes: string[];
}

export interface Run {
  timestamp: string;
  file_hash: string;
}

export interface Chapter {
  id: string;
  title: string;
  headline: string | null;
  summary_sentences: SummarySentence[];
  content?: string;
  entities?: Entity[];
}

export interface SummarySentence {
  summary_text: string;
  source_spans: SourceSpan[];
}

export interface SourceSpan {
  start_index: number;
  end_index: number;
  text: string;
}

export interface Entity {
  name: string;
  type: string;
  description: string;
  history?: { chapter_id: string; content: string }[];
  count?: number;
  chapter_ids?: string[];
}

export interface TimelineEvent {
  chapter_id: string;
  chapter_index: number;
  chapter_title: string;
  content: string[];
  gap_before: number;
}

export interface GraphData {
  nodes: Entity[];
  edges: Relationship[];
}

export interface Relationship {
  source: string;
  target: string;
  weight: number;
  timeline?: EdgeEvent[];
}

export interface GraphNode {
  // Deprecated, use Entity
  id: string;
  label: string;
  group: string;
  value: number;
}

export interface GraphEdge {
  // Deprecated, use Relationship
  from: string;
  to: string;
  value: number;
}

export interface EdgeEvent {
  chapter_id: string;
  weight?: number;
  relation?: string;
  description?: string;
  order?: number;
}

export interface RelationshipInteraction {
  direction: 'forward' | 'backward';
  relation: string;
  description: string;
  confidence: number;
}

export interface NarrativeState {
  trust_level: number;
  romance_level: number;
  conflict_level: number;
  dominant_archetype: string;
  current_stage: string;
  summary_so_far: string;
  unresolved_threads: string[];
}

export interface RelationshipTimelineEvent {
  chapter_id: string;
  chapter_index: number;
  chapter_title: string;
  interactions: RelationshipInteraction[];
  narrative_state?: NarrativeState;
}


==================== FILE: frontend\src\views\Dashboard.vue ====================

<script setup lang="ts">
import { useNovelStore } from '@/stores/novel';
import { onMounted } from 'vue';
import AppNavbar from '../components/AppNavbar.vue';
import OverviewGrid from '../components/OverviewGrid.vue';
import GraphView from '../components/GraphView.vue';
import ReaderView from '../components/ReaderView.vue';

const store = useNovelStore();

onMounted(async () => {
  await store.loadNovels();
});
</script>

<template>
  <div class="h-screen flex flex-col bg-gray-50 text-gray-900 font-sans">
    <AppNavbar />
    
    <main class="flex-1 overflow-hidden relative">
      <div v-if="store.loading && !store.graphData && store.viewMode !== 'focus'" class="absolute inset-0 flex items-center justify-center bg-white/80 z-50">
        <div class="flex flex-col items-center gap-4">
            <div class="animate-spin rounded-full h-12 w-12 border-b-2 border-indigo-600"></div>
            <p class="text-indigo-600 font-medium animate-pulse">Loading story data...</p>
        </div>
      </div>

      <div v-if="store.error" class="p-8 text-center text-red-600">
        <p class="font-bold text-lg mb-2">Error</p>
        <p>{{ store.error }}</p>
      </div>

      <Transition name="fade" mode="out-in">
        <OverviewGrid v-if="store.viewMode === 'overview'" />
        <GraphView v-else-if="store.viewMode === 'graph'" />
        <ReaderView v-else-if="store.viewMode === 'focus' || store.viewMode === 'reader'" />
      </Transition>
    </main>
  </div>
</template>

<style>
.fade-enter-active,
.fade-leave-active {
  transition: opacity 0.2s ease;
}

.fade-enter-from,
.fade-leave-to {
  opacity: 0;
}
</style>
