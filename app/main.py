import argparse
import sys
import os
from core.splitter.processor import Splitter
from core.splitter.saver import save_chapters
from core.summarizer.llm_client import ClientFactory
from core.summarizer.generator import SummaryGenerator
from core.utils import calculate_file_hash
from data_protocol.models import Chapter
import json
import time
from core.config import settings
from core.paths import PathManager

def parse_range(range_str: str, max_val: int) -> tuple:
    """
    è§£æç”¨æˆ·è¾“å…¥çš„èŒƒå›´å­—ç¬¦ä¸²
    æ”¯æŒæ ¼å¼: 
    - "10" -> (1, 10)
    - "5-15" -> (5, 15)
    - "all" -> (1, max_val)
    - "" (empty) -> (1, max_val)
    """
    s = range_str.strip().lower()
    if not s or s == 'all':
        return (1, max_val)
    
    if '-' in s:
        try:
            start, end = map(int, s.split('-'))
            return (max(1, start), min(max_val, end))
        except ValueError:
            return (1, max_val)
            
    try:
        val = int(s)
        return (1, min(max_val, val))
    except ValueError:
        return (1, max_val)

def get_user_input():
    """äº¤äº’å¼è·å–ç”¨æˆ·è¾“å…¥"""
    print("\n=== å°è¯´åˆ†å‰²å·¥å…· ===")
    
    # 0. å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
    config_path = "config.json"
    if os.path.exists(config_path):
        print(f"\næ£€æµ‹åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        if input("æ˜¯å¦åŠ è½½é…ç½®å¹¶ç›´æ¥è¿è¡Œ? (Y/n): ").strip().lower() != 'n':
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                # è§£æé…ç½®
                input_file = config.get('input_file', '')
                encoding = config.get('encoding', 'utf-8')
                output_dir = config.get('output_dir', 'output')
                mode_str = config.get('mode', 'chapter')
                range_str = config.get('chapter_range', '')
                batch_size = config.get('batch_size', 10)
                
                # æ˜ å°„æ¨¡å¼å­—ç¬¦ä¸²åˆ°ç¼–å·
                mode_map_rev = {'volume': '1', 'chapter': '2', 'batch': '3'}
                mode = mode_map_rev.get(mode_str, '2')
                
                # è§£æèŒƒå›´
                # éœ€è¦å…ˆæ‰«æç« èŠ‚æ•°æ‰èƒ½è§£æ "all" æˆ– "-10" å—ï¼Ÿ
                # parse_range éœ€è¦ max_valã€‚
                # æˆ‘ä»¬å¯ä»¥å…ˆæ‰«ææ–‡ä»¶ã€‚
                
                print("\n--- é…ç½®ä¿¡æ¯ ---")
                print(f"æ–‡ä»¶: {input_file}")
                print(f"ç¼–ç : {encoding}")
                print(f"æ¨¡å¼: {mode_str}")
                print(f"èŒƒå›´: {range_str if range_str else 'All'}")
                print(f"è¾“å‡º: {output_dir}")
                
                summ_conf = config.get('summarize', {})
                
                # è‡ªåŠ¨å¡«å…… API Key é€»è¾‘ (Fix for .env loading)
                if summ_conf.get('enabled') and summ_conf.get('provider') == 'openrouter':
                    current_key = summ_conf.get('api_key')
                    if not current_key:  # If None or Empty String
                        # ä¼˜å…ˆä» settings (PydanticåŠ è½½çš„.env) è·å–ï¼Œå…¶æ¬¡æ‰æ˜¯ os.getenv
                        env_key = settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
                        if env_key:
                            summ_conf['api_key'] = env_key
                            print(f"  (å·²è‡ªåŠ¨ä» .env/ç¯å¢ƒå˜é‡ åŠ è½½ OPENROUTER_API_KEY)")

                print(f"AIæ€»ç»“: {'å¼€å¯' if summ_conf.get('enabled') else 'å…³é—­'}")
                if summ_conf.get('enabled'):
                    print(f"  Provider: {summ_conf.get('provider')}")
                    print(f"  Model: {summ_conf.get('model')}")
                    repair_list = summ_conf.get('repair_chapters')
                    if repair_list:
                         print(f"  ğŸ”§ Repair Chapters: {repair_list}")
                
                if input("\nç¡®è®¤æ‰§è¡Œ? (Y/n): ").strip().lower() != 'n':
                    # æ‰§è¡Œé¢„æ‰«æä»¥è·å–ç« èŠ‚æ€»æ•° (ç”¨äºè§£æèŒƒå›´)
                    print("\næ­£åœ¨æ‰«ææ–‡ä»¶ç»“æ„...")
                    splitter = Splitter(encoding=encoding)
                    content = splitter.read_file(input_file)
                    # æ›´æ–°ä¸ºå®é™…æ£€æµ‹åˆ°çš„ç¼–ç 
                    encoding = splitter.encoding
                    total_chapters, _, _ = splitter.scan_chapters(content)
                    
                    chapter_range = parse_range(range_str, total_chapters)
                    
                    # æ„é€ è¿”å›å­—å…¸
                    extra_args = {}
                    if mode == '3':
                        extra_args['range'] = batch_size
                    if chapter_range:
                        extra_args['chapter_range'] = chapter_range
                        
                    return {
                        'input_file': input_file,
                        'mode': mode,
                        'output_dir': output_dir,
                        'encoding': encoding,
                        'extra_args': extra_args,
                        'summarize_config': summ_conf
                    }
            except Exception as e:
                print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                print("å°†è½¬ä¸ºæ‰‹åŠ¨è¾“å…¥æ¨¡å¼...")

    # 1. è·å–è¾“å…¥æ–‡ä»¶
    # å°è¯•ä½¿ç”¨ tkinter å¼¹å‡ºæ–‡ä»¶é€‰æ‹©æ¡†
    input_file = ""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        # éšè—ä¸»çª—å£
        root = tk.Tk()
        root.withdraw()
        
        # å°è¯•å¼ºåˆ¶çª—å£ç½®é¡¶ (Windowsç‰¹å®š)
        root.attributes('-topmost', True)
        
        print("æ­£åœ¨æ‰“å¼€æ–‡ä»¶é€‰æ‹©çª—å£...")
        input_file = filedialog.askopenfilename(
            title="é€‰æ‹©å°è¯´TXTæ–‡ä»¶",
            filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")]
        )
        root.destroy()
    except ImportError:
        # å¦‚æœæ²¡æœ‰ tkinterï¼Œé™é»˜å¤±è´¥ï¼Œå›é€€åˆ°è¾“å…¥æ¡†
        pass
    except Exception as e:
        print(f"æ— æ³•æ‰“å¼€æ–‡ä»¶é€‰æ‹©æ¡† ({e})ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ã€‚")
    
    # å¦‚æœç”¨æˆ·å–æ¶ˆé€‰æ‹©æˆ–æ— æ³•ä½¿ç”¨ tkinterï¼Œå›é€€åˆ°æ‰‹åŠ¨è¾“å…¥
    while not input_file:
        input_file = input("è¯·è¾“å…¥å°è¯´txtæ–‡ä»¶è·¯å¾„: ").strip()
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·
        input_file = input_file.strip('"').strip("'")
        if os.path.exists(input_file):
            break
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
    
    print(f"å·²é€‰æ‹©æ–‡ä»¶: {input_file}")

    # 2. ç¼–ç è®¾ç½®ï¼ˆæå‰åˆ°ç¬¬äºŒæ­¥ï¼Œä»¥ä¾¿æ‰«ææ–‡ä»¶ï¼‰
    encoding = input("\nè¯·è¾“å…¥æ–‡ä»¶ç¼–ç  (é»˜è®¤ä¸º 'utf-8', è‹¥ä¹±ç å¯å°è¯• 'gbk'): ").strip()
    if not encoding:
        encoding = 'utf-8'

    # 3. é¢„æ‰«æç« èŠ‚
    print("\næ­£åœ¨æ‰«ææ–‡ä»¶ç»“æ„...")
    try:
        splitter = Splitter(encoding=encoding)
        content = splitter.read_file(input_file)
        # æ›´æ–°ä¸ºå®é™…æ£€æµ‹åˆ°çš„ç¼–ç 
        encoding = splitter.encoding
        
        total_chapters, titles, is_continuous = splitter.scan_chapters(content)
        
        if total_chapters > 0:
            print(f"âœ… æ£€æµ‹åˆ°å…± {total_chapters} ç« ã€‚")
            if not is_continuous:
                print("âš ï¸  è­¦å‘Š: ç« èŠ‚ç¼–å·ä¼¼ä¹ä¸è¿ç»­ï¼Œå»ºè®®æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
            else:
                print("   ç« èŠ‚ç¼–å·è¿ç»­ã€‚")
            
            print(f"   é¦–ç« : {titles[0]}")
            print(f"   æœ«ç« : {titles[-1]}")
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„åˆ†ç« ç»“æ„ (å¯èƒ½éœ€è¦æŒ‰å·æˆ–è‡ªå®šä¹‰æ­£åˆ™)ã€‚")
            total_chapters = 999999 # Fallback
            
    except Exception as e:
        print(f"æ‰«æå¤±è´¥: {e}")
        total_chapters = 0

    # 4. é€‰æ‹©å¤„ç†èŒƒå›´
    chapter_range = None
    if total_chapters > 0:
        range_input = input(f"\nè¯·è¾“å…¥å¤„ç†èŒƒå›´ (é»˜è®¤å¤„ç†å…¨éƒ¨ï¼Œè¾“å…¥ '10' ä»£è¡¨å‰10ç« ï¼Œ'5-20' ä»£è¡¨åŒºé—´): ").strip()
        chapter_range = parse_range(range_input, total_chapters)
        print(f"å·²é€‰æ‹©èŒƒå›´: ç¬¬{chapter_range[0]}ç«  - ç¬¬{chapter_range[1]}ç« ")

    # 5. é€‰æ‹©æ¨¡å¼
    print("\nè¯·é€‰æ‹©åˆ†å‰²æ¨¡å¼ï¼š")
    print("1. æŒ‰å·åˆ†å‰²ï¼ˆè‡ªåŠ¨è¯†åˆ«åˆ†å·ï¼Œå·å†…å†åˆ†ç« ï¼‰")
    print("2. ä»…æŒ‰ç« èŠ‚åˆ†å‰²ï¼ˆæ•´æœ¬å°è¯´åˆ‡åˆ†ä¸ºå•ç« æ–‡ä»¶ï¼‰")
    print("3. æŒ‰æ•°é‡åˆå¹¶åˆ†å‰²ï¼ˆæ¯Nç« åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼‰")
    
    while True:
        mode = input("è¯·è¾“å…¥æ¨¡å¼ç¼–å· (1/2/3): ").strip()
        if mode in ['1', '2', '3']:
            break
        print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ 1, 2 æˆ– 3ã€‚")

    # 6. è·å–è¾“å‡ºç›®å½•
    output_dir = input(f"\nè¯·è¾“å…¥è¾“å‡ºç›®å½• (é»˜è®¤ä¸º '{settings.OUTPUT_DIR.name}'): ").strip()
    if not output_dir:
        output_dir = str(settings.OUTPUT_DIR)

    # 7. è·å–ç‰¹å®šæ¨¡å¼çš„é¢å¤–å‚æ•°
    extra_args = {}
    if mode == '3':
        while True:
            try:
                range_val = input("è¯·è¾“å…¥æ¯ä¸ªæ–‡ä»¶åŒ…å«çš„ç« èŠ‚æ•° (é»˜è®¤ä¸º10): ").strip()
                if not range_val:
                    extra_args['range'] = 10
                else:
                    extra_args['range'] = int(range_val)
                break
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ã€‚")
    
    # Pass the scan result range
    if chapter_range:
        extra_args['chapter_range'] = chapter_range

    # 8. AI æ€»ç»“é…ç½®
    summarize_config = {'enabled': False}
    print("\næ˜¯å¦å¼€å¯ AI æ™ºèƒ½æ€»ç»“? (y/N)")
    if input().lower().strip() == 'y':
        summarize_config['enabled'] = True
        
        print("\nè¯·é€‰æ‹© LLM æä¾›å•†:")
        print("1. OpenRouter (é»˜è®¤)")
        print("2. Local (Ollama/vLLM)")
        prov_input = input("è¯·è¾“å…¥ç¼–å· (1/2): ").strip()
        
        if prov_input == '2':
            summarize_config['provider'] = 'local'
            # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–é»˜è®¤å€¼
            default_base = os.getenv("LOCAL_LLM_BASE_URL", "http://localhost:11434/v1")
            default_model = os.getenv("LOCAL_LLM_MODEL", "qwen2.5:14b")
            
            base_url = input(f"Base URL (é»˜è®¤ '{default_base}'): ").strip()
            summarize_config['base_url'] = base_url if base_url else default_base
            
            model = input(f"Model Name (é»˜è®¤ '{default_model}'): ").strip()
            summarize_config['model'] = model if model else default_model
        else:
            summarize_config['provider'] = 'openrouter'
            # OpenRouter Config
            default_model = os.getenv("OPENROUTER_MODEL", "google/gemini-2.0-flash-001")
            model = input(f"Model Name (é»˜è®¤ '{default_model}'): ").strip()
            summarize_config['model'] = model if model else default_model
            
            # API Key
            env_key = os.getenv("OPENROUTER_API_KEY")
            if env_key:
                print(f"æ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ OPENROUTER_API_KEY (å·²éšè—)")
                use_env = input("æ˜¯å¦ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ Key? (Y/n): ").strip().lower()
                if use_env == 'n':
                    summarize_config['api_key'] = input("è¯·è¾“å…¥ OpenRouter API Key: ").strip()
                else:
                    summarize_config['api_key'] = env_key
            else:
                summarize_config['api_key'] = input("è¯·è¾“å…¥ OpenRouter API Key: ").strip()

    return {
        'input_file': input_file,
        'mode': mode,
        'output_dir': output_dir,
        'encoding': encoding,
        'extra_args': extra_args,
        'summarize_config': summarize_config
    }

from core.summarizer.prompts import Prompts
from core.cache_manager import CacheManager

def main():
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¯åŠ¨ Web æœåŠ¡å‘½ä»¤
    if len(sys.argv) > 1 and sys.argv[1] == 'serve':
        try:
            import uvicorn
            # from backend.server import app # Don't import here to avoid circular imports during reload
            print("=== StoryTrace Visualization Server ===")
            print("æ­£åœ¨å¯åŠ¨ API æœåŠ¡...")
            
            # Re-read settings to ensure port is correct
            from core.config import settings
            
            print(f"è®¿é—®åœ°å€: http://{settings.API_HOST}:{settings.API_PORT}/docs")
            # Use string import for reload support
            uvicorn.run("backend.server:app", host=settings.API_HOST, port=int(settings.API_PORT), reload=True)
        except ImportError:
            print("é”™è¯¯: è¯·å…ˆå®‰è£… web ä¾èµ–: pip install fastapi uvicorn")
        except Exception as e:
            print(f"å¯åŠ¨å¤±è´¥: {e}")
        return

    parser = argparse.ArgumentParser(description='å…¨èƒ½å°è¯´åˆ†å‰²å·¥å…·')
    parser.add_argument('-i', '--input', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--mode', choices=['volume', 'chapter', 'batch'], 
                        help='åˆ†å‰²æ¨¡å¼: volume(æŒ‰å·), chapter(æŒ‰ç« ), batch(æŒ‰æ•°é‡)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('-e', '--encoding', default='utf-8', help='æ–‡ä»¶ç¼–ç ')
    parser.add_argument('-r', '--range', type=int, default=10, help='æ‰¹é‡åˆ†å‰²æ—¶çš„ç« èŠ‚æ•°é‡ (ä»…batchæ¨¡å¼æœ‰æ•ˆ)')
    parser.add_argument('--pattern', default=r'^[ç¬¬å·\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+å·', help='åˆ†å·åŒ¹é…æ¨¡å¼ (ä»…volumeæ¨¡å¼æœ‰æ•ˆ)')
    
    # LLM ç›¸å…³å‚æ•°
    parser.add_argument('--summarize', action='store_true', help='å¼€å¯æ™ºèƒ½æ€»ç»“ (å®éªŒæ€§åŠŸèƒ½)')
    parser.add_argument('--provider', default='openrouter', choices=['local', 'openrouter'], help='LLM æä¾›å•†')
    parser.add_argument('--api-key', help='API Key (OpenRouter éœ€è¦)')
    parser.add_argument('--model', help='æ¨¡å‹åç§°')
    parser.add_argument('--base-url', help='Local LLM Base URL')
    parser.add_argument('--repair', help='æŒ‡å®šéœ€å¼ºåˆ¶é‡ç”Ÿæˆçš„ç« èŠ‚ç¼–å·ï¼Œé€—å·åˆ†éš” (e.g. 77,78)')

    # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•å‚æ•°ï¼Œä¸”ä¸æ˜¯è¢«å¯¼å…¥è°ƒç”¨ï¼Œåˆ™è¿›å…¥äº¤äº’æ¨¡å¼
    if len(sys.argv) == 1:
        args_dict = get_user_input()
        print("\nDEBUG: ç”¨æˆ·è¾“å…¥æ¥æ”¶å®Œæˆï¼Œæ­£åœ¨åˆå§‹åŒ–...", flush=True)
        input_file = args_dict['input_file']
        mode = args_dict['mode']
        output_dir = args_dict['output_dir']
        encoding = args_dict['encoding']
        
        # æ˜ å°„æ¨¡å¼ç¼–å·åˆ°å†…éƒ¨åç§°
        mode_map = {'1': 'volume', '2': 'chapter', '3': 'batch'}
        mode_name = mode_map[mode]
        
        extra_args = args_dict['extra_args']
        batch_size = extra_args.get('range', 10)
        chapter_range_filter = extra_args.get('chapter_range')
        
        pattern = r'^[ç¬¬å·\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+å·' # äº¤äº’æ¨¡å¼ä½¿ç”¨é»˜è®¤pattern
        
        # è¯»å–äº¤äº’æ¨¡å¼ä¸‹çš„ LLM é…ç½®
        summarize_config = args_dict.get('summarize_config', {'enabled': False})
        summarize = summarize_config['enabled']
        provider = summarize_config.get('provider', 'openrouter')
        api_key = summarize_config.get('api_key')
        model = summarize_config.get('model')
        base_url = summarize_config.get('base_url')
        
        # è§£æä¿®å¤ç« èŠ‚é…ç½®
        repair_chapters = []
        raw_repair = summarize_config.get('repair_chapters', [])
        if isinstance(raw_repair, list):
            repair_chapters = [int(x) for x in raw_repair]
        elif isinstance(raw_repair, str):
            try:
                repair_chapters = [int(x.strip()) for x in raw_repair.split(',') if x.strip()]
            except ValueError:
                print("è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸­ repair_chapters æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºæ•´æ•°åˆ—è¡¨æˆ–é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²")
        elif isinstance(raw_repair, int):
            repair_chapters = [raw_repair]
        
        # å¦‚æœ Config ä¸­æ²¡æœ‰æä¾› API Keyï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not api_key and provider == 'openrouter':
            api_key = settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
            if api_key:
                print("DEBUG: ä½¿ç”¨ .env/ç¯å¢ƒå˜é‡ ä¸­çš„ OPENROUTER_API_KEY")
    else:
        args = parser.parse_args()
        if not args.input:
            parser.error("éäº¤äº’æ¨¡å¼ä¸‹å¿…é¡»æŒ‡å®šè¾“å…¥æ–‡ä»¶ (-i/--input)")
        if not args.mode:
            parser.error("éäº¤äº’æ¨¡å¼ä¸‹å¿…é¡»æŒ‡å®šæ¨¡å¼ (-m/--mode)")
            
        input_file = args.input
        mode_name = args.mode
        output_dir = args.output if args.output else str(settings.OUTPUT_DIR)
        encoding = args.encoding
        batch_size = args.range
        pattern = args.pattern
        chapter_range_filter = None # CLIæ¨¡å¼æš‚ä¸æ”¯æŒ range filterï¼Œåç»­å¯æ·»åŠ 
        
        summarize = args.summarize
        provider = args.provider
        
        # ä¼˜å…ˆä»å‘½ä»¤è¡Œå‚æ•°è·å–ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        api_key = args.api_key or settings.OPENROUTER_API_KEY or os.getenv("OPENROUTER_API_KEY")
        model = args.model
        base_url = args.base_url

        # å¦‚æœæ˜¯ OpenRouter ä¸”æ²¡æœ‰æŒ‡å®š Modelï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–é»˜è®¤ Model
        if provider == 'openrouter' and not model:
             model = settings.OPENROUTER_MODEL or os.getenv("OPENROUTER_MODEL")
             
        # å¦‚æœæ˜¯ Local ä¸”æ²¡æœ‰æŒ‡å®šå‚æ•°ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if provider == 'local':
             if not base_url:
                 base_url = settings.LOCAL_LLM_BASE_URL or os.getenv("LOCAL_LLM_BASE_URL")
             if not model:
                 model = settings.LOCAL_LLM_MODEL or os.getenv("LOCAL_LLM_MODEL")

        # è§£æä¿®å¤ç« èŠ‚å‚æ•°
        repair_chapters = []
        if args.repair:
            try:
                repair_chapters = [int(x.strip()) for x in args.repair.split(',') if x.strip()]
            except ValueError:
                print("è­¦å‘Š: --repair å‚æ•°æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºé€—å·åˆ†éš”çš„æ•°å­— (e.g. 77,78)")

    # æ„å»ºæœ€ç»ˆè¾“å‡ºç›®å½•ç»“æ„
    # 1. è·å–å°è¯´åï¼ˆè¾“å…¥æ–‡ä»¶åï¼Œä¸å«æ‰©å±•åï¼‰
    novel_name = os.path.splitext(os.path.basename(input_file))[0]
    
    # --- è‡ªåŠ¨å¤åˆ¶å¤–éƒ¨æ–‡ä»¶é€»è¾‘ ---
    # è·å–é¡¹ç›®æ ¹ç›®å½• (å‡è®¾ main.py åœ¨ app/ ç›®å½•ä¸‹)
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    input_abs = os.path.abspath(input_file)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨é¡¹ç›®ç›®å½•å†…
    if not input_abs.startswith(project_root):
        print(f"\næç¤º: æ£€æµ‹åˆ°è¾“å…¥æ–‡ä»¶ä½äºé¡¹ç›®ç›®å½•å¤– ({input_abs})")
        inputs_dir = os.path.join(project_root, "inputs")
        os.makedirs(inputs_dir, exist_ok=True)
        
        new_path = os.path.join(inputs_dir, os.path.basename(input_file))
        
        # è‡ªåŠ¨å¤åˆ¶
        try:
            import shutil
            if not os.path.exists(new_path):
                print(f"æ­£åœ¨å¤åˆ¶æ–‡ä»¶åˆ°é¡¹ç›®ç›®å½•: {new_path} ...")
                shutil.copy2(input_file, new_path)
            else:
                print(f"é¡¹ç›®ç›®å½•å†…å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œå°†ä½¿ç”¨: {new_path}")
            
            # æ›´æ–° input_file æŒ‡å‘æ–°è·¯å¾„
            input_file = new_path
        except Exception as e:
            print(f"è­¦å‘Š: æ–‡ä»¶å¤åˆ¶å¤±è´¥ ({e})ï¼Œå°†ç»§ç»­ä½¿ç”¨åŸè·¯å¾„ã€‚")

    print(f"DEBUG: æ­£åœ¨è®¡ç®—æ–‡ä»¶å“ˆå¸Œ... (æ–‡ä»¶: {input_file})", flush=True)
    # 2. è®¡ç®—æ–‡ä»¶å“ˆå¸Œï¼ˆå–å‰8ä½å³å¯ï¼‰
    file_hash = calculate_file_hash(input_file)
    if len(file_hash) > 8:
        file_hash = file_hash[:8]
    print(f"DEBUG: æ–‡ä»¶å“ˆå¸Œ: {file_hash}", flush=True)
    
    # --- ç¼“å­˜æ£€æŸ¥é€»è¾‘ (v3.0) ---
    print(f"DEBUG: Summarize={summarize}, Provider={provider}", flush=True)
    
    # 1. è®¡ç®—å½“å‰è¿è¡Œçš„ Fingerprint
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è¿˜æ²¡æœ‰åŠ è½½ promptsï¼Œéœ€è¦å¼•å…¥ Prompts ç±»æ¥è®¡ç®—
    current_fingerprint = {
        "source_file_hash": file_hash,
        "prompt_hash": Prompts.get_prompt_hash() if summarize else None,
        "model_config": {
            "provider": provider,
            "model": model,
            # "temperature": ... (å¦‚æœåç»­æ”¯æŒ temp å‚æ•°ï¼Œè¿™é‡Œä¹Ÿè¦åŠ ä¸Š)
        } if summarize else None,
        "splitter_config": {
            "mode": mode_name,
            "batch_size": batch_size if mode_name == 'batch' else None,
            "chapter_range_filter": chapter_range_filter, # æ–°å¢èŒƒå›´è¿‡æ»¤æŒ‡çº¹
            "pattern": pattern if mode_name == 'volume' else None
        }
    }
    print("DEBUG: æŒ‡çº¹è®¡ç®—å®Œæˆï¼Œæ­£åœ¨æ£€æŸ¥ç¼“å­˜...")
    
    # 2. æ‰«æå†å²è®°å½•
    novel_output_root = PathManager.get_novel_root(novel_name, file_hash)
    cache_hit_path = None
    cache_hit_timestamp = None
    
    if os.path.exists(novel_output_root) and summarize: # åªæœ‰å¼€å¯æ€»ç»“æ—¶æ‰å€¼å¾—ç¼“å­˜
        for ts in os.listdir(novel_output_root):
            ts_path = os.path.join(novel_output_root, ts)
            meta_path = os.path.join(ts_path, "run_metadata.json")
            if os.path.isdir(ts_path) and os.path.exists(meta_path):
                try:
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta = json.load(f)
                        # æ¯”è¾ƒæŒ‡çº¹
                        # æ³¨æ„ï¼šæ—§ç‰ˆæœ¬çš„ metadata æ²¡æœ‰ fingerprint å­—æ®µï¼Œä¼šè‡ªåŠ¨å¿½ç•¥
                        if meta.get("fingerprint") == current_fingerprint:
                            cache_hit_path = ts_path
                            cache_hit_timestamp = ts
                            break
                except Exception:
                    continue
    
    # 3. å¦‚æœå‘½ä¸­ç¼“å­˜
    if cache_hit_path:
        print(f"\n[Cache Hit] å‘ç°å®Œå…¨ç›¸åŒçš„å†å²è¿è¡Œè®°å½•: {cache_hit_timestamp}")
        print(f"æ— éœ€é‡å¤è°ƒç”¨ LLMã€‚")
        
        # ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        final_output_dir = PathManager.get_run_dir(novel_name, file_hash, timestamp)
        os.makedirs(final_output_dir, exist_ok=True)
        
        # åˆ›å»º ref_link.json
        link_data = {
            "link_type": "cache_hit",
            "target_timestamp": cache_hit_timestamp,
            "reason": "Fingerprint match",
            "fingerprint": current_fingerprint
        }
        with open(os.path.join(final_output_dir, "ref_link.json"), 'w', encoding='utf-8') as f:
            json.dump(link_data, f, ensure_ascii=False, indent=2)
            
        print(f"å·²åˆ›å»ºé“¾æ¥ç›®å½•: {final_output_dir}")
        print(f"æ‚¨å¯ä»¥åœ¨ Visualization Server ä¸­æŸ¥çœ‹æ­¤è®°å½•ï¼ˆå°†è‡ªåŠ¨æŒ‡å‘å†å²æ•°æ®ï¼‰ã€‚")
        return
    
    # --- ç¼“å­˜æ£€æŸ¥ç»“æŸ ---

    # 3. è·å–å½“å‰æ—¶é—´æˆ³
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # æœ€ç»ˆè·¯å¾„ï¼šoutput_dir/novel_name/file_hash/timestamp
    final_output_dir = PathManager.get_run_dir(novel_name, file_hash, timestamp)
    abs_final_output_dir = os.path.abspath(final_output_dir)
    
    # æ‰§è¡Œåˆ†å‰²é€»è¾‘
    print(f"\nå¼€å§‹å¤„ç†ï¼š{input_file}")
    print(f"æ¨¡å¼ï¼š{mode_name}")
    print(f"è¾“å‡ºç›®å½• (ç»å¯¹è·¯å¾„)ï¼š{abs_final_output_dir}")
    
    try:
        print(f"æ­£åœ¨è¯»å–æ–‡ä»¶ (ç¼–ç : {encoding})...")
        splitter = Splitter(encoding=encoding)
        content = splitter.read_file(input_file)
        
        print("æ­£åœ¨åˆ†å‰²ç« èŠ‚...")
        if mode_name == 'volume':
            # æš‚æ—¶ä¸æ”¯æŒå·æ¨¡å¼çš„èŒƒå›´è¿‡æ»¤
            chapters = splitter.split_by_volume(content, volume_pattern=pattern)
        elif mode_name == 'chapter':
            chapters = splitter.split_by_chapter(content, chapter_range=chapter_range_filter)
        elif mode_name == 'batch':
            chapters = splitter.split_by_batch(content, batch_size=batch_size, chapter_range=chapter_range_filter)
        else:
            print(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode_name}")
            return
            
        if chapters:
            print(f"æˆåŠŸåˆ†å‰²å‡º {len(chapters)} ç« ã€‚æ­£åœ¨ä¿å­˜...")
            # ä½¿ç”¨æ–°çš„ final_output_dir ä¿å­˜ç« èŠ‚
            # å¼ºåˆ¶ä½¿ç”¨ UTF-8 ä¿å­˜ï¼Œç¡®ä¿ Web UI èƒ½æ­£ç¡®è¯»å–
            save_chapters(chapters, final_output_dir, encoding='utf-8')
            print("\nåˆ†å‰²å¤„ç†å®Œæˆï¼")
            
            # å¦‚æœå¼€å¯äº†æ€»ç»“åŠŸèƒ½
            if summarize:
                print("\n=== å¼€å§‹æ™ºèƒ½æ€»ç»“ ===")
                try:
                    # ç¡®ä¿å‚æ•°ä¸ä¸ºç©º
                    client_kwargs = {
                        "provider": provider,
                        "api_key": api_key,
                        "model": model,
                        "base_url": base_url
                    }
                    # è¿‡æ»¤æ‰ None å€¼å’Œç©ºå­—ç¬¦ä¸²
                    client_kwargs = {k: v for k, v in client_kwargs.items() if v}
                    
                    llm_client = ClientFactory.create_client(**client_kwargs)
                    generator = SummaryGenerator(llm_client)
                    
                    # --- v4.0 Chapter-Level Caching ---
                    # Initialize CacheManager
                    cache_dir = PathManager.get_cache_dir()
                    cache_manager = CacheManager(str(cache_dir))
                    
                    prompt_hash = Prompts.get_prompt_hash()
                    model_config = {
                        "provider": provider,
                        "model": model,
                        "base_url": base_url
                    }
                    
                    import asyncio
                    
                    # Initialize total_chapters before defining async functions
                    total_chapters = len(chapters)

                    async def process_chapter_async(i, ch, cache_manager, generator, prompt_hash, model_config, semaphore, file_lock, jsonl_path):
                        async with semaphore:
                            print(f"[{i+1}/{total_chapters}] å¤„ç†ç« èŠ‚: {ch.title} ... ", end="", flush=True)
                            
                            # 1. Try Cache
                            current_chapter_num = i + 1
                            should_repair = current_chapter_num in repair_chapters
                            
                            cached_summary = None
                            if not should_repair:
                                cached_summary = cache_manager.get_cached_summary(ch.content, prompt_hash, model_config)
                            else:
                                print(f"ğŸ”§ [Repair] å¼ºåˆ¶é‡ç”Ÿæˆç¬¬ {current_chapter_num} ç« ...")
                            
                            summary_data = None
                            
                            if cached_summary:
                                print("âœ… å‘½ä¸­ç¼“å­˜")
                                cached_summary.chapter_id = ch.id 
                                summary_data = cached_summary.model_dump()
                            else:
                                # 2. Generate (Async) with Retry
                                max_retries = 3
                                retry_delay = 2
                                
                                for attempt in range(max_retries):
                                    try:
                                        summary = await generator.generate_summary_async(ch)
                                        
                                        # 3. Save to Cache
                                        try:
                                            cache_manager.save_summary(ch.content, prompt_hash, model_config, summary)
                                        except Exception as cache_err:
                                            print(f"(Cache Write Failed: {cache_err}) ", end="")
                                            
                                        summary_data = summary.model_dump()
                                        print("âœ¨ ç”Ÿæˆå®Œæˆ")
                                        break # Success
                                    except Exception as e:
                                        if attempt < max_retries - 1:
                                            print(f"âš ï¸ å¤±è´¥(é‡è¯• {attempt+1}/{max_retries}): {e} ... ", end="", flush=True)
                                            await asyncio.sleep(retry_delay * (2 ** attempt)) # Exponential backoff
                                        else:
                                            print(f"âŒ æœ€ç»ˆå¤±è´¥: {e}")
                                            # Create Empty Placeholder to keep chapter in timeline
                                            from data_protocol.models import ChapterSummary
                                            empty_summary = ChapterSummary(
                                                chapter_id=ch.id,
                                                chapter_title=ch.title,
                                                headline="ç”Ÿæˆå¤±è´¥",
                                                summary_sentences=[],
                                                entities=[],
                                                relationships=[]
                                            )
                                            summary_data = empty_summary.model_dump()
                                
                            # Real-time save to summaries.jsonl (with lock)
                            if summary_data:
                                async with file_lock:
                                    with open(jsonl_path, 'a', encoding='utf-8') as f:
                                        json.dump(summary_data, f, ensure_ascii=False)
                                        f.write('\n')
                            
                            return (i, summary_data)

                    async def run_batch_processing():
                        # Adjust concurrency based on provider
                        limit = 1 if provider == 'local' else 5
                        semaphore = asyncio.Semaphore(limit)
                        file_lock = asyncio.Lock()
                        jsonl_path = os.path.join(final_output_dir, "summaries.jsonl")
                        
                        tasks = []
                        for i, ch in enumerate(chapters):
                            task = process_chapter_async(i, ch, cache_manager, generator, prompt_hash, model_config, semaphore, file_lock, jsonl_path)
                            tasks.append(task)
                        
                        results = await asyncio.gather(*tasks)
                        
                        # Sort results by index to ensure order
                        valid_results = [r for r in results if r is not None]
                        valid_results.sort(key=lambda x: x[0])
                        
                        return [r[1] for r in valid_results]

                    # Run Async Loop
                    summaries = asyncio.run(run_batch_processing())
                    
                    # ä¿å­˜æ€»ç»“ç»“æœï¼Œç›´æ¥ä¿å­˜åœ¨ final_output_dir æ ¹ç›®å½•
                    summary_path = os.path.join(final_output_dir, "summaries.json")
                    with open(summary_path, 'w', encoding='utf-8') as f:
                        json.dump(summaries, f, ensure_ascii=False, indent=2)
                    print(f"æ€»ç»“å·²ä¿å­˜è‡³: {summary_path}")
                    
                    # åŒæ—¶ä¿å­˜ä¸€ä»½ metadataï¼Œè®°å½•è¿™æ¬¡è¿è¡Œçš„å‚æ•°
                    metadata = {
                        "timestamp": timestamp,
                        "novel_name": novel_name,
                        "file_hash": file_hash,
                        "input_file": os.path.abspath(input_file),
                        "provider": provider,
                        "model": model,
                        "chapter_count": len(summaries),
                        "fingerprint": current_fingerprint # è®°å½•æŒ‡çº¹ï¼Œä¾›ä¸‹æ¬¡æ ¡éªŒ
                    }
                    with open(os.path.join(final_output_dir, "run_metadata.json"), 'w', encoding='utf-8') as f:
                        json.dump(metadata, f, ensure_ascii=False, indent=2)
                    
                    # --- è‡ªåŠ¨æ‰§è¡Œæ•°æ®åº“è¿ç§» (Auto Migration) ---
                    print("\n=== æ­£åœ¨è‡ªåŠ¨æ›´æ–°å›¾è°±æ•°æ®åº“ ===")
                    try:
                        from scripts.migrate_json_to_sqlite import migrate
                        print("æ­£åœ¨åŒæ­¥æ•°æ®åˆ° storytrace.db ...")
                        migrate()
                        print("âœ… æ•°æ®åº“åŒæ­¥å®Œæˆï¼ç°åœ¨å¯ä»¥å¯åŠ¨ Web æœåŠ¡æŸ¥çœ‹å›¾è°±äº†ã€‚")
                    except Exception as me:
                        print(f"âš ï¸ è‡ªåŠ¨è¿ç§»å¤±è´¥: {me}")
                        print("è¯·ç¨åæ‰‹åŠ¨è¿è¡Œ: python scripts/migrate_json_to_sqlite.py")

                except Exception as e:
                    print(f"æ™ºèƒ½æ€»ç»“å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
        else:
            print("\næœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚ã€‚")
        
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
